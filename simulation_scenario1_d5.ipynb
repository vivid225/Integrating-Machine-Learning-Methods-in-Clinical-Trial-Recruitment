{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd3284-5ee0-45bb-92f3-8c737c02e248",
   "metadata": {
    "executionInfo": {
     "elapsed": 2068,
     "status": "ok",
     "timestamp": 1707466261355,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "87fd3284-5ee0-45bb-92f3-8c737c02e248"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from itertools import product\n",
    "from scipy.stats import norm, binomtest\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "\n",
    "from sklearn import linear_model, svm, naive_bayes, ensemble\n",
    "from sklearn.model_selection import cross_validate, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd9b75-9988-49e9-98c2-566a7f57612f",
   "metadata": {
    "id": "0fbd9b75-9988-49e9-98c2-566a7f57612f"
   },
   "source": [
    "## Read functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZzkESkMbubvs",
   "metadata": {
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1707466293138,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "ZzkESkMbubvs"
   },
   "outputs": [],
   "source": [
    "%run functions_scenario1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tKvlxiIUH6fx",
   "metadata": {
    "id": "tKvlxiIUH6fx"
   },
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hJtnGfuuIMr_",
   "metadata": {
    "id": "hJtnGfuuIMr_"
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zVgytCZXbtpQ",
   "metadata": {
    "id": "zVgytCZXbtpQ"
   },
   "outputs": [],
   "source": [
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0))\n",
    "#             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "                    # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "#                     ('RF', ensemble.RandomForestClassifier(n_estimators=200, criterion='gini', random_state=0))\n",
    "                    # ('XGB', XGBClassifier(n_estimators=50, learning_rate=0.1, random_state=0))\n",
    "                   ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "    param_grid = {\n",
    "        # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "        'LR__C': [0.01] # [0.01, 0.05, 0.1]\n",
    "        # 'Ridge__C': [0.01]\n",
    "        # 'SVM__C': [0.01, 0.05, 0.1]\n",
    "#         'RF__n_estimators': [50] # [10, 30, 50]\n",
    "        # 'XGB__n_estimators': [50]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0optT4Hwjkte",
   "metadata": {
    "id": "0optT4Hwjkte"
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def ensemble_model_fit(data, data_pred):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         data.drop(['recruitment_plan', 'plan_response_rate', 'group_size','response'], axis=1),\n",
    "#         data['response'],\n",
    "#         test_size=0.2,\n",
    "#         random_state=0\n",
    "#     )\n",
    "\n",
    "#     # Define the Logistic Regression model\n",
    "#     logistic_regression = LogisticRegression(C=0.01, max_iter=200,random_state=0)\n",
    "\n",
    "#     # Fit the Logistic Regression model on the training data\n",
    "#     logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "#     # Print out the coefficients of the logistic regression model\n",
    "#     print(\"Coefficients:\", logistic_regression.coef_)\n",
    "#     print(\"Intercept:\", logistic_regression.intercept_)\n",
    "#     print(\"Coefficients shape:\", logistic_regression.coef_.shape)\n",
    "\n",
    "#     # Predict probabilities instead of binary outcomes on the test set\n",
    "#     y_pred_proba_test = logistic_regression.predict_proba(X_test)\n",
    "#     y_pred_test = logistic_regression.predict(X_test)\n",
    "\n",
    "#     # You can also predict probabilities for the prediction data (data_pred)\n",
    "#     X_dt = data_pred.drop(['recruitment_plan', 'plan_response_rate', 'group_size','response'], axis=1)\n",
    "#     y_pred = logistic_regression.predict_proba(X_dt)\n",
    "\n",
    "#     return y_pred\n",
    "\n",
    "# # Call the function\n",
    "# # ensemble_model_fit(data, data_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V73u9G9JJkZZ",
   "metadata": {
    "id": "V73u9G9JJkZZ"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kGy7VUgnz895",
   "metadata": {
    "id": "kGy7VUgnz895"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a66c5-ceb1-4ede-abfc-a99411b182ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 398119,
     "status": "ok",
     "timestamp": 1707464574466,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "0f0a66c5-ceb1-4ede-abfc-a99411b182ea",
    "outputId": "1c344da1-bed8-44c5-ce38-33f08082fddc"
   },
   "outputs": [],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t0bC5wHRwkWx",
   "metadata": {
    "id": "t0bC5wHRwkWx"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7XcvEocqYOP7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1707464574467,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "7XcvEocqYOP7",
    "outputId": "9bc18e80-e973-4686-9d6e-7d47692cd94e"
   },
   "outputs": [],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FDz-e9CSKaWX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1707464574467,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "FDz-e9CSKaWX",
    "outputId": "b7d5a790-b35f-481b-ddf4-555b741cdcda"
   },
   "outputs": [],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9L26KiTYJUZo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1707464574467,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "9L26KiTYJUZo",
    "outputId": "6b0e5258-1a18-4189-e1f6-5bd97267147f"
   },
   "outputs": [],
   "source": [
    "# ORR for each round:\n",
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hw_mU1Xy9kIw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1707464729109,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "Hw_mU1Xy9kIw",
    "outputId": "0cd8a773-701a-4157-c45b-077b6fb3a6ba"
   },
   "outputs": [],
   "source": [
    "# Overall ORR:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dAeUn1ayxgXH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1707464732953,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "dAeUn1ayxgXH",
    "outputId": "752758fe-be9f-41bd-e1aa-3cb7800ecf48"
   },
   "outputs": [],
   "source": [
    "# Highest ORR:\n",
    "print(np.mean(highest_true_rr))\n",
    "print(np.std(highest_true_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NOSItDYuQwa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1707464739928,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "NOSItDYuQwa8",
    "outputId": "5571d920-11d8-4410-a8f8-fef0974a944c"
   },
   "outputs": [],
   "source": [
    "# Adaptive ORR:\n",
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C703gqxdH6Fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707464574467,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "C703gqxdH6Fd",
    "outputId": "d19ee6b3-62df-4a34-cc1c-88b5e5dcc8d2"
   },
   "outputs": [],
   "source": [
    "# Average plan number for each round:\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P_T2Gb6t9hXq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 189,
     "status": "ok",
     "timestamp": 1707464574652,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "P_T2Gb6t9hXq",
    "outputId": "6f670843-c573-43bd-cedd-6d4bc24eb6a7"
   },
   "outputs": [],
   "source": [
    "# Early stopping probabilities for different reasons:\n",
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W3dHQr2AxzDt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707464574653,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "W3dHQr2AxzDt",
    "outputId": "e6383f95-3a08-44a5-9bbc-b95addf0dd35"
   },
   "outputs": [],
   "source": [
    "# sample size for the last round:\n",
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jSdp6rIVngsj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707464574653,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "jSdp6rIVngsj",
    "outputId": "02bdf413-e3a7-4c13-e083-0fcad16cfd1d"
   },
   "outputs": [],
   "source": [
    "# Probability of better performance compared to the benchmark:\n",
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C1KcRlYqwT5H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707464574653,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "C1KcRlYqwT5H",
    "outputId": "5a9f2a67-773a-4323-dfe5-283420bc829e"
   },
   "outputs": [],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uHSypRgXKNRd",
   "metadata": {
    "id": "uHSypRgXKNRd"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4T8kpJkkKNRf",
   "metadata": {
    "id": "4T8kpJkkKNRf"
   },
   "outputs": [],
   "source": [
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            # ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0))\n",
    "#             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "                    # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "                    ('RF', ensemble.RandomForestClassifier(criterion='gini', random_state=0))\n",
    "                    # ('XGB', XGBClassifier(n_estimators=50, learning_rate=0.1, random_state=0))\n",
    "                   ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "    param_grid = {\n",
    "        # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "        # 'LR__C': [0.01] # [0.01, 0.05, 0.1]\n",
    "        # 'Ridge__C': [0.01]\n",
    "        # 'SVM__C': [0.01, 0.05, 0.1]\n",
    "        'RF__n_estimators': [50] # [10, 30, 50]\n",
    "        # 'XGB__n_estimators': [50]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uVNXr0f9KNRf",
   "metadata": {
    "id": "uVNXr0f9KNRf"
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def ensemble_model_fit(data, data_pred):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         data.drop(['recruitment_plan', 'plan_response_rate', 'group_size','response'], axis=1),\n",
    "#         data['response'],\n",
    "#         test_size=0.2,\n",
    "#         random_state=0\n",
    "#     )\n",
    "\n",
    "#     # Define the Logistic Regression model\n",
    "#     logistic_regression = LogisticRegression(C=0.01, max_iter=200,random_state=0)\n",
    "\n",
    "#     # Fit the Logistic Regression model on the training data\n",
    "#     logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "#     # Print out the coefficients of the logistic regression model\n",
    "#     print(\"Coefficients:\", logistic_regression.coef_)\n",
    "#     print(\"Intercept:\", logistic_regression.intercept_)\n",
    "#     print(\"Coefficients shape:\", logistic_regression.coef_.shape)\n",
    "\n",
    "#     # Predict probabilities instead of binary outcomes on the test set\n",
    "#     y_pred_proba_test = logistic_regression.predict_proba(X_test)\n",
    "#     y_pred_test = logistic_regression.predict(X_test)\n",
    "\n",
    "#     # You can also predict probabilities for the prediction data (data_pred)\n",
    "#     X_dt = data_pred.drop(['recruitment_plan', 'plan_response_rate', 'group_size','response'], axis=1)\n",
    "#     y_pred = logistic_regression.predict_proba(X_dt)\n",
    "\n",
    "#     return y_pred\n",
    "\n",
    "# # Call the function\n",
    "# # ensemble_model_fit(data, data_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0L4C5O0LKNRg",
   "metadata": {
    "id": "0L4C5O0LKNRg"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XaFmXCTbKNRg",
   "metadata": {
    "id": "XaFmXCTbKNRg"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E1DotwS2KNRg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 542845,
     "status": "ok",
     "timestamp": 1707455312537,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "E1DotwS2KNRg",
    "outputId": "768e8c04-6c96-450f-f88c-3c415c9a9d61"
   },
   "outputs": [],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZSYI_uHYKNRh",
   "metadata": {
    "id": "ZSYI_uHYKNRh"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XOOp7mX4KNRh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707455312538,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "XOOp7mX4KNRh",
    "outputId": "4079a555-223e-4303-b5cf-4c8149044368"
   },
   "outputs": [],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UVSfzptULdKK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707455312539,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "UVSfzptULdKK",
    "outputId": "25238bb4-606a-4335-c57e-2a862740e8a6"
   },
   "outputs": [],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZwypDIjzKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707455312539,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "ZwypDIjzKNRi",
    "outputId": "c3f67f52-4e4b-481c-f178-c818e5d49d26"
   },
   "outputs": [],
   "source": [
    "# Average ORR for each round:\n",
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vg_qWpVzKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1707455666262,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "vg_qWpVzKNRi",
    "outputId": "874fb9b7-97f0-4b10-a7aa-66f996462b82"
   },
   "outputs": [],
   "source": [
    "# overall ORR:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "li_BxdgNKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1707455718378,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "li_BxdgNKNRi",
    "outputId": "6c8b96d4-7110-43dd-c8de-19128d835157"
   },
   "outputs": [],
   "source": [
    "# Adaptive learning ORR:\n",
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3TMTjJaKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1707455695027,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "f3TMTjJaKNRi",
    "outputId": "7ffecc55-55c3-4be8-fabb-bbddf7a3e7b2"
   },
   "outputs": [],
   "source": [
    "# Highest True RR:\n",
    "mean_result = (np.mean(highest_true_rr))\n",
    "std_result = (np.std(highest_true_rr))\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ObG-atEyKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1707455738828,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "ObG-atEyKNRi",
    "outputId": "ab0d5c93-6eaf-40f8-f32c-f3f731fdbd2a"
   },
   "outputs": [],
   "source": [
    "# Average plan number at each round:\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PxuuVwAwKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1707455312547,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "PxuuVwAwKNRi",
    "outputId": "9681e922-ac43-44a2-b324-fe62886e31a6"
   },
   "outputs": [],
   "source": [
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mxO9LpGvKNRj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1707455312547,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "mxO9LpGvKNRj",
    "outputId": "56e60500-3374-438a-d590-43247fb17f7a"
   },
   "outputs": [],
   "source": [
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rhySjyfeKNRj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707455312540,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "rhySjyfeKNRj",
    "outputId": "2ba7f5f0-b645-417f-dba0-d2658544dc1e"
   },
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UntkTQE5VJn0",
   "metadata": {
    "id": "UntkTQE5VJn0"
   },
   "outputs": [],
   "source": [
    "# Prob. of better performance compared to the benchmark \n",
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O9EfgKcZKSFo",
   "metadata": {
    "id": "O9EfgKcZKSFo"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4VbKqb3LKSF_",
   "metadata": {
    "id": "4VbKqb3LKSF_"
   },
   "outputs": [],
   "source": [
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            # ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0))\n",
    "#             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "                    # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "#                     ('RF', ensemble.RandomForestClassifier(n_estimators=200, criterion='gini', random_state=0))\n",
    "                    ('XGB', XGBClassifier(n_estimators=50, learning_rate=0.1, random_state=0))\n",
    "                   ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "    param_grid = {\n",
    "        # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "        # 'LR__C': [0.01] # [0.01, 0.05, 0.1]\n",
    "        # 'Ridge__C': [0.01]\n",
    "        # 'SVM__C': [0.01, 0.05, 0.1]\n",
    "#         'RF__n_estimators': [50] # [10, 30, 50]\n",
    "        'XGB__n_estimators': [50]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Rb2RU3mKSGA",
   "metadata": {
    "id": "5Rb2RU3mKSGA"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oh_V6UXxKSGA",
   "metadata": {
    "id": "oh_V6UXxKSGA"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sz63YovEKSGA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sz63YovEKSGA",
    "outputId": "83e71af4-bab4-407d-acfc-1d9e8c90ab74"
   },
   "outputs": [],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TysTqb-hKSGB",
   "metadata": {
    "id": "TysTqb-hKSGB"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3rE5NPrzKSGB",
   "metadata": {
    "id": "3rE5NPrzKSGB"
   },
   "outputs": [],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51GW3qKgLfRz",
   "metadata": {
    "id": "51GW3qKgLfRz"
   },
   "outputs": [],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7BpBmgNvKSGB",
   "metadata": {
    "id": "7BpBmgNvKSGB"
   },
   "outputs": [],
   "source": [
    "# ORR for each round:\n",
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DeeO4i9AKSGB",
   "metadata": {
    "id": "DeeO4i9AKSGB"
   },
   "outputs": [],
   "source": [
    "# Overall ORR:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N_ACdIs4KSGB",
   "metadata": {
    "id": "N_ACdIs4KSGB"
   },
   "outputs": [],
   "source": [
    "# Highest True ORR:\n",
    "print(np.mean(highest_true_rr))\n",
    "print(np.std(highest_true_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azjdUixVKSGB",
   "metadata": {
    "id": "azjdUixVKSGB"
   },
   "outputs": [],
   "source": [
    "# Adaptive learning ORR:\n",
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xe_GmWf7KSGB",
   "metadata": {
    "id": "xe_GmWf7KSGB"
   },
   "outputs": [],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fMmvSSjvKSGB",
   "metadata": {
    "id": "fMmvSSjvKSGB"
   },
   "outputs": [],
   "source": [
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oix1Ryk3KSGB",
   "metadata": {
    "id": "oix1Ryk3KSGB"
   },
   "outputs": [],
   "source": [
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QGhgm_aVKSGB",
   "metadata": {
    "id": "QGhgm_aVKSGB"
   },
   "outputs": [],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5YVfZ2WrL_ug",
   "metadata": {
    "id": "5YVfZ2WrL_ug"
   },
   "outputs": [],
   "source": [
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NHSqkmgoMEov",
   "metadata": {
    "id": "NHSqkmgoMEov"
   },
   "source": [
    "## Ensemble learning - 3 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nf1VuXIFMEo6",
   "metadata": {
    "id": "nf1VuXIFMEo6"
   },
   "outputs": [],
   "source": [
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0)),\n",
    "                    ('RF', ensemble.RandomForestClassifier(criterion='gini', random_state=0)),\n",
    "                    ('XGB', XGBClassifier(learning_rate=0.1, random_state=0))\n",
    "                   ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "    param_grid = {\n",
    "        'LR__C': [0.05],\n",
    "        'RF__n_estimators': [100],\n",
    "        'XGB__n_estimators': [50]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beNEkYR6MEo6",
   "metadata": {
    "id": "beNEkYR6MEo6"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xuzbbQ0wMEo6",
   "metadata": {
    "id": "xuzbbQ0wMEo6"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AB5nx86KMEo6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4315144,
     "status": "ok",
     "timestamp": 1707460937777,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "AB5nx86KMEo6",
    "outputId": "636624e6-c5db-4e85-b5c1-cc50bda3e2f6"
   },
   "outputs": [],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equ-RpwzMEo7",
   "metadata": {
    "id": "equ-RpwzMEo7"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gZTkQ-gRMEo7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1707460937778,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "gZTkQ-gRMEo7",
    "outputId": "ee6ac4ed-2453-4bb8-8bd7-daa4eae37431"
   },
   "outputs": [],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BwsZMji-MEo7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1707460937778,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "BwsZMji-MEo7",
    "outputId": "b3e99081-0184-45c8-fe7c-127c766e4c2e"
   },
   "outputs": [],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eUIMiTdEMEo7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1707460937778,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "eUIMiTdEMEo7",
    "outputId": "a71efab3-afff-4902-e063-4228fbcbb9ef"
   },
   "outputs": [],
   "source": [
    "# orr for each round:\n",
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KetRvXYDMEo7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1707461007981,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "KetRvXYDMEo7",
    "outputId": "9d5eff88-85f6-458b-a364-2d86fc377236"
   },
   "outputs": [],
   "source": [
    "# overall orr:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RbNxS-49MEo8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1707461054722,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "RbNxS-49MEo8",
    "outputId": "05dae317-7ca0-4b86-814a-c36d97b68603"
   },
   "outputs": [],
   "source": [
    "# adaptive learning orr:\n",
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fJ4Sy4igMEo7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1707461031343,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "fJ4Sy4igMEo7",
    "outputId": "5435420b-eaf1-4cb4-a1b2-44f3a62a89e8"
   },
   "outputs": [],
   "source": [
    "# highest true rr:\n",
    "mean_result = (np.mean(highest_true_rr))\n",
    "pristd_result = (np.std(highest_true_rr))\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EwuXO4KlMEo8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1707460937971,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "EwuXO4KlMEo8",
    "outputId": "359acfea-bd68-402d-8bcd-7b2af904a3b9"
   },
   "outputs": [],
   "source": [
    "# average plan number for each round:\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TFLSgDLvMEo8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707460937971,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "TFLSgDLvMEo8",
    "outputId": "03617b0a-dc79-4cfb-83da-83c6e5da4cc3"
   },
   "outputs": [],
   "source": [
    "# early stopping probabilities:\n",
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xxj1uDGnMEo8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707460937971,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "xxj1uDGnMEo8",
    "outputId": "be35c129-da76-4594-a220-b8c0c5bfeb39"
   },
   "outputs": [],
   "source": [
    "# sample size for the last round:\n",
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xSzWgZBMnTe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1707461140686,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "xSzWgZBMnTe6",
    "outputId": "a320702a-e71e-428e-e3be-970351e1d475"
   },
   "outputs": [],
   "source": [
    "# probability of better performance compared to the benchmark:\n",
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bnDgAaq6MEo8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707460937971,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "bnDgAaq6MEo8",
    "outputId": "7f4b4357-3335-4573-ac3b-c74bebdf7741"
   },
   "outputs": [],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43JPK1OrNIH6",
   "metadata": {
    "id": "43JPK1OrNIH6"
   },
   "source": [
    "## Ensemble learning - 7 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wuWSEB4bNIH9",
   "metadata": {
    "id": "wuWSEB4bNIH9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import ensemble, linear_model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan', 'plan_response_rate', 'group_size', 'response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            ('LR', linear_model.LogisticRegression(penalty = 'none', max_iter=200, random_state=0)),\n",
    "            ('Lasso', linear_model.LogisticRegression(penalty = \"l1\", max_iter=200, random_state=0,\n",
    "                                                     solver=\"liblinear\")),\n",
    "            ('Ridge', linear_model.LogisticRegression(penalty = \"l2\", max_iter=200, random_state=0)),\n",
    "            ('GBM', ensemble.GradientBoostingClassifier(random_state=0)),\n",
    "            ('RF', ensemble.RandomForestClassifier(random_state=0)),\n",
    "            ('XGB', XGBClassifier(random_state=0)),\n",
    "            ('NN', MLPClassifier(random_state=0))\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "#     param_grid = {\n",
    "#         'Lasso__C': [0.01, 0.1, 1.0],  # Regularization parameter for lasso regression\n",
    "#         'Ridge__C': [0.01, 0.1, 1.0],  # Regularization parameter for ridge regression\n",
    "#         'GBM__learning_rate': [0.01, 0.1, 0.5],  # Learning rate for gradient boosting machine\n",
    "#         'GBM__n_estimators': [50, 100, 200],  # Number of trees for gradient boosting machine\n",
    "#         'RF__n_estimators': [50, 100, 200],  # Number of trees for random forest\n",
    "#         'XGB__learning_rate': [0.01, 0.1, 0.5],  # Learning rate for XGBoost\n",
    "#         'XGB__n_estimators': [50, 100, 200],  # Number of trees for XGBoost\n",
    "#         'NN__hidden_layer_sizes': [(50,), (100,), (50, 50)],  # Size of hidden layers for neural networks\n",
    "#         'NN__alpha': [0.0001, 0.001, 0.01]  # Regularization parameter for neural networks\n",
    "#     }\n",
    "    param_grid = {\n",
    "        'Lasso__C': [0.1],  # Regularization parameter for lasso regression\n",
    "        'Ridge__C': [0.01],  # Regularization parameter for ridge regression\n",
    "        'GBM__learning_rate': [0.01],  # Learning rate for gradient boosting machine\n",
    "        'GBM__n_estimators': [50],  # Number of trees for gradient boosting machine\n",
    "        'RF__n_estimators': [50],  # Number of trees for random forest\n",
    "        'XGB__learning_rate': [0.01],  # Learning rate for XGBoost\n",
    "        'XGB__n_estimators': [50],  # Number of trees for XGBoost\n",
    "        'NN__hidden_layer_sizes': [(50,)],  # Size of hidden layers for neural networks\n",
    "        'NN__alpha': [0.01]  # Regularization parameter for neural networks\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "#     print(\"Best fit parameters:\", best_params)\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan', 'plan_response_rate', 'group_size', 'response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbefdde-99c5-4258-8b4a-5b49176da445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_model_fit(dt_design_5, dt_design_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ixImG0x4NIH-",
   "metadata": {
    "id": "ixImG0x4NIH-"
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def ensemble_model_fit(data, data_pred):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         data.drop(['recruitment_plan', 'plan_response_rate', 'group_size','response'], axis=1),\n",
    "#         data['response'],\n",
    "#         test_size=0.2,\n",
    "#         random_state=0\n",
    "#     )\n",
    "\n",
    "#     # Define the Logistic Regression model\n",
    "#     logistic_regression = LogisticRegression(C=0.01, max_iter=200,random_state=0)\n",
    "\n",
    "#     # Fit the Logistic Regression model on the training data\n",
    "#     logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "#     # Print out the coefficients of the logistic regression model\n",
    "#     print(\"Coefficients:\", logistic_regression.coef_)\n",
    "#     print(\"Intercept:\", logistic_regression.intercept_)\n",
    "#     print(\"Coefficients shape:\", logistic_regression.coef_.shape)\n",
    "\n",
    "#     # Predict probabilities instead of binary outcomes on the test set\n",
    "#     y_pred_proba_test = logistic_regression.predict_proba(X_test)\n",
    "#     y_pred_test = logistic_regression.predict(X_test)\n",
    "\n",
    "#     # You can also predict probabilities for the prediction data (data_pred)\n",
    "#     X_dt = data_pred.drop(['recruitment_plan', 'plan_response_rate', 'group_size','response'], axis=1)\n",
    "#     y_pred = logistic_regression.predict_proba(X_dt)\n",
    "\n",
    "#     return y_pred\n",
    "\n",
    "# # Call the function\n",
    "# # ensemble_model_fit(data, data_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gXsJYLIiNIH-",
   "metadata": {
    "id": "gXsJYLIiNIH-"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IT4WmJdVNIH-",
   "metadata": {
    "id": "IT4WmJdVNIH-"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6WNHSDDGNIH-",
   "metadata": {
    "id": "6WNHSDDGNIH-"
   },
   "outputs": [],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "highest_true_rr = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    highest_true_rr.append(np.max(dt_design_5['plan_response_rate']))\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, \n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nk18kzKRNIH_",
   "metadata": {
    "id": "nk18kzKRNIH_"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9J1mW4QbNIH_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1707448236231,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "9J1mW4QbNIH_",
    "outputId": "338e681d-1cf5-4fba-cdf9-37d207e4cf10"
   },
   "outputs": [],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6NYOdlLXNIH_",
   "metadata": {
    "id": "6NYOdlLXNIH_"
   },
   "outputs": [],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iu_OS2wcNIH_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1707448237526,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "iu_OS2wcNIH_",
    "outputId": "27d70514-4ac7-40f9-8373-5ed213bdb833"
   },
   "outputs": [],
   "source": [
    "# orr for each round:\n",
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x86hoXfQNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707448339675,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "x86hoXfQNIIA",
    "outputId": "44c42256-3c95-48ff-b6a1-2d7484750b9e"
   },
   "outputs": [],
   "source": [
    "# overall orr:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NoLQzsrsNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1707448339008,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "NoLQzsrsNIIA",
    "outputId": "3e8dab14-08fa-4902-87dd-f18235e86888"
   },
   "outputs": [],
   "source": [
    "# highest true rr:\n",
    "print(np.mean(highest_true_rr))\n",
    "print(np.std(highest_true_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43XsahNUNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1707447643064,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "43XsahNUNIIA",
    "outputId": "d8e676ad-a73e-4e62-f939-ebf6efadaa9e"
   },
   "outputs": [],
   "source": [
    "# adaptive learning orr:\n",
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-vHcWwS5NIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1707448246018,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "-vHcWwS5NIIA",
    "outputId": "7e9f5fc0-3a8c-4472-f0c2-bb0392711f79"
   },
   "outputs": [],
   "source": [
    "# average plan number for each round:\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ICQ_3-9NIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1707448245147,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "4ICQ_3-9NIIA",
    "outputId": "b4a9a3b4-4878-418d-da2f-545cc90cc55b"
   },
   "outputs": [],
   "source": [
    "# early stopping probabilities:\n",
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lpvh9zRkNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1707447645503,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "lpvh9zRkNIIA",
    "outputId": "8d467010-aa11-47ae-85d1-b6e431ff7e3b"
   },
   "outputs": [],
   "source": [
    "# sample size for the last round:\n",
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IT1BZInpNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1707447644111,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "IT1BZInpNIIA",
    "outputId": "05483b1d-c213-419c-c926-cb56090014dd"
   },
   "outputs": [],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7zsQ_p2wNIIA",
   "metadata": {
    "id": "7zsQ_p2wNIIA"
   },
   "outputs": [],
   "source": [
    "# probability of better performance compared to the benchmark:\n",
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb2358-aa3c-4b8c-94fd-6fdbc20860a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b258b-6df4-461c-9f7e-32b460510c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
