{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "87fd3284-5ee0-45bb-92f3-8c737c02e248",
   "metadata": {
    "id": "87fd3284-5ee0-45bb-92f3-8c737c02e248"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from itertools import product\n",
    "from scipy.stats import norm, binomtest\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "\n",
    "from sklearn import linear_model, svm, naive_bayes, ensemble\n",
    "from sklearn.model_selection import cross_validate, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd9b75-9988-49e9-98c2-566a7f57612f",
   "metadata": {
    "id": "0fbd9b75-9988-49e9-98c2-566a7f57612f"
   },
   "source": [
    "## Read functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d83be1f2-3005-425d-981c-1aee03417ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions_scenario2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tKvlxiIUH6fx",
   "metadata": {
    "id": "tKvlxiIUH6fx"
   },
   "source": [
    "## Scenario 2, Case 2 with interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "JT1oO4o7IJwF",
   "metadata": {
    "id": "JT1oO4o7IJwF"
   },
   "outputs": [],
   "source": [
    "def invlogit(p_list):\n",
    "    invlogit_values = []\n",
    "    for p in p_list:\n",
    "        invlogit_values.append(np.exp(p) / (1 + np.exp(p)))\n",
    "\n",
    "    return invlogit_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "uhuynYYgIJwG",
   "metadata": {
    "id": "uhuynYYgIJwG"
   },
   "outputs": [],
   "source": [
    "design_list = [5,8,10]\n",
    "patient_n_list = [5400,680,170] # n_patient_per_plan\n",
    "\n",
    "# def plan_true_rate(row, impact_rates):\n",
    "#     tmp = row * impact_rates\n",
    "#     tmp = tmp[tmp != 0]\n",
    "#     return np.prod(tmp) * 0.05\n",
    "\n",
    "def generate_data_step1(design_number = 5, n_rounds = 4, n_patient_per_plan = 5400, seed=42):\n",
    "\n",
    "  # design_list = [5,8,10]\n",
    "\n",
    "  # Record the start time\n",
    "#   start_time = time.time()\n",
    "\n",
    "  # scenario 2:\n",
    "  random.seed(seed)\n",
    "\n",
    "  # n_design = design_number\n",
    "  n_patient_per_plan_round = n_patient_per_plan/n_rounds # each round is capped by this patient number\n",
    "\n",
    "  # Create all possible combinations of design features\n",
    "  design_combinations = list(product([1, 0], repeat=n_design))\n",
    "\n",
    "  design_feature_df = pd.DataFrame(design_combinations, columns=[f'Design_Feature_{i+1}' for i in range(n_design)])\n",
    "  # add interaction term:\n",
    "  interaction = [1 if row['Design_Feature_1'] + row['Design_Feature_2'] == 2 else 0 for _, row in design_feature_df.iterrows()]\n",
    "  design_feature_df['interaction'] = interaction\n",
    "\n",
    "  design_feature_df['recruitment_plan'] = [x + 1 for x in range(2 ** n_design)]\n",
    "\n",
    "  # design_feature_df\n",
    "  random.seed(seed)\n",
    "  # impact_rates = np.array([random.uniform(0.6, 1.5) for _ in range(n_design)])\n",
    "  impact_rates = np.array([-0.5, 0, 0, 0, 0, 1]) # design 2 has the highest rr\n",
    "  response_rate_list = np.dot(np.array(design_feature_df.iloc[:,:(n_design+1)]), impact_rates)\n",
    "  # normalize to [0,1]\n",
    "  # normalized_values = normalize_to_0_1(response_rate_list) * 0.115\n",
    "  # inverse logit\n",
    "  normalized_values = np.array(invlogit(response_rate_list)) * 0.11\n",
    "  design_feature_df['plan_response_rate'] = normalized_values\n",
    "\n",
    "  design_feature_df.drop(columns=['interaction'], axis = 1, inplace=True)\n",
    "\n",
    "  # Apply plan_true_rate to each row\n",
    "  # result_column = design_feature_df.iloc[:, :n_design].apply(lambda row: plan_true_rate(row, impact_rates), axis=1)\n",
    "\n",
    "  # Add the result_column to the design_feature_df\n",
    "  # design_feature_df['plan_response_rate'] = result_column\n",
    "\n",
    "  # each combination repeat for n_patient_per_plan_round\n",
    "  design_feature_df = pd.DataFrame(np.repeat(design_feature_df.values, n_patient_per_plan_round, axis=0), columns=design_feature_df.columns)\n",
    "\n",
    "  # add response outcome column:\n",
    "  grouped_df = design_feature_df.groupby(list(design_feature_df.columns)).size().reset_index(name='group_size')\n",
    "\n",
    "  random.seed(seed)\n",
    "  random_seeds_for_resp = [random.randint(1, 100000) for _ in range(len(grouped_df))]\n",
    "\n",
    "  def generate_responses(row):\n",
    "      rate = row['plan_response_rate']\n",
    "      num = row['group_size']\n",
    "      # random.seed(42)\n",
    "      seed1 = random_seeds_for_resp[row.name]\n",
    "      np.random.seed(seed1)\n",
    "      return np.random.binomial(n=1, p=rate, size=int(num))\n",
    "\n",
    "  grouped_df['response'] = grouped_df.apply(generate_responses, axis=1)\n",
    "\n",
    "  # Explode the 'response' arrays to expand the DataFrame\n",
    "  expanded_df = grouped_df.explode('response').reset_index(drop=True)\n",
    "  expanded_df['response'] = expanded_df['response'].astype(float)\n",
    "\n",
    "#   end_time = time.time()\n",
    "\n",
    "#   elapsed_time = end_time - start_time\n",
    "\n",
    "#   print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "  return expanded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hJtnGfuuIMr_",
   "metadata": {
    "id": "hJtnGfuuIMr_"
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "zVgytCZXbtpQ",
   "metadata": {
    "id": "zVgytCZXbtpQ"
   },
   "outputs": [],
   "source": [
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0))\n",
    "#             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "                    # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "#                     ('RF', ensemble.RandomForestClassifier(n_estimators=200, criterion='gini', random_state=0))\n",
    "                    # ('XGB', XGBClassifier(n_estimators=50, learning_rate=0.1, random_state=0))\n",
    "                   ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "    param_grid = {\n",
    "        # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "        'LR__C': [0.01, 0.1, 1.0] # [0.01, 0.05, 0.1]\n",
    "        # 'Ridge__C': [0.01]\n",
    "        # 'SVM__C': [0.01, 0.05, 0.1]\n",
    "#         'RF__n_estimators': [50] # [10, 30, 50]\n",
    "        # 'XGB__n_estimators': [50]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0optT4Hwjkte",
   "metadata": {
    "id": "0optT4Hwjkte"
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def ensemble_model_fit(data, data_pred):\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         data.drop(['recruitment_plan', 'plan_response_rate', 'group_size','response'], axis=1),\n",
    "#         data['response'],\n",
    "#         test_size=0.2,\n",
    "#         random_state=0\n",
    "#     )\n",
    "\n",
    "#     # Define the Logistic Regression model\n",
    "#     logistic_regression = LogisticRegression(C=0.01, max_iter=200,random_state=0)\n",
    "\n",
    "#     # Fit the Logistic Regression model on the training data\n",
    "#     logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "#     # Print out the coefficients of the logistic regression model\n",
    "#     print(\"Coefficients:\", logistic_regression.coef_)\n",
    "#     print(\"Intercept:\", logistic_regression.intercept_)\n",
    "#     print(\"Coefficients shape:\", logistic_regression.coef_.shape)\n",
    "\n",
    "#     # Predict probabilities instead of binary outcomes on the test set\n",
    "#     y_pred_proba_test = logistic_regression.predict_proba(X_test)\n",
    "#     y_pred_test = logistic_regression.predict(X_test)\n",
    "\n",
    "#     # You can also predict probabilities for the prediction data (data_pred)\n",
    "#     X_dt = data_pred.drop(['recruitment_plan', 'plan_response_rate', 'group_size','response'], axis=1)\n",
    "#     y_pred = logistic_regression.predict_proba(X_dt)\n",
    "\n",
    "#     return y_pred\n",
    "\n",
    "# # Call the function\n",
    "# # ensemble_model_fit(data, data_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V73u9G9JJkZZ",
   "metadata": {
    "id": "V73u9G9JJkZZ"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "kGy7VUgnz895",
   "metadata": {
    "id": "kGy7VUgnz895"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f0a66c5-ceb1-4ede-abfc-a99411b182ea",
   "metadata": {
    "id": "0f0a66c5-ceb1-4ede-abfc-a99411b182ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['step1_rr: 0', 'step2_rr: 0', 'step3_rr: 0', 'step4_rr: 0', 'step5_rr: 0']\n",
      "empirical response rate 0.05655306495882891\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4240.799240494033\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03145624959349912 0.06349294395987579 0.03203669436637667\n",
      "remaining size for Round 3: 135760\n",
      "Calculated size for Round 3: 7054.0537551469515\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03274560725004911 0.06487887661321948 0.03213326936317037\n",
      "remaining size for Round 4: 128706\n",
      "2\n",
      "['step1_rr: 1', 'step2_rr: 1', 'step3_rr: 1', 'step4_rr: 1', 'step5_rr: 1']\n",
      "empirical response rate 0.054637465690759376\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04284867883572635 0.06421230125649269 0.021363622420766337\n",
      "remaining size for Round 3: 135887\n",
      "Calculated size for Round 3: 6199.105937709977\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03603485531522797 0.07057620432667427 0.0345413490114463\n",
      "remaining size for Round 4: 129688\n",
      "Calculated size for Round 4: 6213.1189058198215\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03515621927412892 0.06978192556479508 0.03462570629066616\n",
      "remaining size for last Round 5: 123475\n",
      "3\n",
      "['step1_rr: 2', 'step2_rr: 2', 'step3_rr: 2', 'step4_rr: 2', 'step5_rr: 2']\n",
      "empirical response rate 0.05303636779505947\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.0337654666507847 0.06778402333074415 0.034018556679959455\n",
      "remaining size for Round 3: 135993\n",
      "4\n",
      "['step1_rr: 3', 'step2_rr: 3', 'step3_rr: 3', 'step4_rr: 3', 'step5_rr: 3']\n",
      "empirical response rate 0.054265782250686186\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "5\n",
      "['step1_rr: 4', 'step2_rr: 4', 'step3_rr: 4', 'step4_rr: 4', 'step5_rr: 4']\n",
      "empirical response rate 0.05772529734675206\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4318.826898633964\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.0566276674270284 0.0681910954817027 0.0115634280546743\n",
      "remaining size for Round 3: 135682\n",
      "Calculated size for Round 3: 6553.845614745704\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02878410114658716 0.06772140761138573 0.03893730646479857\n",
      "remaining size for Round 4: 129129\n",
      "Calculated size for Round 4: 5514.264215597699\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03465372988668418 0.06873941287775938 0.0340856829910752\n",
      "remaining size for last Round 5: 123615\n",
      "6\n",
      "['step1_rr: 5', 'step2_rr: 5', 'step3_rr: 5', 'step4_rr: 5', 'step5_rr: 5']\n",
      "empirical response rate 0.05458028362305581\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.010918454884916867 0.07185341407958279 0.06093495919466592\n",
      "remaining size for Round 3: 135891\n",
      "Calculated size for Round 3: 4957.033805476557\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03224408163702103 0.06557248996002198 0.03332840832300095\n",
      "remaining size for Round 4: 130934\n",
      "7\n",
      "['step1_rr: 6', 'step2_rr: 6', 'step3_rr: 6', 'step4_rr: 6', 'step5_rr: 6']\n",
      "empirical response rate 0.05775388838060384\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4320.7313323598355\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.006188973127500396 0.075307690059244 0.0691187169317436\n",
      "remaining size for Round 3: 135680\n",
      "8\n",
      "['step1_rr: 7', 'step2_rr: 7', 'step3_rr: 7', 'step4_rr: 7', 'step5_rr: 7']\n",
      "empirical response rate 0.05749656907593779\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4303.593688344371\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.04737948495821778 0.0670604466186155 0.01968096166039772\n",
      "remaining size for Round 3: 135697\n",
      "Calculated size for Round 3: 6137.767862794326\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05520366278824519 0.06694306016717344 0.011739397378928249\n",
      "remaining size for Round 4: 129560\n",
      "Calculated size for Round 4: 5774.197670061037\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.01896580402252414 0.07641671483943899 0.05745091081691485\n",
      "remaining size for last Round 5: 123786\n",
      "9\n",
      "['step1_rr: 8', 'step2_rr: 8', 'step3_rr: 8', 'step4_rr: 8', 'step5_rr: 8']\n",
      "empirical response rate 0.0553236505032022\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4159.079338458144\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.01845267816302106 0.05600480526409397 0.037552127101072905\n",
      "remaining size for Round 3: 135841\n",
      "10\n",
      "['step1_rr: 9', 'step2_rr: 9', 'step3_rr: 9', 'step4_rr: 9', 'step5_rr: 9']\n",
      "empirical response rate 0.0536939615736505\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.005620823768613869 0.06861319091118735 0.06299236714257349\n",
      "remaining size for Round 3: 135950\n",
      "11\n",
      "['step1_rr: 10', 'step2_rr: 10', 'step3_rr: 10', 'step4_rr: 10', 'step5_rr: 10']\n",
      "empirical response rate 0.05460887465690759\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.03629009920171225 0.0735820280617789 0.037291928860066645\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 5571.607786178937\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.015450413032497539 0.07511217470050212 0.059661761668004576\n",
      "remaining size for Round 4: 130318\n",
      "12\n",
      "['step1_rr: 11', 'step2_rr: 11', 'step3_rr: 11', 'step4_rr: 11', 'step5_rr: 11']\n",
      "empirical response rate 0.05275045745654163\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 3988.418451118696\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04282278355229486 0.06411524828233969 0.021292464730044834\n",
      "remaining size for Round 3: 136012\n",
      "Calculated size for Round 3: 6233.038925616907\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.019489027633176205 0.07459949395283255 0.05511046631965635\n",
      "remaining size for Round 4: 129779\n",
      "13\n",
      "['step1_rr: 12', 'step2_rr: 12', 'step3_rr: 12', 'step4_rr: 12', 'step5_rr: 12']\n",
      "empirical response rate 0.05626715462031107\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4221.784173594918\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03697471900225886 0.06498711821628714 0.028012399214028275\n",
      "remaining size for Round 3: 135779\n",
      "Calculated size for Round 3: 6228.637095402568\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03602139789254266 0.07096355932614243 0.03494216143359977\n",
      "remaining size for Round 4: 129551\n",
      "Calculated size for Round 4: 6094.221849167555\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03757267806364218 0.07589719892769348 0.0383245208640513\n",
      "remaining size for last Round 5: 123457\n",
      "14\n",
      "['step1_rr: 13', 'step2_rr: 13', 'step3_rr: 13', 'step4_rr: 13', 'step5_rr: 13']\n",
      "empirical response rate 0.05466605672461116\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03335816925473581 0.06684853436263313 0.033490365107897324\n",
      "remaining size for Round 3: 135885\n",
      "Calculated size for Round 3: 5537.56151432847\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.029385986777006705 0.07141162488415054 0.04202563810714383\n",
      "remaining size for Round 4: 130348\n",
      "Calculated size for Round 4: 6611.232678603852\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03668697448288484 0.07249513480025088 0.03580816031736604\n",
      "remaining size for last Round 5: 123737\n",
      "15\n",
      "['step1_rr: 14', 'step2_rr: 14', 'step3_rr: 14', 'step4_rr: 14', 'step5_rr: 14']\n",
      "empirical response rate 0.05375114364135407\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.022182138332619363 0.06629968447901155 0.044117546146392184\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 5263.305133252926\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03298839476644137 0.06667332114627122 0.03368492637982985\n",
      "remaining size for Round 4: 130683\n",
      "Calculated size for Round 4: 6564.752236529791\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.034392293215473164 0.06821549616447639 0.03382320294900323\n",
      "remaining size for last Round 5: 124119\n",
      "16\n",
      "['step1_rr: 15', 'step2_rr: 15', 'step3_rr: 15', 'step4_rr: 15', 'step5_rr: 15']\n",
      "empirical response rate 0.05466605672461116\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.02091647760688436 0.0628083961387334 0.04189191853184904\n",
      "remaining size for Round 3: 135885\n",
      "17\n",
      "['step1_rr: 16', 'step2_rr: 16', 'step3_rr: 16', 'step4_rr: 16', 'step5_rr: 16']\n",
      "empirical response rate 0.05595265324794144\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02514377703431816 0.0634720006808119 0.038328223646493735\n",
      "remaining size for Round 3: 135800\n",
      "Calculated size for Round 3: 5582.264421050326\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.052135718350334426 0.07041819707218812 0.018282478721853693\n",
      "remaining size for Round 4: 130218\n",
      "Calculated size for Round 4: 6685.189142058586\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.024386569322759514 0.07137107645476708 0.046984507132007566\n",
      "remaining size for last Round 5: 123533\n",
      "18\n",
      "['step1_rr: 17', 'step2_rr: 17', 'step3_rr: 17', 'step4_rr: 17', 'step5_rr: 17']\n",
      "empirical response rate 0.05480901189387008\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4124.9058208503975\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03473260603155418 0.06932681629130175 0.034594210259747564\n",
      "remaining size for Round 3: 135876\n",
      "Calculated size for Round 3: 6028.919086897068\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.01899514804640903 0.07405155037139742 0.05505640232498839\n",
      "remaining size for Round 4: 129848\n",
      "19\n",
      "['step1_rr: 18', 'step2_rr: 18', 'step3_rr: 18', 'step4_rr: 18', 'step5_rr: 18']\n",
      "empirical response rate 0.05598124428179323\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.0607733889512444 0.06781171194308107 0.007038322991836668\n",
      "remaining size for Round 3: 135798\n",
      "Calculated size for Round 3: 5683.114627996356\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.061467149697026435 0.06801180900709913 0.006544659310072698\n",
      "remaining size for Round 4: 130115\n",
      "Calculated size for Round 4: 5456.37637220965\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03469754017619066 0.0669363797929558 0.032238839616765144\n",
      "remaining size for last Round 5: 124659\n",
      "20\n",
      "['step1_rr: 19', 'step2_rr: 19', 'step3_rr: 19', 'step4_rr: 19', 'step5_rr: 19']\n",
      "empirical response rate 0.05489478499542543\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.033310899323225035 0.06684808065609628 0.033537181332871244\n",
      "remaining size for Round 3: 135870\n",
      "Calculated size for Round 3: 5763.422505418232\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05282885130162042 0.06973757831305456 0.016908727011434144\n",
      "remaining size for Round 4: 130107\n",
      "Calculated size for Round 4: 6639.2088350707245\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.02388350694298715 0.07269873753955665 0.0488152305965695\n",
      "remaining size for last Round 5: 123468\n",
      "21\n",
      "['step1_rr: 20', 'step2_rr: 20', 'step3_rr: 20', 'step4_rr: 20', 'step5_rr: 20']\n",
      "empirical response rate 0.05486619396157365\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4128.701861019453\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.03507416232785836 0.07030993936967583 0.035235777041817476\n",
      "remaining size for Round 3: 135872\n",
      "Calculated size for Round 3: 5454.584226495059\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05436965718764321 0.06694838477116248 0.012578727583519272\n",
      "remaining size for Round 4: 130418\n",
      "Calculated size for Round 4: 6180.819025513669\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03459096048431274 0.07020814669386886 0.035617186209556125\n",
      "remaining size for last Round 5: 124238\n",
      "22\n",
      "['step1_rr: 21', 'step2_rr: 21', 'step3_rr: 21', 'step4_rr: 21', 'step5_rr: 21']\n",
      "empirical response rate 0.05518069533394328\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.03258849852147397 0.0768959874025818 0.04430748888110783\n",
      "remaining size for Round 3: 135851\n",
      "Calculated size for Round 3: 7078.104089533953\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.024475592061074043 0.07522122664212605 0.05074563458105201\n",
      "remaining size for Round 4: 128773\n",
      "23\n",
      "['step1_rr: 22', 'step2_rr: 22', 'step3_rr: 22', 'step4_rr: 22', 'step5_rr: 22']\n",
      "empirical response rate 0.054780420860018296\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02342572719598416 0.06604155865395127 0.04261583145796711\n",
      "remaining size for Round 3: 135877\n",
      "Calculated size for Round 3: 4979.026114458517\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.04231001467220155 0.0709719167502108 0.028661902078009255\n",
      "remaining size for Round 4: 130898\n",
      "Calculated size for Round 4: 6957.9955838901315\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.045179362941523714 0.06835249167150118 0.02317312872997746\n",
      "remaining size for last Round 5: 123941\n",
      "24\n",
      "['step1_rr: 23', 'step2_rr: 23', 'step3_rr: 23', 'step4_rr: 23', 'step5_rr: 23']\n",
      "empirical response rate 0.05415141811527905\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04505581131404279 0.06726326926537285 0.022207457951330056\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 8370.50974645775\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.0334699908130509 0.06488572928330831 0.03141573847025741\n",
      "remaining size for Round 4: 127549\n",
      "25\n",
      "['step1_rr: 24', 'step2_rr: 24', 'step3_rr: 24', 'step4_rr: 24', 'step5_rr: 24']\n",
      "empirical response rate 0.05400846294602013\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.019738296976954287 0.059439235700898055 0.03970093872394377\n",
      "remaining size for Round 3: 135929\n",
      "26\n",
      "['step1_rr: 25', 'step2_rr: 25', 'step3_rr: 25', 'step4_rr: 25', 'step5_rr: 25']\n",
      "empirical response rate 0.056038426349496795\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4206.576669795643\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.012279113929764537 0.06483718571483546 0.05255807178507092\n",
      "remaining size for Round 3: 135794\n",
      "Calculated size for Round 3: 5160.85244002046\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.032584647429328546 0.06535287086698241 0.032768223437653864\n",
      "remaining size for Round 4: 130634\n",
      "27\n",
      "['step1_rr: 26', 'step2_rr: 26', 'step3_rr: 26', 'step4_rr: 26', 'step5_rr: 26']\n",
      "empirical response rate 0.05377973467520585\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.035638172023783096 0.07105744881927073 0.035419276795487634\n",
      "remaining size for Round 3: 135944\n",
      "Calculated size for Round 3: 7787.47350091209\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.037244207412329554 0.07288055641604757 0.03563634900371802\n",
      "remaining size for Round 4: 128157\n",
      "28\n",
      "['step1_rr: 27', 'step2_rr: 27', 'step3_rr: 27', 'step4_rr: 27', 'step5_rr: 27']\n",
      "empirical response rate 0.0529791857273559\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4003.567322548448\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.015895918267092028 0.06462745782300051 0.04873153955590849\n",
      "remaining size for Round 3: 135997\n",
      "29\n",
      "['step1_rr: 28', 'step2_rr: 28', 'step3_rr: 28', 'step4_rr: 28', 'step5_rr: 28']\n",
      "empirical response rate 0.05312214089661482\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4013.037453633404\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.035309314910309614 0.053240305503364733 0.01793099059305512\n",
      "remaining size for Round 3: 135987\n",
      "Calculated size for Round 3: 6539.083262677942\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.033930728432906086 0.06637547087681474 0.03244474244390865\n",
      "remaining size for Round 4: 129448\n",
      "30\n",
      "['step1_rr: 29', 'step2_rr: 29', 'step3_rr: 29', 'step4_rr: 29', 'step5_rr: 29']\n",
      "empirical response rate 0.054837602927721864\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.03004581822931362 0.06896839862037868 0.03892258039106506\n",
      "remaining size for Round 3: 135874\n",
      "Calculated size for Round 3: 5266.917783889707\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.012452321335012492 0.07227191104326469 0.0598195897082522\n",
      "remaining size for Round 4: 130608\n",
      "31\n",
      "['step1_rr: 30', 'step2_rr: 30', 'step3_rr: 30', 'step4_rr: 30', 'step5_rr: 30']\n",
      "empirical response rate 0.05518069533394328\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.03676306079217381 0.06731421453305567 0.030551153740881853\n",
      "remaining size for Round 3: 135851\n",
      "Calculated size for Round 3: 5488.020541830489\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04003241555866185 0.06431498537469998 0.024282569816038137\n",
      "remaining size for Round 4: 130363\n",
      "Calculated size for Round 4: 5687.724715428306\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04630304321333899 0.0709324230754732 0.024629379862134218\n",
      "remaining size for last Round 5: 124676\n",
      "32\n",
      "['step1_rr: 31', 'step2_rr: 31', 'step3_rr: 31', 'step4_rr: 31', 'step5_rr: 31']\n",
      "empirical response rate 0.05435155535224154\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4094.5466697157462\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.0059709716951798 0.07447877086285352 0.06850779916767373\n",
      "remaining size for Round 3: 135906\n",
      "33\n",
      "['step1_rr: 32', 'step2_rr: 32', 'step3_rr: 32', 'step4_rr: 32', 'step5_rr: 32']\n",
      "empirical response rate 0.05332227813357731\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4026.2983311032726\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.00624924878280834 0.07231982974377996 0.06607058096097161\n",
      "remaining size for Round 3: 135974\n",
      "34\n",
      "['step1_rr: 33', 'step2_rr: 33', 'step3_rr: 33', 'step4_rr: 33', 'step5_rr: 33']\n",
      "empirical response rate 0.05375114364135407\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.057463047997257655 0.06808329758284946 0.01062024958559181\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 6339.325528231618\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.05822655830656289 0.0677280849467228 0.009501526640159914\n",
      "remaining size for Round 4: 129607\n",
      "Calculated size for Round 4: 5690.148658241525\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.014333647567730262 0.0706787045434407 0.05634505697571044\n",
      "remaining size for last Round 5: 123917\n",
      "35\n",
      "['step1_rr: 34', 'step2_rr: 34', 'step3_rr: 34', 'step4_rr: 34', 'step5_rr: 34']\n",
      "empirical response rate 0.054637465690759376\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.03788123187624859 0.05681981560110398 0.018938583724855393\n",
      "remaining size for Round 3: 135887\n",
      "Calculated size for Round 3: 6782.593947375342\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.029533808937370253 0.05970238580614068 0.030168576868770426\n",
      "remaining size for Round 4: 129105\n",
      "36\n",
      "['step1_rr: 35', 'step2_rr: 35', 'step3_rr: 35', 'step4_rr: 35', 'step5_rr: 35']\n",
      "empirical response rate 0.05669602012808783\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4250.309141054068\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.024751064637863626 0.06218810053753355 0.03743703589966992\n",
      "remaining size for Round 3: 135750\n",
      "Calculated size for Round 3: 5986.623109395045\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.032428439336790876 0.06555380578290315 0.033125366446112275\n",
      "remaining size for Round 4: 129764\n",
      "37\n",
      "['step1_rr: 36', 'step2_rr: 36', 'step3_rr: 36', 'step4_rr: 36', 'step5_rr: 36']\n",
      "empirical response rate 0.05600983531564501\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4204.676016429063\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.01757974313677671 0.06888750629046066 0.05130776315368395\n",
      "remaining size for Round 3: 135796\n",
      "Calculated size for Round 3: 5391.5063355915845\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04877179680862316 0.07252700421702685 0.023755207408403686\n",
      "remaining size for Round 4: 130405\n",
      "Calculated size for Round 4: 7774.725088680245\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03396592905359832 0.06876706213841866 0.034801133084820336\n",
      "remaining size for last Round 5: 122631\n",
      "38\n",
      "['step1_rr: 37', 'step2_rr: 37', 'step3_rr: 37', 'step4_rr: 37', 'step5_rr: 37']\n",
      "empirical response rate 0.05458028362305581\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.018522266868652236 0.07427770815889025 0.05575544129023801\n",
      "remaining size for Round 3: 135891\n",
      "Calculated size for Round 3: 5534.404147064938\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04718952719526763 0.07008995145007674 0.022900424254809107\n",
      "remaining size for Round 4: 130357\n",
      "Calculated size for Round 4: 7905.114057774291\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.033544990849319896 0.0671413396533675 0.0335963488040476\n",
      "remaining size for last Round 5: 122452\n",
      "39\n",
      "['step1_rr: 38', 'step2_rr: 38', 'step3_rr: 38', 'step4_rr: 38', 'step5_rr: 38']\n",
      "empirical response rate 0.05535224153705398\n",
      "{'LR__C': 1.0}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4160.97847079396\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03578419716648553 0.07058814878016195 0.03480395161367642\n",
      "remaining size for Round 3: 135840\n",
      "Calculated size for Round 3: 7887.491717640237\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03728077321794565 0.07433180338434817 0.037051030166402515\n",
      "remaining size for Round 4: 127953\n",
      "40\n",
      "['step1_rr: 39', 'step2_rr: 39', 'step3_rr: 39', 'step4_rr: 39', 'step5_rr: 39']\n",
      "empirical response rate 0.05489478499542543\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.05612910928771692 0.06768088570910955 0.011551776421392622\n",
      "remaining size for Round 3: 135870\n",
      "Calculated size for Round 3: 6593.261948333312\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.042671474710225976 0.06839457732934018 0.025723102619114202\n",
      "remaining size for Round 4: 129277\n",
      "Calculated size for Round 4: 5803.81421809859\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.024721748456310786 0.07225048021273471 0.04752873175642393\n",
      "remaining size for last Round 5: 123474\n",
      "41\n",
      "['step1_rr: 40', 'step2_rr: 40', 'step3_rr: 40', 'step4_rr: 40', 'step5_rr: 40']\n",
      "empirical response rate 0.05529505946935041\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4157.18026960777\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02663807909657908 0.053387900039918584 0.026749820943339504\n",
      "remaining size for Round 3: 135843\n",
      "42\n",
      "['step1_rr: 41', 'step2_rr: 41', 'step3_rr: 41', 'step4_rr: 41', 'step5_rr: 41']\n",
      "empirical response rate 0.05363677950594693\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03560679279391549 0.07131844718122754 0.03571165438731205\n",
      "remaining size for Round 3: 135953\n",
      "43\n",
      "['step1_rr: 42', 'step2_rr: 42', 'step3_rr: 42', 'step4_rr: 42', 'step5_rr: 42']\n",
      "empirical response rate 0.05377973467520585\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03741667754351408 0.07491014079176016 0.037493463248246074\n",
      "remaining size for Round 3: 135944\n",
      "44\n",
      "['step1_rr: 43', 'step2_rr: 43', 'step3_rr: 43', 'step4_rr: 43', 'step5_rr: 43']\n",
      "empirical response rate 0.05583828911253431\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4193.273425323935\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03229425856140293 0.06544601907697337 0.033151760515570436\n",
      "remaining size for Round 3: 135807\n",
      "45\n",
      "['step1_rr: 44', 'step2_rr: 44', 'step3_rr: 44', 'step4_rr: 44', 'step5_rr: 44']\n",
      "empirical response rate 0.05555237877401647\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4174.274174005051\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.010718370734851556 0.07134516662349116 0.060626795888639604\n",
      "remaining size for Round 3: 135826\n",
      "Calculated size for Round 3: 5093.628848467482\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03703260627700405 0.07546430368323864 0.038431697406234595\n",
      "remaining size for Round 4: 130733\n",
      "46\n",
      "['step1_rr: 45', 'step2_rr: 45', 'step3_rr: 45', 'step4_rr: 45', 'step5_rr: 45']\n",
      "empirical response rate 0.0536939615736505\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04288545188449965 0.06810725303712085 0.025221801152621202\n",
      "remaining size for Round 3: 135950\n",
      "Calculated size for Round 3: 5989.862014903634\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.05785014908299949 0.07146491732733765 0.013614768244338153\n",
      "remaining size for Round 4: 129961\n",
      "Calculated size for Round 4: 6311.63314837037\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05176416390350012 0.06914569260728005 0.017381528703779937\n",
      "remaining size for last Round 5: 123650\n",
      "47\n",
      "['step1_rr: 46', 'step2_rr: 46', 'step3_rr: 46', 'step4_rr: 46', 'step5_rr: 46']\n",
      "empirical response rate 0.05449451052150046\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4104.032152159118\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.031648279626521815 0.06350026000138781 0.031851980374865994\n",
      "remaining size for Round 3: 135896\n",
      "Calculated size for Round 3: 5949.185795839282\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.047886258653454944 0.06886697886585269 0.020980720212397747\n",
      "remaining size for Round 4: 129947\n",
      "Calculated size for Round 4: 6444.409890944068\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.034716093850737845 0.0679767262952546 0.033260632444516755\n",
      "remaining size for last Round 5: 123503\n",
      "48\n",
      "['step1_rr: 47', 'step2_rr: 47', 'step3_rr: 47', 'step4_rr: 47', 'step5_rr: 47']\n",
      "empirical response rate 0.055380832570905765\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03985867427534459 0.07918669268843871 0.03932801841309412\n",
      "remaining size for Round 3: 135838\n",
      "Calculated size for Round 3: 9484.739300214818\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03378907063798118 0.06884252281961911 0.03505345218163793\n",
      "remaining size for Round 4: 126354\n",
      "49\n",
      "['step1_rr: 48', 'step2_rr: 48', 'step3_rr: 48', 'step4_rr: 48', 'step5_rr: 48']\n",
      "empirical response rate 0.0554951967063129\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4170.4750844497285\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.022266161180593793 0.06689538787944171 0.04462922669884792\n",
      "remaining size for Round 3: 135830\n",
      "Calculated size for Round 3: 5036.104514255987\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.01763977356038052 0.07222876349755263 0.05458898993717211\n",
      "remaining size for Round 4: 130794\n",
      "50\n",
      "['step1_rr: 49', 'step2_rr: 49', 'step3_rr: 49', 'step4_rr: 49', 'step5_rr: 49']\n",
      "empirical response rate 0.05563815187557182\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4179.973283933777\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.027937631262913813 0.05527486538545932 0.027337234122545503\n",
      "remaining size for Round 3: 135821\n",
      "51\n",
      "['step1_rr: 50', 'step2_rr: 50', 'step3_rr: 50', 'step4_rr: 50', 'step5_rr: 50']\n",
      "empirical response rate 0.05586688014638609\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4195.17369890541\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.01129324574960135 0.06368718334974599 0.052393937600144644\n",
      "remaining size for Round 3: 135805\n",
      "Calculated size for Round 3: 5066.1138723883805\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.033783586861165005 0.06742973189886922 0.03364614503770422\n",
      "remaining size for Round 4: 130739\n",
      "52\n",
      "['step1_rr: 51', 'step2_rr: 51', 'step3_rr: 51', 'step4_rr: 51', 'step5_rr: 51']\n",
      "empirical response rate 0.055809698078682524\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.028988827378353885 0.05793524125343504 0.028946413875081158\n",
      "remaining size for Round 3: 135809\n",
      "53\n",
      "['step1_rr: 52', 'step2_rr: 52', 'step3_rr: 52', 'step4_rr: 52', 'step5_rr: 52']\n",
      "empirical response rate 0.05661024702653248\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4244.60301145521\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.037292688780083454 0.07429563352870161 0.037002944748618156\n",
      "remaining size for Round 3: 135756\n",
      "Calculated size for Round 3: 6058.496483823337\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.02047919658301617 0.07750670927229557 0.0570275126892794\n",
      "remaining size for Round 4: 129698\n",
      "54\n",
      "['step1_rr: 53', 'step2_rr: 53', 'step3_rr: 53', 'step4_rr: 53', 'step5_rr: 53']\n",
      "empirical response rate 0.054837602927721864\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.05688093138468732 0.07086692596209536 0.01398599457740804\n",
      "remaining size for Round 3: 135874\n",
      "Calculated size for Round 3: 5906.505452748003\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03526091107914414 0.06929174601423259 0.03403083493508845\n",
      "remaining size for Round 4: 129968\n",
      "Calculated size for Round 4: 5670.9567881750345\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.017677370826904435 0.07059640680770941 0.05291903598080498\n",
      "remaining size for last Round 5: 124298\n",
      "55\n",
      "['step1_rr: 54', 'step2_rr: 54', 'step3_rr: 54', 'step4_rr: 54', 'step5_rr: 54']\n",
      "empirical response rate 0.05323650503202196\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4020.614713204558\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.034596971427661403 0.06929655873186576 0.03469958730420435\n",
      "remaining size for Round 3: 135980\n",
      "56\n",
      "['step1_rr: 55', 'step2_rr: 55', 'step3_rr: 55', 'step4_rr: 55', 'step5_rr: 55']\n",
      "empirical response rate 0.054780420860018296\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02660945400663099 0.05249658930609141 0.025887135299460424\n",
      "remaining size for Round 3: 135877\n",
      "57\n",
      "['step1_rr: 56', 'step2_rr: 56', 'step3_rr: 56', 'step4_rr: 56', 'step5_rr: 56']\n",
      "empirical response rate 0.05446591948764867\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4102.134928162425\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05221680309761988 0.06967825348008497 0.01746145038246509\n",
      "remaining size for Round 3: 135898\n",
      "Calculated size for Round 3: 8426.618478403469\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05041996063171298 0.07361121521418879 0.023191254582475805\n",
      "remaining size for Round 4: 127472\n",
      "Calculated size for Round 4: 6295.835439529324\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03793684861206622 0.07411091102301878 0.036174062410952564\n",
      "remaining size for last Round 5: 121177\n",
      "58\n",
      "['step1_rr: 57', 'step2_rr: 57', 'step3_rr: 57', 'step4_rr: 57', 'step5_rr: 57']\n",
      "empirical response rate 0.053979871912168347\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4069.8918802880116\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03751424090146991 0.07509726164652207 0.03758302074505216\n",
      "remaining size for Round 3: 135931\n",
      "59\n",
      "['step1_rr: 58', 'step2_rr: 58', 'step3_rr: 58', 'step4_rr: 58', 'step5_rr: 58']\n",
      "empirical response rate 0.05546660567246112\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4168.575634817409\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03387355477560568 0.06752235400661384 0.033648799231008164\n",
      "remaining size for Round 3: 135832\n",
      "Calculated size for Round 3: 6004.854545614174\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.017210492901623926 0.06997279746889352 0.0527623045672696\n",
      "remaining size for Round 4: 129828\n",
      "60\n",
      "['step1_rr: 59', 'step2_rr: 59', 'step3_rr: 59', 'step4_rr: 59', 'step5_rr: 59']\n",
      "empirical response rate 0.05498055809698079\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4136.294704781159\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.013040717813863963 0.07178220622216978 0.05874148840830582\n",
      "remaining size for Round 3: 135864\n",
      "Calculated size for Round 3: 5347.7864628242\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03633631045335153 0.07425353324522133 0.0379172227918698\n",
      "remaining size for Round 4: 130517\n",
      "61\n",
      "['step1_rr: 60', 'step2_rr: 60', 'step3_rr: 60', 'step4_rr: 60', 'step5_rr: 60']\n",
      "empirical response rate 0.055895471180237875\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4197.074035806328\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.013187621696635947 0.06704768792568411 0.05386006622904816\n",
      "remaining size for Round 3: 135803\n",
      "Calculated size for Round 3: 5146.591781136348\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.034164984997643165 0.06886059813259401 0.03469561313495085\n",
      "remaining size for Round 4: 130657\n",
      "62\n",
      "['step1_rr: 61', 'step2_rr: 61', 'step3_rr: 61', 'step4_rr: 61', 'step5_rr: 61']\n",
      "empirical response rate 0.05312214089661482\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4013.037453633404\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02788883101743718 0.0556493834756221 0.02776055245818492\n",
      "remaining size for Round 3: 135987\n",
      "63\n",
      "['step1_rr: 62', 'step2_rr: 62', 'step3_rr: 62', 'step4_rr: 62', 'step5_rr: 62']\n",
      "empirical response rate 0.05689615736505032\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4263.625650278873\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.010509355954959144 0.07317385014429933 0.0626644941893402\n",
      "remaining size for Round 3: 135737\n",
      "Calculated size for Round 3: 5187.060786898692\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.034171902321426674 0.06774466453643219 0.03357276221500551\n",
      "remaining size for Round 4: 130550\n",
      "64\n",
      "['step1_rr: 63', 'step2_rr: 63', 'step3_rr: 63', 'step4_rr: 63', 'step5_rr: 63']\n",
      "empirical response rate 0.05458028362305581\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.016322573803775584 0.0648452927331688 0.04852271892939322\n",
      "remaining size for Round 3: 135891\n",
      "65\n",
      "['step1_rr: 64', 'step2_rr: 64', 'step3_rr: 64', 'step4_rr: 64', 'step5_rr: 64']\n",
      "empirical response rate 0.05592406221408966\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03182561265318274 0.06365264516572092 0.03182703251253818\n",
      "remaining size for Round 3: 135802\n",
      "66\n",
      "['step1_rr: 65', 'step2_rr: 65', 'step3_rr: 65', 'step4_rr: 65', 'step5_rr: 65']\n",
      "empirical response rate 0.05598124428179323\n",
      "{'LR__C': 1.0}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.009353410045391747 0.07434070288099312 0.06498729283560137\n",
      "remaining size for Round 3: 135798\n",
      "67\n",
      "['step1_rr: 66', 'step2_rr: 66', 'step3_rr: 66', 'step4_rr: 66', 'step5_rr: 66']\n",
      "empirical response rate 0.056781793229643183\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4256.015838229115\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.01390874865498583 0.07485682770272037 0.06094807904773454\n",
      "remaining size for Round 3: 135744\n",
      "Calculated size for Round 3: 5311.453058451149\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.0359803885430401 0.0745106294679657 0.0385302409249256\n",
      "remaining size for Round 4: 130433\n",
      "68\n",
      "['step1_rr: 67', 'step2_rr: 67', 'step3_rr: 67', 'step4_rr: 67', 'step5_rr: 67']\n",
      "empirical response rate 0.05609560841720036\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4210.378166320425\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.02144696818739162 0.07309083064178232 0.0516438624543907\n",
      "remaining size for Round 3: 135790\n",
      "Calculated size for Round 3: 5653.301749063315\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.04811896233545361 0.07307732617990634 0.024958363844452727\n",
      "remaining size for Round 4: 130137\n",
      "Calculated size for Round 4: 7600.948489412965\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03914755165404615 0.07366663192487967 0.034519080270833516\n",
      "remaining size for last Round 5: 122537\n",
      "69\n",
      "['step1_rr: 68', 'step2_rr: 68', 'step3_rr: 68', 'step4_rr: 68', 'step5_rr: 68']\n",
      "empirical response rate 0.05486619396157365\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4128.701861019453\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.028079420185471528 0.05610879510114899 0.02802937491567746\n",
      "remaining size for Round 3: 135872\n",
      "70\n",
      "['step1_rr: 69', 'step2_rr: 69', 'step3_rr: 69', 'step4_rr: 69', 'step5_rr: 69']\n",
      "empirical response rate 0.05363677950594693\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.05297790673098304 0.06587068818923984 0.0128927814582568\n",
      "remaining size for Round 3: 135953\n",
      "Calculated size for Round 3: 5206.52916150175\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03449189895877294 0.06976762946838896 0.03527573050961602\n",
      "remaining size for Round 4: 130747\n",
      "Calculated size for Round 4: 5318.0785305237505\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.017785134289837592 0.06937450862112465 0.05158937433128706\n",
      "remaining size for last Round 5: 125429\n",
      "71\n",
      "['step1_rr: 70', 'step2_rr: 70', 'step3_rr: 70', 'step4_rr: 70', 'step5_rr: 70']\n",
      "empirical response rate 0.055809698078682524\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.022925032406748938 0.06786086412375092 0.04493583171700198\n",
      "remaining size for Round 3: 135809\n",
      "Calculated size for Round 3: 5310.250718021933\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.018938538418674933 0.0753623879763845 0.05642384955770957\n",
      "remaining size for Round 4: 130499\n",
      "72\n",
      "['step1_rr: 71', 'step2_rr: 71', 'step3_rr: 71', 'step4_rr: 71', 'step5_rr: 71']\n",
      "empirical response rate 0.05592406221408966\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.016012056779877222 0.07061515348476323 0.05460309670488601\n",
      "remaining size for Round 3: 135802\n",
      "Calculated size for Round 3: 5210.91453012291\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02575701058154053 0.076783067399121 0.05102605681758046\n",
      "remaining size for Round 4: 130592\n",
      "73\n",
      "['step1_rr: 72', 'step2_rr: 72', 'step3_rr: 72', 'step4_rr: 72', 'step5_rr: 72']\n",
      "empirical response rate 0.05721065873741994\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4284.557829370903\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03609602131375423 0.07302133518527669 0.03692531387152246\n",
      "remaining size for Round 3: 135716\n",
      "74\n",
      "['step1_rr: 73', 'step2_rr: 73', 'step3_rr: 73', 'step4_rr: 73', 'step5_rr: 73']\n",
      "empirical response rate 0.05572392497712717\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03319920880910898 0.0664440705148682 0.033244861705759216\n",
      "remaining size for Round 3: 135815\n",
      "Calculated size for Round 3: 6861.281394245931\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03532867158100521 0.0699547457047057 0.03462607412370049\n",
      "remaining size for Round 4: 128954\n",
      "75\n",
      "['step1_rr: 74', 'step2_rr: 74', 'step3_rr: 74', 'step4_rr: 74', 'step5_rr: 74']\n",
      "empirical response rate 0.056724611161939616\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "76\n",
      "['step1_rr: 75', 'step2_rr: 75', 'step3_rr: 75', 'step4_rr: 75', 'step5_rr: 75']\n",
      "empirical response rate 0.053979871912168347\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4069.8918802880116\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03839386291569943 0.06131612867675832 0.022922265761058894\n",
      "remaining size for Round 3: 135931\n",
      "Calculated size for Round 3: 5457.783848435716\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.03067677883394748 0.07104105732925092 0.04036427849530344\n",
      "remaining size for Round 4: 130474\n",
      "Calculated size for Round 4: 5524.898632877159\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03512881207334249 0.07288531325778534 0.037756501184442855\n",
      "remaining size for last Round 5: 124950\n",
      "77\n",
      "['step1_rr: 76', 'step2_rr: 76', 'step3_rr: 76', 'step4_rr: 76', 'step5_rr: 76']\n",
      "empirical response rate 0.05618138151875572\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4216.080885454846\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.037891077617823836 0.06793279907413681 0.030041721456312974\n",
      "remaining size for Round 3: 135784\n",
      "Calculated size for Round 3: 5836.721599018012\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.057318230157641925 0.07129417195066648 0.013975941793024554\n",
      "remaining size for Round 4: 129948\n",
      "Calculated size for Round 4: 6424.257012882614\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05302834426014143 0.07026735868257786 0.01723901442243643\n",
      "remaining size for last Round 5: 123524\n",
      "78\n",
      "['step1_rr: 77', 'step2_rr: 77', 'step3_rr: 77', 'step4_rr: 77', 'step5_rr: 77']\n",
      "empirical response rate 0.05303636779505947\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.017519675746336193 0.06870591710198608 0.051186241355649885\n",
      "remaining size for Round 3: 135993\n",
      "Calculated size for Round 3: 5689.51967087966\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.035368269801314176 0.07007946080576517 0.034711191004451\n",
      "remaining size for Round 4: 130304\n",
      "79\n",
      "['step1_rr: 78', 'step2_rr: 78', 'step3_rr: 78', 'step4_rr: 78', 'step5_rr: 78']\n",
      "empirical response rate 0.054923376029277216\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4132.498155686146\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.035567623779595645 0.07117415012041307 0.03560652634081743\n",
      "remaining size for Round 3: 135868\n",
      "80\n",
      "['step1_rr: 79', 'step2_rr: 79', 'step3_rr: 79', 'step4_rr: 79', 'step5_rr: 79']\n",
      "empirical response rate 0.05415141811527905\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.040234079164399236 0.06025570397495536 0.020021624810556124\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 7948.543730752031\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.033775524411103826 0.06605108443576285 0.03227556002465903\n",
      "remaining size for Round 4: 127971\n",
      "81\n",
      "['step1_rr: 80', 'step2_rr: 80', 'step3_rr: 80', 'step4_rr: 80', 'step5_rr: 80']\n",
      "empirical response rate 0.05518069533394328\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.029018085919271977 0.05787881369795714 0.02886072777868516\n",
      "remaining size for Round 3: 135851\n",
      "82\n",
      "['step1_rr: 81', 'step2_rr: 81', 'step3_rr: 81', 'step4_rr: 81', 'step5_rr: 81']\n",
      "empirical response rate 0.05572392497712717\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.005578288358707274 0.06844261780463487 0.0628643294459276\n",
      "remaining size for Round 3: 135815\n",
      "83\n",
      "['step1_rr: 82', 'step2_rr: 82', 'step3_rr: 82', 'step4_rr: 82', 'step5_rr: 82']\n",
      "empirical response rate 0.05558096980786825\n",
      "{'LR__C': 1.0}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4176.173813910594\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.033707939188071565 0.0672226755046268 0.03351473631655523\n",
      "remaining size for Round 3: 135824\n",
      "Calculated size for Round 3: 6348.214668802298\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.04621370278569084 0.06879664752458656 0.022582944738895716\n",
      "remaining size for Round 4: 129476\n",
      "Calculated size for Round 4: 6533.637501106819\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03501191595811491 0.06765695278920503 0.032645036831090116\n",
      "remaining size for last Round 5: 122943\n",
      "84\n",
      "['step1_rr: 83', 'step2_rr: 83', 'step3_rr: 83', 'step4_rr: 83', 'step5_rr: 83']\n",
      "empirical response rate 0.056038426349496795\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4206.576669795643\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.023976796308127865 0.07175285764062422 0.04777606133249636\n",
      "remaining size for Round 3: 135794\n",
      "Calculated size for Round 3: 5304.218644467848\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.01881265994297481 0.07244630167032198 0.05363364172734718\n",
      "remaining size for Round 4: 130490\n",
      "85\n",
      "['step1_rr: 84', 'step2_rr: 84', 'step3_rr: 84', 'step4_rr: 84', 'step5_rr: 84']\n",
      "empirical response rate 0.05466605672461116\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.013936154213267476 0.0557458488232304 0.04180969460996292\n",
      "remaining size for Round 3: 135885\n",
      "86\n",
      "['step1_rr: 85', 'step2_rr: 85', 'step3_rr: 85', 'step4_rr: 85', 'step5_rr: 85']\n",
      "empirical response rate 0.053579597438243365\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4043.352644626449\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.04626380586011212 0.06194803181025074 0.015684225950138624\n",
      "remaining size for Round 3: 135957\n",
      "Calculated size for Round 3: 5458.123723892312\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05137973024576308 0.060397903350215436 0.009018173104452354\n",
      "remaining size for Round 4: 130499\n",
      "Calculated size for Round 4: 5256.339552365794\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.02766089267069121 0.06550234378526973 0.03784145111457852\n",
      "remaining size for last Round 5: 125243\n",
      "87\n",
      "['step1_rr: 86', 'step2_rr: 86', 'step3_rr: 86', 'step4_rr: 86', 'step5_rr: 86']\n",
      "empirical response rate 0.054180009149130834\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4083.166195613249\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03695812044344006 0.07291911604789947 0.03596099560445941\n",
      "remaining size for Round 3: 135917\n",
      "Calculated size for Round 3: 5787.066491725529\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.04623191942665165 0.0765335431165785 0.03030162368992686\n",
      "remaining size for Round 4: 130130\n",
      "Calculated size for Round 4: 6815.210568165239\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02549731630279269 0.07331017589982836 0.04781285959703567\n",
      "remaining size for last Round 5: 123315\n",
      "88\n",
      "['step1_rr: 87', 'step2_rr: 87', 'step3_rr: 87', 'step4_rr: 87', 'step5_rr: 87']\n",
      "empirical response rate 0.05400846294602013\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03697121424499662 0.07459875303212987 0.03762753878713325\n",
      "remaining size for Round 3: 135929\n",
      "89\n",
      "['step1_rr: 88', 'step2_rr: 88', 'step3_rr: 88', 'step4_rr: 88', 'step5_rr: 88']\n",
      "empirical response rate 0.057467978042086004\n",
      "{'LR__C': 1.0}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4301.689819632026\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03340663849005182 0.0669999808330844 0.03359334234303257\n",
      "remaining size for Round 3: 135699\n",
      "Calculated size for Round 3: 7313.485792940557\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03342174015274666 0.06551776658631245 0.03209602643356579\n",
      "remaining size for Round 4: 128386\n",
      "90\n",
      "['step1_rr: 89', 'step2_rr: 89', 'step3_rr: 89', 'step4_rr: 89', 'step5_rr: 89']\n",
      "empirical response rate 0.05595265324794144\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05205430001362302 0.0595845777189021 0.00753027770527908\n",
      "remaining size for Round 3: 135800\n",
      "Calculated size for Round 3: 5431.333858119192\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.01953054347784568 0.06448854028264828 0.0449579968048026\n",
      "remaining size for Round 4: 130369\n",
      "Calculated size for Round 4: 4979.157608334927\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.032767605240976876 0.06459534923461335 0.03182774399363648\n",
      "remaining size for last Round 5: 125390\n",
      "91\n",
      "['step1_rr: 90', 'step2_rr: 90', 'step3_rr: 90', 'step4_rr: 90', 'step5_rr: 90']\n",
      "empirical response rate 0.056209972552607505\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4217.9819182904175\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.01435100278231017 0.07335449335163169 0.05900349056932152\n",
      "remaining size for Round 3: 135783\n",
      "92\n",
      "['step1_rr: 91', 'step2_rr: 91', 'step3_rr: 91', 'step4_rr: 91', 'step5_rr: 91']\n",
      "empirical response rate 0.055666742909423604\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4181.87311403394\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.018347505235960848 0.06897928222816407 0.050631776992203226\n",
      "remaining size for Round 3: 135819\n",
      "Calculated size for Round 3: 5271.734714231149\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.04637597646631917 0.07009676956145706 0.023720793095137895\n",
      "remaining size for Round 4: 130548\n",
      "Calculated size for Round 4: 7559.9218431853415\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03726673293343108 0.07180615184131478 0.0345394189078837\n",
      "remaining size for last Round 5: 122989\n",
      "93\n",
      "['step1_rr: 92', 'step2_rr: 92', 'step3_rr: 92', 'step4_rr: 92', 'step5_rr: 92']\n",
      "empirical response rate 0.05609560841720036\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4210.378166320425\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.036467249644890745 0.06538576958434963 0.02891851993945889\n",
      "remaining size for Round 3: 135790\n",
      "Calculated size for Round 3: 5590.9290453134345\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.042715934694322194 0.07572560103363019 0.03300966633930799\n",
      "remaining size for Round 4: 130200\n",
      "Calculated size for Round 4: 6055.906409068403\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.037643445797590804 0.07281722968676063 0.03517378388916983\n",
      "remaining size for last Round 5: 124145\n",
      "94\n",
      "['step1_rr: 93', 'step2_rr: 93', 'step3_rr: 93', 'step4_rr: 93', 'step5_rr: 93']\n",
      "empirical response rate 0.05340805123513266\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4031.9825257930215\n",
      "{'LR__C': 0.1}\n",
      "orr termination 0.01211597614484993 0.07178067868789231 0.05966470254304238\n",
      "remaining size for Round 3: 135969\n",
      "Calculated size for Round 3: 5017.745695363901\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.035959809398440096 0.07210231597739912 0.036142506578959024\n",
      "remaining size for Round 4: 130952\n",
      "95\n",
      "['step1_rr: 94', 'step2_rr: 94', 'step3_rr: 94', 'step4_rr: 94', 'step5_rr: 94']\n",
      "empirical response rate 0.05349382433668801\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4037.6672970440713\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05520340946172635 0.06900960229623031 0.01380619283450396\n",
      "remaining size for Round 3: 135963\n",
      "Calculated size for Round 3: 5911.7583785546185\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03877747472703957 0.07467816378962565 0.03590068906258608\n",
      "remaining size for Round 4: 130052\n",
      "Calculated size for Round 4: 5941.357397602118\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.05385713987558416 0.0718271147324774 0.017969974856893237\n",
      "remaining size for last Round 5: 124111\n",
      "96\n",
      "['step1_rr: 95', 'step2_rr: 95', 'step3_rr: 95', 'step4_rr: 95', 'step5_rr: 95']\n",
      "empirical response rate 0.05443732845379689\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4100.237767911125\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.04111662384909412 0.0655984563516973 0.024481832502603176\n",
      "remaining size for Round 3: 135900\n",
      "Calculated size for Round 3: 5936.020715330494\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.02952864918379588 0.07490246371372342 0.04537381452992754\n",
      "remaining size for Round 4: 129964\n",
      "Calculated size for Round 4: 6418.259273935601\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.03596721103134244 0.07168598808985234 0.0357187770585099\n",
      "remaining size for last Round 5: 123546\n",
      "97\n",
      "['step1_rr: 96', 'step2_rr: 96', 'step3_rr: 96', 'step4_rr: 96', 'step5_rr: 96']\n",
      "empirical response rate 0.05200709057639524\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 3939.2130430862803\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02939517302138745 0.06829833438025731 0.03890316135886986\n",
      "remaining size for Round 3: 136061\n",
      "Calculated size for Round 3: 6437.701495372068\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.02475386216902664 0.07257616345427151 0.04782230128524487\n",
      "remaining size for Round 4: 129624\n",
      "98\n",
      "['step1_rr: 97', 'step2_rr: 97', 'step3_rr: 97', 'step4_rr: 97', 'step5_rr: 97']\n",
      "empirical response rate 0.05652447392497713\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4238.897449671384\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.005416998547883985 0.06979131555716153 0.06437431700927755\n",
      "remaining size for Round 3: 135762\n",
      "99\n",
      "['step1_rr: 98', 'step2_rr: 98', 'step3_rr: 98', 'step4_rr: 98', 'step5_rr: 98']\n",
      "empirical response rate 0.05460887465690759\n",
      "{'LR__C': 0.01}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "{'LR__C': 1.0}\n",
      "orr termination 0.0488699431665034 0.06826489134771103 0.019394948181207634\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 6075.909698075552\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.043458677708132235 0.06948151637547767 0.026022838667345435\n",
      "remaining size for Round 4: 129814\n",
      "Calculated size for Round 4: 5902.690763535462\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.046205493533959766 0.0692255889629543 0.02302009542899454\n",
      "remaining size for last Round 5: 123912\n",
      "100\n",
      "['step1_rr: 99', 'step2_rr: 99', 'step3_rr: 99', 'step4_rr: 99', 'step5_rr: 99']\n",
      "empirical response rate 0.055380832570905765\n",
      "{'LR__C': 0.1}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.036505994784500576 0.07196738463348379 0.03546138984898321\n",
      "remaining size for Round 3: 135838\n",
      "Calculated size for Round 3: 8533.170957357615\n",
      "{'LR__C': 0.01}\n",
      "orr termination 0.038132435363739385 0.0759437091891412 0.037811273825401816\n",
      "remaining size for Round 4: 127305\n"
     ]
    }
   ],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "highest_true_rr = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    highest_true_rr.append(np.max(dt_design_5['plan_response_rate']))\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t0bC5wHRwkWx",
   "metadata": {
    "id": "t0bC5wHRwkWx"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7XcvEocqYOP7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1707448236231,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "7XcvEocqYOP7",
    "outputId": "338e681d-1cf5-4fba-cdf9-37d207e4cf10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step1_rr</th>\n",
       "      <th>step2_rr</th>\n",
       "      <th>step3_rr</th>\n",
       "      <th>step4_rr</th>\n",
       "      <th>step5_rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.058348</td>\n",
       "      <td>0.061799</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.065446</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.061710</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.061721</td>\n",
       "      <td>0.063410</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.063445</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.066576</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.060130</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.062704</td>\n",
       "      <td>0.065873</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.061833</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    step1_rr  step2_rr  step3_rr  step4_rr  step5_rr\n",
       "0      0.055  0.058348  0.061799  0.068471       NaN\n",
       "1      0.055  0.061768  0.065446  0.068471  0.068471\n",
       "2      0.055  0.061710  0.068471       NaN       NaN\n",
       "3      0.055  0.055000       NaN       NaN       NaN\n",
       "4      0.055  0.061721  0.063410  0.068471  0.068471\n",
       "..       ...       ...       ...       ...       ...\n",
       "95     0.055  0.063445  0.068471  0.068471  0.068471\n",
       "96     0.055  0.066576  0.068471  0.068471       NaN\n",
       "97     0.055  0.060130  0.068471       NaN       NaN\n",
       "98     0.055  0.062704  0.065873  0.068471  0.068471\n",
       "99     0.055  0.061833  0.068471  0.068471       NaN\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "FDz-e9CSKaWX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1707453750518,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "FDz-e9CSKaWX",
    "outputId": "f8d84477-5173-4336-cc55-4ffcc0ada5f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 (0.8)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9L26KiTYJUZo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1707448237526,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "9L26KiTYJUZo",
    "outputId": "27d70514-4ac7-40f9-8373-5ed213bdb833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_rr: 0.055 (0.000)\n",
      "step2_rr: 0.061 (0.004)\n",
      "step3_rr: 0.066 (0.005)\n",
      "step4_rr: 0.068 (0.002)\n",
      "step5_rr: 0.068 (0.003)\n"
     ]
    }
   ],
   "source": [
    "# orr for each round:\n",
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Hw_mU1Xy9kIw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707448339675,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "Hw_mU1Xy9kIw",
    "outputId": "44c42256-3c95-48ff-b6a1-2d7484750b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.064, StD: 0.004\n"
     ]
    }
   ],
   "source": [
    "# overall orr:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dAeUn1ayxgXH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1707448339008,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "dAeUn1ayxgXH",
    "outputId": "3e8dab14-08fa-4902-87dd-f18235e86888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.068 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# highest true rr:\n",
    "mean_result=(np.mean(highest_true_rr))\n",
    "std_result=(np.std(highest_true_rr))\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "NOSItDYuQwa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1707447643064,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "NOSItDYuQwa8",
    "outputId": "d8e676ad-a73e-4e62-f939-ebf6efadaa9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.066, StD: 0.005\n"
     ]
    }
   ],
   "source": [
    "# adaptive learning orr:\n",
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "C703gqxdH6Fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1707448246018,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "C703gqxdH6Fd",
    "outputId": "7e9f5fc0-3a8c-4472-f0c2-bb0392711f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_plan_number: nan (nan)\n",
      "step2_plan_number: 7.1 (3.9)\n",
      "step3_plan_number: 2.9 (2.0)\n",
      "step4_plan_number: 2.0 (1.4)\n",
      "step5_plan_number: 1.4 (0.8)\n"
     ]
    }
   ],
   "source": [
    "# average plan number for each round:\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "P_T2Gb6t9hXq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1707448245147,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "P_T2Gb6t9hXq",
    "outputId": "b4a9a3b4-4878-418d-da2f-545cc90cc55b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': 0.67,\n",
       " 'early_stopping_plan': 0.67,\n",
       " 'early_stopping_orr': 0.0,\n",
       " 'early_stopping_size': 0.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# early stopping probabilities:\n",
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "W3dHQr2AxzDt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1707447645503,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "W3dHQr2AxzDt",
    "outputId": "8d467010-aa11-47ae-85d1-b6e431ff7e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129828.75 5130.973592555315\n"
     ]
    }
   ],
   "source": [
    "# sample size for the last round:\n",
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c7f36-4800-4d10-b25e-f0050933d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilities for better performance compared to the benchmark:\n",
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "C1KcRlYqwT5H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1707447644111,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "C1KcRlYqwT5H",
    "outputId": "05483b1d-c213-419c-c926-cb56090014dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_sample_size: 34976.000 (0.000)\n",
      "step2_sample_size: 6855.844 (19020.756)\n",
      "step3_sample_size: 47113.405 (60380.932)\n",
      "step4_sample_size: 68859.140 (61678.788)\n",
      "step5_sample_size: 123752.727 (868.797)\n"
     ]
    }
   ],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uHSypRgXKNRd",
   "metadata": {
    "id": "uHSypRgXKNRd"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4T8kpJkkKNRf",
   "metadata": {
    "id": "4T8kpJkkKNRf"
   },
   "outputs": [],
   "source": [
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            # ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0))\n",
    "#             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "                    # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "                    ('RF', ensemble.RandomForestClassifier(criterion='gini', random_state=0))\n",
    "                    # ('XGB', XGBClassifier(n_estimators=50, learning_rate=0.1, random_state=0))\n",
    "                   ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "    param_grid = {\n",
    "        # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "        # 'LR__C': [0.01] # [0.01, 0.05, 0.1]\n",
    "        # 'Ridge__C': [0.01]\n",
    "        # 'SVM__C': [0.01, 0.05, 0.1]\n",
    "#         'RF__n_estimators': [50, 100, 200]\n",
    "        'RF__n_estimators': [50]\n",
    "#         'RF__max_depth': [10, 20, None]\n",
    "        # 'XGB__n_estimators': [50]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0L4C5O0LKNRg",
   "metadata": {
    "id": "0L4C5O0LKNRg"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "XaFmXCTbKNRg",
   "metadata": {
    "id": "XaFmXCTbKNRg"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "E1DotwS2KNRg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 542845,
     "status": "ok",
     "timestamp": 1707455312537,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "E1DotwS2KNRg",
    "outputId": "768e8c04-6c96-450f-f88c-3c415c9a9d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['step1_rr: 0', 'step2_rr: 0', 'step3_rr: 0', 'step4_rr: 0', 'step5_rr: 0']\n",
      "empirical response rate 0.05655306495882891\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4240.799240494033\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05479087988334956 0.06836783503271052 0.013576955149360956\n",
      "remaining size for Round 3: 135760\n",
      "Calculated size for Round 3: 7250.5978185355325\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03649780748875311 0.07259724332691517 0.03609943583816206\n",
      "remaining size for Round 4: 128510\n",
      "Calculated size for Round 4: 5970.162675655956\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.034455066447021364 0.06981692622864044 0.03536185978161908\n",
      "remaining size for last Round 5: 122540\n",
      "2\n",
      "['step1_rr: 1', 'step2_rr: 1', 'step3_rr: 1', 'step4_rr: 1', 'step5_rr: 1']\n",
      "empirical response rate 0.054637465690759376\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.047233103989835004 0.07205895170483104 0.024825847714996033\n",
      "remaining size for Round 3: 135887\n",
      "Calculated size for Round 3: 9900.25225171141\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03969611869750919 0.07270868897855161 0.03301257028104242\n",
      "remaining size for Round 4: 125987\n",
      "3\n",
      "['step1_rr: 2', 'step2_rr: 2', 'step3_rr: 2', 'step4_rr: 2', 'step5_rr: 2']\n",
      "empirical response rate 0.05303636779505947\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.044863282478420204 0.07272051048841391 0.027857228009993705\n",
      "remaining size for Round 3: 135993\n",
      "Calculated size for Round 3: 5922.566611783426\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.025419827150161445 0.07364697147199153 0.04822714432183009\n",
      "remaining size for Round 4: 130071\n",
      "Calculated size for Round 4: 6141.583213039123\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.032843878001257674 0.0670606430587095 0.034216765057451824\n",
      "remaining size for last Round 5: 123930\n",
      "4\n",
      "['step1_rr: 3', 'step2_rr: 3', 'step3_rr: 3', 'step4_rr: 3', 'step5_rr: 3']\n",
      "empirical response rate 0.054265782250686186\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4088.8561455390104\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.018341153697270837 0.07345579460799809 0.05511464091072725\n",
      "remaining size for Round 3: 135912\n",
      "Calculated size for Round 3: 6133.3882212029985\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03558750641564242 0.06950905861532408 0.03392155219968166\n",
      "remaining size for Round 4: 129779\n",
      "5\n",
      "['step1_rr: 4', 'step2_rr: 4', 'step3_rr: 4', 'step4_rr: 4', 'step5_rr: 4']\n",
      "empirical response rate 0.05772529734675206\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4318.826898633964\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.06239626944633041 0.07555070079534301 0.013154431349012605\n",
      "remaining size for Round 3: 135682\n",
      "Calculated size for Round 3: 7399.226084855928\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.031089615471676053 0.07289697873829777 0.04180736326662172\n",
      "remaining size for Round 4: 128283\n",
      "Calculated size for Round 4: 5858.250789640348\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.036802395317004466 0.07237258217625668 0.035570186859252215\n",
      "remaining size for last Round 5: 122425\n",
      "6\n",
      "['step1_rr: 5', 'step2_rr: 5', 'step3_rr: 5', 'step4_rr: 5', 'step5_rr: 5']\n",
      "empirical response rate 0.05458028362305581\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03842628158399514 0.07685454192230222 0.03842826033830708\n",
      "remaining size for Round 3: 135891\n",
      "7\n",
      "['step1_rr: 6', 'step2_rr: 6', 'step3_rr: 6', 'step4_rr: 6', 'step5_rr: 6']\n",
      "empirical response rate 0.05775388838060384\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4320.7313323598355\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.050752688478343966 0.07544918652031397 0.024696498041970008\n",
      "remaining size for Round 3: 135680\n",
      "Calculated size for Round 3: 11276.769746877006\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03869133280284942 0.07373317628729227 0.03504184348444285\n",
      "remaining size for Round 4: 124404\n",
      "8\n",
      "['step1_rr: 7', 'step2_rr: 7', 'step3_rr: 7', 'step4_rr: 7', 'step5_rr: 7']\n",
      "empirical response rate 0.05749656907593779\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4303.593688344371\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.037832598139177685 0.07871648804161754 0.04088388990243986\n",
      "remaining size for Round 3: 135697\n",
      "9\n",
      "['step1_rr: 8', 'step2_rr: 8', 'step3_rr: 8', 'step4_rr: 8', 'step5_rr: 8']\n",
      "empirical response rate 0.0553236505032022\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4159.079338458144\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.008926336268698166 0.0921164712754455 0.08319013500674734\n",
      "remaining size for Round 3: 135841\n",
      "10\n",
      "['step1_rr: 9', 'step2_rr: 9', 'step3_rr: 9', 'step4_rr: 9', 'step5_rr: 9']\n",
      "empirical response rate 0.0536939615736505\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05113226161588439 0.07494492630898641 0.023812664693102024\n",
      "remaining size for Round 3: 135950\n",
      "Calculated size for Round 3: 10439.322112783004\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03338524953241381 0.070775578306268 0.03739032877385419\n",
      "remaining size for Round 4: 125511\n",
      "11\n",
      "['step1_rr: 10', 'step2_rr: 10', 'step3_rr: 10', 'step4_rr: 10', 'step5_rr: 10']\n",
      "empirical response rate 0.05460887465690759\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.036934895139631274 0.07496079338495505 0.03802589824532378\n",
      "remaining size for Round 3: 135889\n",
      "12\n",
      "['step1_rr: 11', 'step2_rr: 11', 'step3_rr: 11', 'step4_rr: 11', 'step5_rr: 11']\n",
      "empirical response rate 0.05275045745654163\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 3988.418451118696\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.019745256453902384 0.0702818845449711 0.050536628091068715\n",
      "remaining size for Round 3: 136012\n",
      "Calculated size for Round 3: 4934.141804984078\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03819005128030385 0.0751261821949981 0.03693613091469425\n",
      "remaining size for Round 4: 131078\n",
      "Calculated size for Round 4: 7395.7275983570435\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03641062808649981 0.07268924778179564 0.03627861969529583\n",
      "remaining size for last Round 5: 123683\n",
      "13\n",
      "['step1_rr: 12', 'step2_rr: 12', 'step3_rr: 12', 'step4_rr: 12', 'step5_rr: 12']\n",
      "empirical response rate 0.05626715462031107\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4221.784173594918\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.025079726580397883 0.07579884543508791 0.050719118854690035\n",
      "remaining size for Round 3: 135779\n",
      "14\n",
      "['step1_rr: 13', 'step2_rr: 13', 'step3_rr: 13', 'step4_rr: 13', 'step5_rr: 13']\n",
      "empirical response rate 0.05466605672461116\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.027159284635807728 0.07428818578486994 0.04712890114906221\n",
      "remaining size for Round 3: 135885\n",
      "15\n",
      "['step1_rr: 14', 'step2_rr: 14', 'step3_rr: 14', 'step4_rr: 14', 'step5_rr: 14']\n",
      "empirical response rate 0.05375114364135407\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.061754708300914896 0.06978452898301822 0.008029820682103325\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 6219.191447995639\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04995268784531014 0.0666741919056793 0.016721504060369166\n",
      "remaining size for Round 4: 129727\n",
      "Calculated size for Round 4: 5357.285480926125\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05724562731554485 0.06835275158210556 0.011107124266560714\n",
      "remaining size for last Round 5: 124370\n",
      "16\n",
      "['step1_rr: 15', 'step2_rr: 15', 'step3_rr: 15', 'step4_rr: 15', 'step5_rr: 15']\n",
      "empirical response rate 0.05466605672461116\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "17\n",
      "['step1_rr: 16', 'step2_rr: 16', 'step3_rr: 16', 'step4_rr: 16', 'step5_rr: 16']\n",
      "empirical response rate 0.05595265324794144\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03772266426641252 0.07299072741644211 0.03526806315002959\n",
      "remaining size for Round 3: 135800\n",
      "18\n",
      "['step1_rr: 17', 'step2_rr: 17', 'step3_rr: 17', 'step4_rr: 17', 'step5_rr: 17']\n",
      "empirical response rate 0.05480901189387008\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "19\n",
      "['step1_rr: 18', 'step2_rr: 18', 'step3_rr: 18', 'step4_rr: 18', 'step5_rr: 18']\n",
      "empirical response rate 0.05598124428179323\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.035540940616257004 0.07189797308047015 0.036357032464213145\n",
      "remaining size for Round 3: 135798\n",
      "20\n",
      "['step1_rr: 19', 'step2_rr: 19', 'step3_rr: 19', 'step4_rr: 19', 'step5_rr: 19']\n",
      "empirical response rate 0.05489478499542543\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.016244832169371275 0.07718825844931121 0.060943426279939934\n",
      "remaining size for Round 3: 135870\n",
      "21\n",
      "['step1_rr: 20', 'step2_rr: 20', 'step3_rr: 20', 'step4_rr: 20', 'step5_rr: 20']\n",
      "empirical response rate 0.05486619396157365\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4128.701861019453\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.059886955490640145 0.07006226264687092 0.010175307156230773\n",
      "remaining size for Round 3: 135872\n",
      "Calculated size for Round 3: 6631.41199133565\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05483119818463452 0.06565633161098028 0.010825133426345758\n",
      "remaining size for Round 4: 129241\n",
      "Calculated size for Round 4: 5521.3896721688525\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.015377707100590087 0.07203678983091749 0.0566590827303274\n",
      "remaining size for last Round 5: 123720\n",
      "22\n",
      "['step1_rr: 21', 'step2_rr: 21', 'step3_rr: 21', 'step4_rr: 21', 'step5_rr: 21']\n",
      "empirical response rate 0.05518069533394328\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.036134524742202426 0.0715297305497446 0.03539520580754217\n",
      "remaining size for Round 3: 135851\n",
      "23\n",
      "['step1_rr: 22', 'step2_rr: 22', 'step3_rr: 22', 'step4_rr: 22', 'step5_rr: 22']\n",
      "empirical response rate 0.054780420860018296\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.036753701386784375 0.0732100067083052 0.036456305321520825\n",
      "remaining size for Round 3: 135877\n",
      "24\n",
      "['step1_rr: 23', 'step2_rr: 23', 'step3_rr: 23', 'step4_rr: 23', 'step5_rr: 23']\n",
      "empirical response rate 0.05415141811527905\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.026526572874448463 0.07350246798548801 0.04697589511103955\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 7045.591842333557\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.031767434612363185 0.06556447545648328 0.033797040844120094\n",
      "remaining size for Round 4: 128874\n",
      "25\n",
      "['step1_rr: 24', 'step2_rr: 24', 'step3_rr: 24', 'step4_rr: 24', 'step5_rr: 24']\n",
      "empirical response rate 0.05400846294602013\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.034215068874187717 0.0732777970269745 0.03906272815278678\n",
      "remaining size for Round 3: 135929\n",
      "26\n",
      "['step1_rr: 25', 'step2_rr: 25', 'step3_rr: 25', 'step4_rr: 25', 'step5_rr: 25']\n",
      "empirical response rate 0.056038426349496795\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4206.576669795643\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03832627650582619 0.07522401015812698 0.036897733652300785\n",
      "remaining size for Round 3: 135794\n",
      "27\n",
      "['step1_rr: 26', 'step2_rr: 26', 'step3_rr: 26', 'step4_rr: 26', 'step5_rr: 26']\n",
      "empirical response rate 0.05377973467520585\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.011103646158536503 0.08839902087593494 0.07729537471739845\n",
      "remaining size for Round 3: 135944\n",
      "28\n",
      "['step1_rr: 27', 'step2_rr: 27', 'step3_rr: 27', 'step4_rr: 27', 'step5_rr: 27']\n",
      "empirical response rate 0.0529791857273559\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4003.567322548448\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05550513955683436 0.06662136387231055 0.011116224315476188\n",
      "remaining size for Round 3: 135997\n",
      "Calculated size for Round 3: 6792.737997313366\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.015009630464658663 0.07092270660964675 0.05591307614498809\n",
      "remaining size for Round 4: 129205\n",
      "29\n",
      "['step1_rr: 28', 'step2_rr: 28', 'step3_rr: 28', 'step4_rr: 28', 'step5_rr: 28']\n",
      "empirical response rate 0.05312214089661482\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4013.037453633404\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.028508440130324268 0.0762362365753982 0.04772779644507393\n",
      "remaining size for Round 3: 135987\n",
      "30\n",
      "['step1_rr: 29', 'step2_rr: 29', 'step3_rr: 29', 'step4_rr: 29', 'step5_rr: 29']\n",
      "empirical response rate 0.054837602927721864\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.048749687396122884 0.07183329760030013 0.02308361020417725\n",
      "remaining size for Round 3: 135874\n",
      "Calculated size for Round 3: 9883.130559724419\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.033454401359868755 0.06881197068823802 0.03535756932836927\n",
      "remaining size for Round 4: 125991\n",
      "31\n",
      "['step1_rr: 30', 'step2_rr: 30', 'step3_rr: 30', 'step4_rr: 30', 'step5_rr: 30']\n",
      "empirical response rate 0.05518069533394328\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.032483800803700974 0.0718671479544207 0.03938334715071973\n",
      "remaining size for Round 3: 135851\n",
      "Calculated size for Round 3: 6350.598717829481\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.036755033311825155 0.07154830874148392 0.034793275429658765\n",
      "remaining size for Round 4: 129501\n",
      "Calculated size for Round 4: 6542.115257026668\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03620783050082859 0.07240155975615224 0.03619372925532365\n",
      "remaining size for last Round 5: 122959\n",
      "32\n",
      "['step1_rr: 31', 'step2_rr: 31', 'step3_rr: 31', 'step4_rr: 31', 'step5_rr: 31']\n",
      "empirical response rate 0.05435155535224154\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4094.5466697157462\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03530997073642991 0.07355963570799433 0.038249664971564415\n",
      "remaining size for Round 3: 135906\n",
      "33\n",
      "['step1_rr: 32', 'step2_rr: 32', 'step3_rr: 32', 'step4_rr: 32', 'step5_rr: 32']\n",
      "empirical response rate 0.05332227813357731\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4026.2983311032726\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.02192748297958886 0.06732250145205265 0.04539501847246379\n",
      "remaining size for Round 3: 135974\n",
      "Calculated size for Round 3: 5694.752519932292\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.022458867771743097 0.06994281992000113 0.04748395214825804\n",
      "remaining size for Round 4: 130280\n",
      "34\n",
      "['step1_rr: 33', 'step2_rr: 33', 'step3_rr: 33', 'step4_rr: 33', 'step5_rr: 33']\n",
      "empirical response rate 0.05375114364135407\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05289336778848443 0.06802389858864971 0.015130530800165284\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 6029.716868138978\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.06152794546082654 0.07179503661803875 0.010267091157212214\n",
      "remaining size for Round 4: 129917\n",
      "Calculated size for Round 4: 5892.782871023818\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05191394848564922 0.07394800205379523 0.022034053568146014\n",
      "remaining size for last Round 5: 124025\n",
      "35\n",
      "['step1_rr: 34', 'step2_rr: 34', 'step3_rr: 34', 'step4_rr: 34', 'step5_rr: 34']\n",
      "empirical response rate 0.054637465690759376\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04193320303211194 0.07546044003432424 0.0335272370022123\n",
      "remaining size for Round 3: 135887\n",
      "36\n",
      "['step1_rr: 35', 'step2_rr: 35', 'step3_rr: 35', 'step4_rr: 35', 'step5_rr: 35']\n",
      "empirical response rate 0.05669602012808783\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4250.309141054068\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.02434320349476901 0.07553673791948885 0.05119353442471984\n",
      "remaining size for Round 3: 135750\n",
      "37\n",
      "['step1_rr: 36', 'step2_rr: 36', 'step3_rr: 36', 'step4_rr: 36', 'step5_rr: 36']\n",
      "empirical response rate 0.05600983531564501\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4204.676016429063\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.046006597321100504 0.07254890367172226 0.026542306350621755\n",
      "remaining size for Round 3: 135796\n",
      "Calculated size for Round 3: 6769.100533138973\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04218921739247883 0.0709405477456861 0.028751330353207274\n",
      "remaining size for Round 4: 129027\n",
      "Calculated size for Round 4: 6253.636011708991\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.023982548345472376 0.06989145970433407 0.04590891135886169\n",
      "remaining size for last Round 5: 122774\n",
      "38\n",
      "['step1_rr: 37', 'step2_rr: 37', 'step3_rr: 37', 'step4_rr: 37', 'step5_rr: 37']\n",
      "empirical response rate 0.05458028362305581\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04595363983612917 0.0731138467096043 0.027160206873475132\n",
      "remaining size for Round 3: 135891\n",
      "Calculated size for Round 3: 6074.783768333311\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.037671186777220436 0.07449035030312579 0.03681916352590535\n",
      "remaining size for Round 4: 129817\n",
      "Calculated size for Round 4: 6341.480128701641\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.028987918267104455 0.07994552006460542 0.05095760179750097\n",
      "remaining size for last Round 5: 123476\n",
      "39\n",
      "['step1_rr: 38', 'step2_rr: 38', 'step3_rr: 38', 'step4_rr: 38', 'step5_rr: 38']\n",
      "empirical response rate 0.05535224153705398\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4160.97847079396\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.02409817585279634 0.07362584733464338 0.04952767148184704\n",
      "remaining size for Round 3: 135840\n",
      "40\n",
      "['step1_rr: 39', 'step2_rr: 39', 'step3_rr: 39', 'step4_rr: 39', 'step5_rr: 39']\n",
      "empirical response rate 0.05489478499542543\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.026143774321763482 0.08122910349664965 0.05508532917488616\n",
      "remaining size for Round 3: 135870\n",
      "41\n",
      "['step1_rr: 40', 'step2_rr: 40', 'step3_rr: 40', 'step4_rr: 40', 'step5_rr: 40']\n",
      "empirical response rate 0.05529505946935041\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4157.18026960777\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.017087105346470552 0.07161262898717305 0.0545255236407025\n",
      "remaining size for Round 3: 135843\n",
      "42\n",
      "['step1_rr: 41', 'step2_rr: 41', 'step3_rr: 41', 'step4_rr: 41', 'step5_rr: 41']\n",
      "empirical response rate 0.05363677950594693\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04277175323006894 0.07402841927147681 0.03125666604140787\n",
      "remaining size for Round 3: 135953\n",
      "43\n",
      "['step1_rr: 42', 'step2_rr: 42', 'step3_rr: 42', 'step4_rr: 42', 'step5_rr: 42']\n",
      "empirical response rate 0.05377973467520585\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03709153076710271 0.07384211442846976 0.03675058366136705\n",
      "remaining size for Round 3: 135944\n",
      "44\n",
      "['step1_rr: 43', 'step2_rr: 43', 'step3_rr: 43', 'step4_rr: 43', 'step5_rr: 43']\n",
      "empirical response rate 0.05583828911253431\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4193.273425323935\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.037765936438970624 0.07402830231862051 0.036262365879649885\n",
      "remaining size for Round 3: 135807\n",
      "Calculated size for Round 3: 8320.321571989089\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03896360437416528 0.07664983454645263 0.03768623017228735\n",
      "remaining size for Round 4: 127487\n",
      "45\n",
      "['step1_rr: 44', 'step2_rr: 44', 'step3_rr: 44', 'step4_rr: 44', 'step5_rr: 44']\n",
      "empirical response rate 0.05555237877401647\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4174.274174005051\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.050730345914651365 0.07000121782211577 0.019270871907464404\n",
      "remaining size for Round 3: 135826\n",
      "Calculated size for Round 3: 6795.121200278774\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.01812727411454087 0.0830115426571787 0.06488426854263782\n",
      "remaining size for Round 4: 129031\n",
      "46\n",
      "['step1_rr: 45', 'step2_rr: 45', 'step3_rr: 45', 'step4_rr: 45', 'step5_rr: 45']\n",
      "empirical response rate 0.0536939615736505\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03692545247860876 0.07487117352981248 0.037945721051203724\n",
      "remaining size for Round 3: 135950\n",
      "47\n",
      "['step1_rr: 46', 'step2_rr: 46', 'step3_rr: 46', 'step4_rr: 46', 'step5_rr: 46']\n",
      "empirical response rate 0.05449451052150046\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4104.032152159118\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05694246560788392 0.07423113970463602 0.017288674096752096\n",
      "remaining size for Round 3: 135896\n",
      "Calculated size for Round 3: 6604.886814601002\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.048670400086442356 0.07251652339279982 0.023846123306357464\n",
      "remaining size for Round 4: 129292\n",
      "Calculated size for Round 4: 6132.506347397339\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03769199943080541 0.07349917993079659 0.03580718049999118\n",
      "remaining size for last Round 5: 123160\n",
      "48\n",
      "['step1_rr: 47', 'step2_rr: 47', 'step3_rr: 47', 'step4_rr: 47', 'step5_rr: 47']\n",
      "empirical response rate 0.055380832570905765\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03767195376464684 0.08272768757927955 0.04505573381463271\n",
      "remaining size for Round 3: 135838\n",
      "Calculated size for Round 3: 7260.252766594291\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.025551527188568766 0.075435541124619 0.04988401393605024\n",
      "remaining size for Round 4: 128578\n",
      "49\n",
      "['step1_rr: 48', 'step2_rr: 48', 'step3_rr: 48', 'step4_rr: 48', 'step5_rr: 48']\n",
      "empirical response rate 0.0554951967063129\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4170.4750844497285\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04955274423919574 0.07531746201972828 0.025764717780532534\n",
      "remaining size for Round 3: 135830\n",
      "Calculated size for Round 3: 9498.585279716583\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03619078846894987 0.07223875067580793 0.03604796220685806\n",
      "remaining size for Round 4: 126332\n",
      "50\n",
      "['step1_rr: 49', 'step2_rr: 49', 'step3_rr: 49', 'step4_rr: 49', 'step5_rr: 49']\n",
      "empirical response rate 0.05563815187557182\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4179.973283933777\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04712872938480479 0.06940580983506046 0.02227708045025567\n",
      "remaining size for Round 3: 135821\n",
      "Calculated size for Round 3: 9229.378389616008\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03617858181720766 0.07238700562127787 0.03620842380407021\n",
      "remaining size for Round 4: 126592\n",
      "51\n",
      "['step1_rr: 50', 'step2_rr: 50', 'step3_rr: 50', 'step4_rr: 50', 'step5_rr: 50']\n",
      "empirical response rate 0.05586688014638609\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4195.17369890541\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03478987677211882 0.07006844033292949 0.03527856356081067\n",
      "remaining size for Round 3: 135805\n",
      "52\n",
      "['step1_rr: 51', 'step2_rr: 51', 'step3_rr: 51', 'step4_rr: 51', 'step5_rr: 51']\n",
      "empirical response rate 0.055809698078682524\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05517525458413658 0.06614049850576255 0.01096524392162597\n",
      "remaining size for Round 3: 135809\n",
      "Calculated size for Round 3: 5020.6489981046\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03589693784426623 0.07177756136152541 0.03588062351725918\n",
      "remaining size for Round 4: 130789\n",
      "Calculated size for Round 4: 5157.474665576988\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.026694644355874216 0.07340751765392724 0.04671287329805302\n",
      "remaining size for last Round 5: 125632\n",
      "53\n",
      "['step1_rr: 52', 'step2_rr: 52', 'step3_rr: 52', 'step4_rr: 52', 'step5_rr: 52']\n",
      "empirical response rate 0.05661024702653248\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "54\n",
      "['step1_rr: 53', 'step2_rr: 53', 'step3_rr: 53', 'step4_rr: 53', 'step5_rr: 53']\n",
      "empirical response rate 0.054837602927721864\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.0566478192158653 0.07536013928364352 0.018712320067778218\n",
      "remaining size for Round 3: 135874\n",
      "Calculated size for Round 3: 9913.181927906324\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05119860024454463 0.07708096557040521 0.02588236532586058\n",
      "remaining size for Round 4: 125961\n",
      "Calculated size for Round 4: 6273.148131925713\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.0371139455986305 0.07438636635129306 0.03727242075266256\n",
      "remaining size for last Round 5: 119688\n",
      "55\n",
      "['step1_rr: 54', 'step2_rr: 54', 'step3_rr: 54', 'step4_rr: 54', 'step5_rr: 54']\n",
      "empirical response rate 0.05323650503202196\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4020.614713204558\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.016022229389576686 0.08132626760406926 0.06530403821449257\n",
      "remaining size for Round 3: 135980\n",
      "56\n",
      "['step1_rr: 55', 'step2_rr: 55', 'step3_rr: 55', 'step4_rr: 55', 'step5_rr: 55']\n",
      "empirical response rate 0.054780420860018296\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04735553476437185 0.06690872712748616 0.019553192363114313\n",
      "remaining size for Round 3: 135877\n",
      "Calculated size for Round 3: 6459.886467099371\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05465916439238506 0.06919856993416189 0.01453940554177683\n",
      "remaining size for Round 4: 129418\n",
      "Calculated size for Round 4: 5718.980963726033\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03719085901919087 0.0671398828569257 0.029949023837734824\n",
      "remaining size for last Round 5: 123700\n",
      "57\n",
      "['step1_rr: 56', 'step2_rr: 56', 'step3_rr: 56', 'step4_rr: 56', 'step5_rr: 56']\n",
      "empirical response rate 0.05446591948764867\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "58\n",
      "['step1_rr: 57', 'step2_rr: 57', 'step3_rr: 57', 'step4_rr: 57', 'step5_rr: 57']\n",
      "empirical response rate 0.053979871912168347\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "59\n",
      "['step1_rr: 58', 'step2_rr: 58', 'step3_rr: 58', 'step4_rr: 58', 'step5_rr: 58']\n",
      "empirical response rate 0.05546660567246112\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4168.575634817409\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.025709208731387226 0.07381899024881519 0.048109781517427966\n",
      "remaining size for Round 3: 135832\n",
      "Calculated size for Round 3: 5431.278352518088\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03609949018109219 0.07133112540776565 0.03523163522667346\n",
      "remaining size for Round 4: 130401\n",
      "Calculated size for Round 4: 6857.410739868843\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.034193640516615 0.06927968675422196 0.03508604623760696\n",
      "remaining size for last Round 5: 123544\n",
      "60\n",
      "['step1_rr: 59', 'step2_rr: 59', 'step3_rr: 59', 'step4_rr: 59', 'step5_rr: 59']\n",
      "empirical response rate 0.05498055809698079\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4136.294704781159\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.026887202817078834 0.07035473927787858 0.04346753646079975\n",
      "remaining size for Round 3: 135864\n",
      "Calculated size for Round 3: 5034.94427141054\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.047131568666295025 0.07010965437548763 0.02297808570919261\n",
      "remaining size for Round 4: 130830\n",
      "Calculated size for Round 4: 6171.687690902207\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.033137337477936485 0.06749202394599653 0.034354686468060044\n",
      "remaining size for last Round 5: 124659\n",
      "61\n",
      "['step1_rr: 60', 'step2_rr: 60', 'step3_rr: 60', 'step4_rr: 60', 'step5_rr: 60']\n",
      "empirical response rate 0.055895471180237875\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "62\n",
      "['step1_rr: 61', 'step2_rr: 61', 'step3_rr: 61', 'step4_rr: 61', 'step5_rr: 61']\n",
      "empirical response rate 0.05312214089661482\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "63\n",
      "['step1_rr: 62', 'step2_rr: 62', 'step3_rr: 62', 'step4_rr: 62', 'step5_rr: 62']\n",
      "empirical response rate 0.05689615736505032\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4263.625650278873\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.045882921328739466 0.07555961624898866 0.029676694920249193\n",
      "remaining size for Round 3: 135737\n",
      "Calculated size for Round 3: 7630.832321432281\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05137849913426059 0.07644151718190403 0.025063018047643444\n",
      "remaining size for Round 4: 128107\n",
      "Calculated size for Round 4: 6702.458479264044\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.037196443219699664 0.07552607503521187 0.03832963181551221\n",
      "remaining size for last Round 5: 121405\n",
      "64\n",
      "['step1_rr: 63', 'step2_rr: 63', 'step3_rr: 63', 'step4_rr: 63', 'step5_rr: 63']\n",
      "empirical response rate 0.05458028362305581\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "65\n",
      "['step1_rr: 64', 'step2_rr: 64', 'step3_rr: 64', 'step4_rr: 64', 'step5_rr: 64']\n",
      "empirical response rate 0.05592406221408966\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03531132449652286 0.0717872889785277 0.03647596448200483\n",
      "remaining size for Round 3: 135802\n",
      "66\n",
      "['step1_rr: 65', 'step2_rr: 65', 'step3_rr: 65', 'step4_rr: 65', 'step5_rr: 65']\n",
      "empirical response rate 0.05598124428179323\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04499149435070674 0.08426920793758029 0.03927771358687355\n",
      "remaining size for Round 3: 135798\n",
      "67\n",
      "['step1_rr: 66', 'step2_rr: 66', 'step3_rr: 66', 'step4_rr: 66', 'step5_rr: 66']\n",
      "empirical response rate 0.056781793229643183\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4256.015838229115\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.031068366441837445 0.07265892048589269 0.04159055404405525\n",
      "remaining size for Round 3: 135744\n",
      "Calculated size for Round 3: 7336.422574491681\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04064355188017852 0.07835084755771513 0.037707295677536605\n",
      "remaining size for Round 4: 128408\n",
      "68\n",
      "['step1_rr: 67', 'step2_rr: 67', 'step3_rr: 67', 'step4_rr: 67', 'step5_rr: 67']\n",
      "empirical response rate 0.05609560841720036\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4210.378166320425\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.01835361682398761 0.0768013334626213 0.05844771663863369\n",
      "remaining size for Round 3: 135790\n",
      "Calculated size for Round 3: 5534.0192105185615\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.049426847912557526 0.07266256948517566 0.023235721572618134\n",
      "remaining size for Round 4: 130256\n",
      "Calculated size for Round 4: 7943.16093406762\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03642866832306411 0.07360371476817648 0.037175046445112374\n",
      "remaining size for last Round 5: 122313\n",
      "69\n",
      "['step1_rr: 68', 'step2_rr: 68', 'step3_rr: 68', 'step4_rr: 68', 'step5_rr: 68']\n",
      "empirical response rate 0.05486619396157365\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "70\n",
      "['step1_rr: 69', 'step2_rr: 69', 'step3_rr: 69', 'step4_rr: 69', 'step5_rr: 69']\n",
      "empirical response rate 0.05363677950594693\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.06124437931715371 0.07059309350185261 0.009348714184698903\n",
      "remaining size for Round 3: 135953\n",
      "Calculated size for Round 3: 6522.418912982449\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.0587042949655741 0.06966052302993181 0.010956228064357712\n",
      "remaining size for Round 4: 129431\n",
      "Calculated size for Round 4: 5780.056907019969\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.016207697649540227 0.07475267475697957 0.05854497710743934\n",
      "remaining size for last Round 5: 123651\n",
      "71\n",
      "['step1_rr: 70', 'step2_rr: 70', 'step3_rr: 70', 'step4_rr: 70', 'step5_rr: 70']\n",
      "empirical response rate 0.055809698078682524\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04240929289531538 0.0704861019124843 0.028076809017168927\n",
      "remaining size for Round 3: 135809\n",
      "Calculated size for Round 3: 6021.368804925812\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.045225557084608785 0.07501687111106614 0.029791314026457356\n",
      "remaining size for Round 4: 129788\n",
      "Calculated size for Round 4: 6477.964171862995\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.023488714379353053 0.07386896106584359 0.050380246686490535\n",
      "remaining size for last Round 5: 123311\n",
      "72\n",
      "['step1_rr: 71', 'step2_rr: 71', 'step3_rr: 71', 'step4_rr: 71', 'step5_rr: 71']\n",
      "empirical response rate 0.05592406221408966\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.06255360829349199 0.07379940909987004 0.011245800806378048\n",
      "remaining size for Round 3: 135802\n",
      "Calculated size for Round 3: 7078.750211994331\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.06109480981589569 0.07145615832704412 0.010361348511148429\n",
      "remaining size for Round 4: 128724\n",
      "Calculated size for Round 4: 5951.495581523443\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04440201180713626 0.07263015702763266 0.028228145220496402\n",
      "remaining size for last Round 5: 122773\n",
      "73\n",
      "['step1_rr: 72', 'step2_rr: 72', 'step3_rr: 72', 'step4_rr: 72', 'step5_rr: 72']\n",
      "empirical response rate 0.05721065873741994\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4284.557829370903\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.039117565713307476 0.07614662870018074 0.037029062986873265\n",
      "remaining size for Round 3: 135716\n",
      "74\n",
      "['step1_rr: 73', 'step2_rr: 73', 'step3_rr: 73', 'step4_rr: 73', 'step5_rr: 73']\n",
      "empirical response rate 0.05572392497712717\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05843424716620882 0.0691054260830031 0.010671178916794283\n",
      "remaining size for Round 3: 135815\n",
      "Calculated size for Round 3: 7068.980605534773\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.031879856011243914 0.07214873820026954 0.04026888218902563\n",
      "remaining size for Round 4: 128747\n",
      "Calculated size for Round 4: 5932.84746128694\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03613121920102868 0.07380801144802436 0.03767679224699568\n",
      "remaining size for last Round 5: 122815\n",
      "75\n",
      "['step1_rr: 74', 'step2_rr: 74', 'step3_rr: 74', 'step4_rr: 74', 'step5_rr: 74']\n",
      "empirical response rate 0.056724611161939616\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4252.211310393531\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.0382269161200339 0.07517961557695868 0.03695269945692478\n",
      "remaining size for Round 3: 135748\n",
      "Calculated size for Round 3: 8073.871400156355\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.035318267017075446 0.07071160515164494 0.0353933381345695\n",
      "remaining size for Round 4: 127675\n",
      "76\n",
      "['step1_rr: 75', 'step2_rr: 75', 'step3_rr: 75', 'step4_rr: 75', 'step5_rr: 75']\n",
      "empirical response rate 0.053979871912168347\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4069.8918802880116\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.035086038857732385 0.06938737803952517 0.03430133918179279\n",
      "remaining size for Round 3: 135931\n",
      "77\n",
      "['step1_rr: 76', 'step2_rr: 76', 'step3_rr: 76', 'step4_rr: 76', 'step5_rr: 76']\n",
      "empirical response rate 0.05618138151875572\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4216.080885454846\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.021111667820758274 0.07890850300610479 0.057796835185346514\n",
      "remaining size for Round 3: 135784\n",
      "78\n",
      "['step1_rr: 77', 'step2_rr: 77', 'step3_rr: 77', 'step4_rr: 77', 'step5_rr: 77']\n",
      "empirical response rate 0.05303636779505947\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03629593372358374 0.06978439030312952 0.033488456579545786\n",
      "remaining size for Round 3: 135993\n",
      "79\n",
      "['step1_rr: 78', 'step2_rr: 78', 'step3_rr: 78', 'step4_rr: 78', 'step5_rr: 78']\n",
      "empirical response rate 0.054923376029277216\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4132.498155686146\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05012833743604661 0.07579316106182743 0.02566482362578082\n",
      "remaining size for Round 3: 135868\n",
      "Calculated size for Round 3: 9930.989207474006\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03490212061224758 0.0711170569202876 0.03621493630804001\n",
      "remaining size for Round 4: 125938\n",
      "80\n",
      "['step1_rr: 79', 'step2_rr: 79', 'step3_rr: 79', 'step4_rr: 79', 'step5_rr: 79']\n",
      "empirical response rate 0.05415141811527905\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.055745735445023384 0.06974036946001637 0.013994634014992985\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 5827.383161041974\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.031555674061992424 0.07650261908513334 0.044946945023140915\n",
      "remaining size for Round 4: 130092\n",
      "Calculated size for Round 4: 5656.576675768559\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.02393459893047456 0.0726822829387465 0.04874768400827194\n",
      "remaining size for last Round 5: 124436\n",
      "81\n",
      "['step1_rr: 80', 'step2_rr: 80', 'step3_rr: 80', 'step4_rr: 80', 'step5_rr: 80']\n",
      "empirical response rate 0.05518069533394328\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05181987143548478 0.0766696846060381 0.02484981317055332\n",
      "remaining size for Round 3: 135851\n",
      "Calculated size for Round 3: 9789.92270661903\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03408985981283416 0.07277653863602726 0.0386866788231931\n",
      "remaining size for Round 4: 126062\n",
      "82\n",
      "['step1_rr: 81', 'step2_rr: 81', 'step3_rr: 81', 'step4_rr: 81', 'step5_rr: 81']\n",
      "empirical response rate 0.05572392497712717\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05327547787440785 0.07116575024091366 0.01789027236650581\n",
      "remaining size for Round 3: 135815\n",
      "Calculated size for Round 3: 7962.666517789327\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04877276651535532 0.06999376692085404 0.02122100040549872\n",
      "remaining size for Round 4: 127853\n",
      "Calculated size for Round 4: 6144.618445297023\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03493003034218327 0.06890432872879158 0.033974298386608315\n",
      "remaining size for last Round 5: 121709\n",
      "83\n",
      "['step1_rr: 82', 'step2_rr: 82', 'step3_rr: 82', 'step4_rr: 82', 'step5_rr: 82']\n",
      "empirical response rate 0.05558096980786825\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4176.173813910594\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.060967939585467805 0.06811381570722856 0.007145876121760757\n",
      "remaining size for Round 3: 135824\n",
      "Calculated size for Round 3: 6210.4782410704765\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.02199367971571077 0.07514164933428974 0.05314796961857897\n",
      "remaining size for Round 4: 129614\n",
      "Calculated size for Round 4: 5594.540846530497\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.036342650195138264 0.0707346070336072 0.03439195683846894\n",
      "remaining size for last Round 5: 124020\n",
      "84\n",
      "['step1_rr: 83', 'step2_rr: 83', 'step3_rr: 83', 'step4_rr: 83', 'step5_rr: 83']\n",
      "empirical response rate 0.056038426349496795\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "85\n",
      "['step1_rr: 84', 'step2_rr: 84', 'step3_rr: 84', 'step4_rr: 84', 'step5_rr: 84']\n",
      "empirical response rate 0.05466605672461116\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.046881934899255115 0.0681112344791078 0.021229299579852687\n",
      "remaining size for Round 3: 135885\n",
      "Calculated size for Round 3: 8419.704587834109\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03627967201544677 0.07260332768901893 0.03632365567357217\n",
      "remaining size for Round 4: 127466\n",
      "86\n",
      "['step1_rr: 85', 'step2_rr: 85', 'step3_rr: 85', 'step4_rr: 85', 'step5_rr: 85']\n",
      "empirical response rate 0.053579597438243365\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4043.352644626449\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04884540072854049 0.068755297805372 0.01990989707683151\n",
      "remaining size for Round 3: 135957\n",
      "Calculated size for Round 3: 5575.404505414518\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.05892708303991541 0.06707553667641286 0.008148453636497452\n",
      "remaining size for Round 4: 130382\n",
      "Calculated size for Round 4: 5659.397549962436\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03793699680369186 0.07474677390445447 0.036809777100762615\n",
      "remaining size for last Round 5: 124723\n",
      "87\n",
      "['step1_rr: 86', 'step2_rr: 86', 'step3_rr: 86', 'step4_rr: 86', 'step5_rr: 86']\n",
      "empirical response rate 0.054180009149130834\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4083.166195613249\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.050346248550457405 0.07393433316194273 0.023588084611485323\n",
      "remaining size for Round 3: 135917\n",
      "Calculated size for Round 3: 10522.766518241293\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03722990227354419 0.07190288973998914 0.03467298746644495\n",
      "remaining size for Round 4: 125395\n",
      "88\n",
      "['step1_rr: 87', 'step2_rr: 87', 'step3_rr: 87', 'step4_rr: 87', 'step5_rr: 87']\n",
      "empirical response rate 0.05400846294602013\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.035412226265070415 0.07237452005784265 0.03696229379277223\n",
      "remaining size for Round 3: 135929\n",
      "Calculated size for Round 3: 8340.032403277186\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.037247326645478473 0.07663462070295787 0.0393872940574794\n",
      "remaining size for Round 4: 127589\n",
      "89\n",
      "['step1_rr: 88', 'step2_rr: 88', 'step3_rr: 88', 'step4_rr: 88', 'step5_rr: 88']\n",
      "empirical response rate 0.057467978042086004\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4301.689819632026\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.0354844943386024 0.06903348477753782 0.03354899043893542\n",
      "remaining size for Round 3: 135699\n",
      "Calculated size for Round 3: 6209.801361343093\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.019520206447260633 0.07291026731125473 0.0533900608639941\n",
      "remaining size for Round 4: 129490\n",
      "90\n",
      "['step1_rr: 89', 'step2_rr: 89', 'step3_rr: 89', 'step4_rr: 89', 'step5_rr: 89']\n",
      "empirical response rate 0.05595265324794144\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03337145402853884 0.07940141644068077 0.04602996241214193\n",
      "remaining size for Round 3: 135800\n",
      "Calculated size for Round 3: 8323.145346904686\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.0374029336676213 0.07559330444439186 0.03819037077677056\n",
      "remaining size for Round 4: 127477\n",
      "91\n",
      "['step1_rr: 90', 'step2_rr: 90', 'step3_rr: 90', 'step4_rr: 90', 'step5_rr: 90']\n",
      "empirical response rate 0.056209972552607505\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4217.9819182904175\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03965518738456652 0.07622847363722733 0.03657328625266081\n",
      "remaining size for Round 3: 135783\n",
      "92\n",
      "['step1_rr: 91', 'step2_rr: 91', 'step3_rr: 91', 'step4_rr: 91', 'step5_rr: 91']\n",
      "empirical response rate 0.055666742909423604\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4181.87311403394\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.017028228527053182 0.07637336984016864 0.059345141313115454\n",
      "remaining size for Round 3: 135819\n",
      "Calculated size for Round 3: 5635.676079326155\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04966811318693942 0.07424129530410727 0.024573182117167844\n",
      "remaining size for Round 4: 130184\n",
      "Calculated size for Round 4: 7763.669352496701\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.037568385107026536 0.07505721752071776 0.03748883241369122\n",
      "remaining size for last Round 5: 122421\n",
      "93\n",
      "['step1_rr: 92', 'step2_rr: 92', 'step3_rr: 92', 'step4_rr: 92', 'step5_rr: 92']\n",
      "empirical response rate 0.05609560841720036\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "94\n",
      "['step1_rr: 93', 'step2_rr: 93', 'step3_rr: 93', 'step4_rr: 93', 'step5_rr: 93']\n",
      "empirical response rate 0.05340805123513266\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4031.9825257930215\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.028377005165123686 0.08032060094415654 0.05194359577903285\n",
      "remaining size for Round 3: 135969\n",
      "Calculated size for Round 3: 6007.366696431663\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.02286511125566243 0.07686594992618595 0.05400083867052352\n",
      "remaining size for Round 4: 129962\n",
      "95\n",
      "['step1_rr: 94', 'step2_rr: 94', 'step3_rr: 94', 'step4_rr: 94', 'step5_rr: 94']\n",
      "empirical response rate 0.05349382433668801\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4037.6672970440713\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.03653745532354103 0.07291340459113285 0.03637594926759182\n",
      "remaining size for Round 3: 135963\n",
      "Calculated size for Round 3: 7261.844597234258\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.0247248184418945 0.07509807916773086 0.05037326072583635\n",
      "remaining size for Round 4: 128702\n",
      "96\n",
      "['step1_rr: 95', 'step2_rr: 95', 'step3_rr: 95', 'step4_rr: 95', 'step5_rr: 95']\n",
      "empirical response rate 0.05443732845379689\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4100.237767911125\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.01783259069858378 0.07218459379168457 0.05435200309310079\n",
      "remaining size for Round 3: 135900\n",
      "Calculated size for Round 3: 4975.141842447518\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.037657626985590435 0.07520048753240409 0.037542860546813654\n",
      "remaining size for Round 4: 130925\n",
      "Calculated size for Round 4: 7716.914629962007\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.037598380630556226 0.07491129855119515 0.03731291792063892\n",
      "remaining size for last Round 5: 123209\n",
      "97\n",
      "['step1_rr: 96', 'step2_rr: 96', 'step3_rr: 96', 'step4_rr: 96', 'step5_rr: 96']\n",
      "empirical response rate 0.05200709057639524\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "98\n",
      "['step1_rr: 97', 'step2_rr: 97', 'step3_rr: 97', 'step4_rr: 97', 'step5_rr: 97']\n",
      "empirical response rate 0.05652447392497713\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "99\n",
      "['step1_rr: 98', 'step2_rr: 98', 'step3_rr: 98', 'step4_rr: 98', 'step5_rr: 98']\n",
      "empirical response rate 0.05460887465690759\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.048414883004693106 0.07307915351003869 0.02466427050534558\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 10204.89607811533\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04067027321936518 0.07914006137461627 0.03846978815525109\n",
      "remaining size for Round 4: 125685\n",
      "100\n",
      "['step1_rr: 99', 'step2_rr: 99', 'step3_rr: 99', 'step4_rr: 99', 'step5_rr: 99']\n",
      "empirical response rate 0.055380832570905765\n",
      "{'RF__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.04015394086316739 0.07702591012940288 0.03687196926623549\n",
      "remaining size for Round 3: 135838\n",
      "Calculated size for Round 3: 7573.905444816961\n",
      "{'RF__n_estimators': 50}\n",
      "orr termination 0.028180127139910038 0.08273350551667177 0.05455337837676173\n",
      "remaining size for Round 4: 128265\n"
     ]
    }
   ],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "highest_true_rr = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    highest_true_rr.append(np.max(dt_design_5['plan_response_rate']))\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZSYI_uHYKNRh",
   "metadata": {
    "id": "ZSYI_uHYKNRh"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "XOOp7mX4KNRh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707455312538,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "XOOp7mX4KNRh",
    "outputId": "4079a555-223e-4303-b5cf-4c8149044368"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step1_rr</th>\n",
       "      <th>step2_rr</th>\n",
       "      <th>step3_rr</th>\n",
       "      <th>step4_rr</th>\n",
       "      <th>step5_rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.063155</td>\n",
       "      <td>0.065021</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.063836</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.064696</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.060285</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.064135</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.061347</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.066441</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    step1_rr  step2_rr  step3_rr  step4_rr  step5_rr\n",
       "0      0.055  0.063155  0.065021  0.068471  0.068471\n",
       "1      0.055  0.063836  0.068471  0.068471       NaN\n",
       "2      0.055  0.064696  0.068471  0.068471  0.068471\n",
       "3      0.055  0.060285  0.068471  0.068471       NaN\n",
       "4      0.055  0.064135  0.065973  0.068471  0.068471\n",
       "..       ...       ...       ...       ...       ...\n",
       "95     0.055  0.061347  0.068471  0.068471  0.068471\n",
       "96     0.055  0.068471       NaN       NaN       NaN\n",
       "97     0.055  0.068471       NaN       NaN       NaN\n",
       "98     0.055  0.068471  0.068471  0.068471       NaN\n",
       "99     0.055  0.066441  0.068471  0.068471       NaN\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "UVSfzptULdKK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707455312539,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "UVSfzptULdKK",
    "outputId": "25238bb4-606a-4335-c57e-2a862740e8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7 (1.0)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ZwypDIjzKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707455312539,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "ZwypDIjzKNRi",
    "outputId": "c3f67f52-4e4b-481c-f178-c818e5d49d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_rr: 0.055 (0.000)\n",
      "step2_rr: 0.066 (0.003)\n",
      "step3_rr: 0.068 (0.002)\n",
      "step4_rr: 0.068 (0.001)\n",
      "step5_rr: 0.068 (0.001)\n"
     ]
    }
   ],
   "source": [
    "# orr for each round:\n",
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "vg_qWpVzKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1707455666262,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "vg_qWpVzKNRi",
    "outputId": "874fb9b7-97f0-4b10-a7aa-66f996462b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.066 (0.001)\n"
     ]
    }
   ],
   "source": [
    "# overall orr:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "li_BxdgNKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1707455718378,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "li_BxdgNKNRi",
    "outputId": "6c8b96d4-7110-43dd-c8de-19128d835157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.068 (0.001)\n"
     ]
    }
   ],
   "source": [
    "# adaptive learning orr:\n",
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3TMTjJaKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1707455695027,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "f3TMTjJaKNRi",
    "outputId": "7ffecc55-55c3-4be8-fabb-bbddf7a3e7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.068 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# highest true rr:\n",
    "mean_result = (np.mean(highest_true_rr))\n",
    "std_result = (np.std(highest_true_rr))\n",
    "print(f\"Mean: {mean_result:.3f} ({std_result:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ObG-atEyKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1707455738828,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "ObG-atEyKNRi",
    "outputId": "ab0d5c93-6eaf-40f8-f32c-f3f731fdbd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_plan_number: nan (nan)\n",
      "step2_plan_number: 5.1 (4.0)\n",
      "step3_plan_number: 2.9 (2.3)\n",
      "step4_plan_number: 2.2 (1.6)\n",
      "step5_plan_number: 1.5 (1.0)\n"
     ]
    }
   ],
   "source": [
    "# average plan number for each round:\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "PxuuVwAwKNRi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1707455312547,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "PxuuVwAwKNRi",
    "outputId": "9681e922-ac43-44a2-b324-fe62886e31a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': 0.72,\n",
       " 'early_stopping_plan': 0.72,\n",
       " 'early_stopping_orr': 0.0,\n",
       " 'early_stopping_size': 0.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# early stopping probabilities:\n",
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "mxO9LpGvKNRj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1707455312547,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "mxO9LpGvKNRj",
    "outputId": "56e60500-3374-438a-d590-43247fb17f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130706.03 6259.832643857182\n"
     ]
    }
   ],
   "source": [
    "# sample size for the last round:\n",
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "rhySjyfeKNRj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707455312540,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "rhySjyfeKNRj",
    "outputId": "2ba7f5f0-b645-417f-dba0-d2658544dc1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_sample_size: 34976.000 (0.000)\n",
      "step2_sample_size: 21802.249 (45690.069)\n",
      "step3_sample_size: 56065.754 (62391.363)\n",
      "step4_sample_size: 64649.525 (60619.740)\n",
      "step5_sample_size: 123252.536 (1149.734)\n"
     ]
    }
   ],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "UntkTQE5VJn0",
   "metadata": {
    "id": "UntkTQE5VJn0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities for better performance compared to the benchmark:\n",
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O9EfgKcZKSFo",
   "metadata": {
    "id": "O9EfgKcZKSFo"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4VbKqb3LKSF_",
   "metadata": {
    "id": "4VbKqb3LKSF_"
   },
   "outputs": [],
   "source": [
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            # ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0))\n",
    "#             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "                    # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "#                     ('RF', ensemble.RandomForestClassifier(n_estimators=200, criterion='gini', random_state=0))\n",
    "                    ('XGB', XGBClassifier(n_estimators=50, learning_rate=0.1, random_state=0))\n",
    "                   ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "    param_grid = {\n",
    "        # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "        # 'LR__C': [0.01] # [0.01, 0.05, 0.1]\n",
    "        # 'Ridge__C': [0.01]\n",
    "        # 'SVM__C': [0.01, 0.05, 0.1]\n",
    "#         'RF__n_estimators': [50] # [10, 30, 50]\n",
    "        'XGB__learning_rate': [0.01, 0.1, 1],\n",
    "        'XGB__n_estimators': [50, 100, 200]\n",
    "#         'XGB__n_estimators': [50]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best fit parameters:\", best_params)\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Rb2RU3mKSGA",
   "metadata": {
    "id": "5Rb2RU3mKSGA"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "oh_V6UXxKSGA",
   "metadata": {
    "id": "oh_V6UXxKSGA"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "sz63YovEKSGA",
   "metadata": {
    "id": "sz63YovEKSGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['step1_rr: 0', 'step2_rr: 0', 'step3_rr: 0', 'step4_rr: 0', 'step5_rr: 0']\n",
      "empirical response rate 0.05655306495882891\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4240.799240494033\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.4767242670059204 0.2383621335029602 -0.2383621335029602\n",
      "1 0.4767242670059204 0.2383621335029602 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135760\n",
      "2\n",
      "['step1_rr: 1', 'step2_rr: 1', 'step3_rr: 1', 'step4_rr: 1', 'step5_rr: 1']\n",
      "empirical response rate 0.054637465690759376\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.1538586428115833 0.20905391458355962 0.055195271771976334\n",
      "remaining size for Round 3: 135887\n",
      "Calculated size for Round 3: 4572.518073556432\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.00424320837961517 0.11724445223808289 0.11300124385846771\n",
      "remaining size for Round 4: 131315\n",
      "3\n",
      "['step1_rr: 2', 'step2_rr: 2', 'step3_rr: 2', 'step4_rr: 2', 'step5_rr: 2']\n",
      "empirical response rate 0.05303636779505947\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.2778062123940105 0.19633791098992026 -0.08146830140409023\n",
      "3 0.2778062123940105 0.19633791098992026 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135993\n",
      "4\n",
      "['step1_rr: 3', 'step2_rr: 3', 'step3_rr: 3', 'step4_rr: 3', 'step5_rr: 3']\n",
      "empirical response rate 0.054265782250686186\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4088.8561455390104\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.0943772171834874 0.2097887247800827 0.1154115075965953\n",
      "remaining size for Round 3: 135912\n",
      "Calculated size for Round 3: 7444.694707496396\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.059354860335588455 0.23741944134235382 0.17806458100676537\n",
      "remaining size for Round 4: 128468\n",
      "5\n",
      "['step1_rr: 4', 'step2_rr: 4', 'step3_rr: 4', 'step4_rr: 4', 'step5_rr: 4']\n",
      "empirical response rate 0.05772529734675206\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4318.826898633964\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.023331182654892084 0.10499267318918555 0.08166149053429347\n",
      "remaining size for Round 3: 135682\n",
      "Calculated size for Round 3: 6255.034948077894\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03591011439496744 0.07162889093160629 0.03571877653663885\n",
      "remaining size for Round 4: 129427\n",
      "6\n",
      "['step1_rr: 5', 'step2_rr: 5', 'step3_rr: 5', 'step4_rr: 5', 'step5_rr: 5']\n",
      "empirical response rate 0.05458028362305581\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.2540257086576609 0.21495239309970743 -0.03907331555795346\n",
      "6 0.2540257086576609 0.21495239309970743 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135891\n",
      "7\n",
      "['step1_rr: 6', 'step2_rr: 6', 'step3_rr: 6', 'step4_rr: 6', 'step5_rr: 6']\n",
      "empirical response rate 0.05775388838060384\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4320.7313323598355\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03202746371373054 0.1754001082602729 0.14337264454654236\n",
      "remaining size for Round 3: 135680\n",
      "Calculated size for Round 3: 4902.4311280776255\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.04382728033686349 0.17550195291796697 0.1316746725811035\n",
      "remaining size for Round 4: 130778\n",
      "Calculated size for Round 4: 6424.5259051579615\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.06362372654511436 0.08515557898085195 0.02153185243573759\n",
      "remaining size for last Round 5: 124354\n",
      "8\n",
      "['step1_rr: 7', 'step2_rr: 7', 'step3_rr: 7', 'step4_rr: 7', 'step5_rr: 7']\n",
      "empirical response rate 0.05749656907593779\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4303.593688344371\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.015353106761763664 0.9978132247924805 0.9824601180307168\n",
      "remaining size for Round 3: 135697\n",
      "9\n",
      "['step1_rr: 8', 'step2_rr: 8', 'step3_rr: 8', 'step4_rr: 8', 'step5_rr: 8']\n",
      "empirical response rate 0.0553236505032022\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4159.079338458144\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.07098868920642469 0.18281252682209015 0.11182383761566546\n",
      "remaining size for Round 3: 135841\n",
      "Calculated size for Round 3: 6207.113256656187\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.06123025715351105 0.2449210286140442 0.18369077146053314\n",
      "remaining size for Round 4: 129634\n",
      "10\n",
      "['step1_rr: 9', 'step2_rr: 9', 'step3_rr: 9', 'step4_rr: 9', 'step5_rr: 9']\n",
      "empirical response rate 0.0536939615736505\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.0654441833294668 0.12181494385004044 0.05637076052057363\n",
      "remaining size for Round 3: 135950\n",
      "11\n",
      "['step1_rr: 10', 'step2_rr: 10', 'step3_rr: 10', 'step4_rr: 10', 'step5_rr: 10']\n",
      "empirical response rate 0.05460887465690759\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.05613701542908572 0.11384645312260457 0.05770943769351885\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 8544.561077957635\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.19558250856849052 0.11738142461552142 -0.0782010839529691\n",
      "11 0.19558250856849052 0.11738142461552142 early stop at Round 3\n",
      "early stop, remaining size for Round4: 127345\n",
      "12\n",
      "['step1_rr: 11', 'step2_rr: 11', 'step3_rr: 11', 'step4_rr: 11', 'step5_rr: 11']\n",
      "empirical response rate 0.05275045745654163\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 3988.418451118696\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.06622835701798896 0.22245801845082225 0.1562296614328333\n",
      "remaining size for Round 3: 136012\n",
      "Calculated size for Round 3: 6242.525673089111\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.060662919500040303 0.08127484498237986 0.020611925482339553\n",
      "remaining size for Round 4: 129770\n",
      "Calculated size for Round 4: 5751.103417243141\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.032966602367128714 0.07856157347810377 0.04559497111097506\n",
      "remaining size for last Round 5: 124019\n",
      "13\n",
      "['step1_rr: 12', 'step2_rr: 12', 'step3_rr: 12', 'step4_rr: 12', 'step5_rr: 12']\n",
      "empirical response rate 0.05626715462031107\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4221.784173594918\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.03435448737571409 0.17207525670528412 0.13772076932957003\n",
      "remaining size for Round 3: 135779\n",
      "14\n",
      "['step1_rr: 13', 'step2_rr: 13', 'step3_rr: 13', 'step4_rr: 13', 'step5_rr: 13']\n",
      "empirical response rate 0.05466605672461116\n",
      "Best fit parameters: {'XGB__learning_rate': 1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.037340664286316265 0.10145577043294907 0.0641151061466328\n",
      "remaining size for Round 3: 135885\n",
      "15\n",
      "['step1_rr: 14', 'step2_rr: 14', 'step3_rr: 14', 'step4_rr: 14', 'step5_rr: 14']\n",
      "empirical response rate 0.05375114364135407\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03313533094146097 0.11553670803639741 0.08240137709493645\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 8179.3978640491405\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.050462809137879025 0.10036011040210724 0.049897301264228214\n",
      "remaining size for Round 4: 127767\n",
      "16\n",
      "['step1_rr: 15', 'step2_rr: 15', 'step3_rr: 15', 'step4_rr: 15', 'step5_rr: 15']\n",
      "empirical response rate 0.05466605672461116\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.4632480651281502 0.34682285785675043 -0.11642520727139977\n",
      "16 0.4632480651281502 0.34682285785675043 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135885\n",
      "17\n",
      "['step1_rr: 16', 'step2_rr: 16', 'step3_rr: 16', 'step4_rr: 16', 'step5_rr: 16']\n",
      "empirical response rate 0.05595265324794144\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03731245712385476 0.07331182062625885 0.03599936350240409\n",
      "remaining size for Round 3: 135800\n",
      "18\n",
      "['step1_rr: 17', 'step2_rr: 17', 'step3_rr: 17', 'step4_rr: 17', 'step5_rr: 17']\n",
      "empirical response rate 0.05480901189387008\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4124.9058208503975\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.060978710651397705 0.24391484260559082 0.18293613195419312\n",
      "remaining size for Round 3: 135876\n",
      "19\n",
      "['step1_rr: 18', 'step2_rr: 18', 'step3_rr: 18', 'step4_rr: 18', 'step5_rr: 18']\n",
      "empirical response rate 0.05598124428179323\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03690884089131765 0.07380913943052292 0.03690029853920527\n",
      "remaining size for Round 3: 135798\n",
      "20\n",
      "['step1_rr: 19', 'step2_rr: 19', 'step3_rr: 19', 'step4_rr: 19', 'step5_rr: 19']\n",
      "empirical response rate 0.05489478499542543\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.7124534994363785 0.11874224990606308 -0.5937112495303154\n",
      "20 0.7124534994363785 0.11874224990606308 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135870\n",
      "21\n",
      "['step1_rr: 20', 'step2_rr: 20', 'step3_rr: 20', 'step4_rr: 20', 'step5_rr: 20']\n",
      "empirical response rate 0.05486619396157365\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4128.701861019453\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.17072370250481222 0.19903890777156652 0.028315205266754295\n",
      "remaining size for Round 3: 135872\n",
      "Calculated size for Round 3: 6389.373787638449\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.3513605666849076 0.23273913039888874 -0.11862143628601887\n",
      "21 0.3513605666849076 0.23273913039888874 early stop at Round 3\n",
      "early stop, remaining size for Round4: 129483\n",
      "22\n",
      "['step1_rr: 21', 'step2_rr: 21', 'step3_rr: 21', 'step4_rr: 21', 'step5_rr: 21']\n",
      "empirical response rate 0.05518069533394328\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.24154676496982574 0.24154676496982574 0.0\n",
      "22 0.24154676496982574 0.24154676496982574 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135851\n",
      "23\n",
      "['step1_rr: 22', 'step2_rr: 22', 'step3_rr: 22', 'step4_rr: 22', 'step5_rr: 22']\n",
      "empirical response rate 0.054780420860018296\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.01433324331058973 0.20719729804272918 0.19286405473213947\n",
      "remaining size for Round 3: 135877\n",
      "Calculated size for Round 3: 5373.690853956164\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.06152815909751589 0.12183600664138794 0.06030784754387205\n",
      "remaining size for Round 4: 130504\n",
      "24\n",
      "['step1_rr: 23', 'step2_rr: 23', 'step3_rr: 23', 'step4_rr: 23', 'step5_rr: 23']\n",
      "empirical response rate 0.05415141811527905\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.19602853430809836 0.2560127526521683 0.05998421834406992\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 6330.290395051026\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.042644841596484184 0.34148824673820993 0.29884340514172575\n",
      "remaining size for Round 4: 129589\n",
      "Calculated size for Round 4: 6824.855248932426\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03720610523292712 0.07216930389404297 0.03496319866111585\n",
      "remaining size for last Round 5: 122765\n",
      "25\n",
      "['step1_rr: 24', 'step2_rr: 24', 'step3_rr: 24', 'step4_rr: 24', 'step5_rr: 24']\n",
      "empirical response rate 0.05400846294602013\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "Best fit parameters: {'XGB__learning_rate': 1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.010925463839681846 0.07459320734995656 0.06366774351027471\n",
      "remaining size for Round 3: 135929\n",
      "Calculated size for Round 3: 5810.1549419204475\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.02684758662543553 0.0795987993478775 0.05275121272244197\n",
      "remaining size for Round 4: 130119\n",
      "26\n",
      "['step1_rr: 25', 'step2_rr: 25', 'step3_rr: 25', 'step4_rr: 25', 'step5_rr: 25']\n",
      "empirical response rate 0.056038426349496795\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4206.576669795643\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.024138672373608835 0.1218695405274566 0.09773086815384777\n",
      "remaining size for Round 3: 135794\n",
      "Calculated size for Round 3: 5621.864048804033\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.04222700213053873 0.08463075011968613 0.042403747989147395\n",
      "remaining size for Round 4: 130173\n",
      "27\n",
      "['step1_rr: 26', 'step2_rr: 26', 'step3_rr: 26', 'step4_rr: 26', 'step5_rr: 26']\n",
      "empirical response rate 0.05377973467520585\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 100}\n",
      "orr termination 0.010827318782852013 0.08613141626119614 0.07530409747834413\n",
      "remaining size for Round 3: 135944\n",
      "28\n",
      "['step1_rr: 27', 'step2_rr: 27', 'step3_rr: 27', 'step4_rr: 27', 'step5_rr: 27']\n",
      "empirical response rate 0.0529791857273559\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4003.567322548448\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.12398451838577605 0.1873117757569954 0.06332725737121934\n",
      "remaining size for Round 3: 135997\n",
      "Calculated size for Round 3: 6754.169760956738\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.3558392639773622 0.13804996653509205 -0.21778929744227016\n",
      "28 0.3558392639773622 0.13804996653509205 early stop at Round 3\n",
      "early stop, remaining size for Round4: 129243\n",
      "29\n",
      "['step1_rr: 28', 'step2_rr: 28', 'step3_rr: 28', 'step4_rr: 28', 'step5_rr: 28']\n",
      "empirical response rate 0.05312214089661482\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4013.037453633404\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.062204381435989484 0.17718349823343002 0.11497911679744054\n",
      "remaining size for Round 3: 135987\n",
      "Calculated size for Round 3: 5481.993886965835\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.05447838078379097 0.144817605413715 0.09033922462992403\n",
      "remaining size for Round 4: 130506\n",
      "Calculated size for Round 4: 7064.098262172105\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.02480294791475614 0.07184968143701553 0.047046733522259396\n",
      "remaining size for last Round 5: 123442\n",
      "30\n",
      "['step1_rr: 29', 'step2_rr: 29', 'step3_rr: 29', 'step4_rr: 29', 'step5_rr: 29']\n",
      "empirical response rate 0.054837602927721864\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.06136992717526554 0.12468360364437103 0.06331367646910549\n",
      "remaining size for Round 3: 135874\n",
      "31\n",
      "['step1_rr: 30', 'step2_rr: 30', 'step3_rr: 30', 'step4_rr: 30', 'step5_rr: 30']\n",
      "empirical response rate 0.05518069533394328\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.30365771610030146 0.12050341462751918 -0.18315430147278228\n",
      "31 0.30365771610030146 0.12050341462751918 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135851\n",
      "32\n",
      "['step1_rr: 31', 'step2_rr: 31', 'step3_rr: 31', 'step4_rr: 31', 'step5_rr: 31']\n",
      "empirical response rate 0.05435155535224154\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4094.5466697157462\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.011393970581729597 0.12203119695186615 0.11063722637013655\n",
      "remaining size for Round 3: 135906\n",
      "33\n",
      "['step1_rr: 32', 'step2_rr: 32', 'step3_rr: 32', 'step4_rr: 32', 'step5_rr: 32']\n",
      "empirical response rate 0.05332227813357731\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4026.2983311032726\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.18215629178852685 0.4067137685594457 0.22455747677091883\n",
      "remaining size for Round 3: 135974\n",
      "Calculated size for Round 3: 4760.512918854601\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.05966412013907995 0.20865774732775833 0.14899362718867837\n",
      "remaining size for Round 4: 131214\n",
      "Calculated size for Round 4: 5874.924880443516\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.041429722063284526 0.07999465248256463 0.0385649304192801\n",
      "remaining size for last Round 5: 125340\n",
      "34\n",
      "['step1_rr: 33', 'step2_rr: 33', 'step3_rr: 33', 'step4_rr: 33', 'step5_rr: 33']\n",
      "empirical response rate 0.05375114364135407\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.010263211567553958 0.15405068134611108 0.1437874697785571\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 5216.685998283433\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.23513972759246826 0.11756986379623413 -0.11756986379623413\n",
      "34 0.23513972759246826 0.11756986379623413 early stop at Round 3\n",
      "early stop, remaining size for Round4: 130730\n",
      "35\n",
      "['step1_rr: 34', 'step2_rr: 34', 'step3_rr: 34', 'step4_rr: 34', 'step5_rr: 34']\n",
      "empirical response rate 0.054637465690759376\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.025332838145661 0.11986810714006424 0.09453526899440323\n",
      "remaining size for Round 3: 135887\n",
      "36\n",
      "['step1_rr: 35', 'step2_rr: 35', 'step3_rr: 35', 'step4_rr: 35', 'step5_rr: 35']\n",
      "empirical response rate 0.05669602012808783\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4250.309141054068\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03482903740255068 0.12063232389310269 0.08580328649055201\n",
      "remaining size for Round 3: 135750\n",
      "Calculated size for Round 3: 6987.056368040549\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.04019418245130118 0.07914623618125916 0.038952053729957976\n",
      "remaining size for Round 4: 128763\n",
      "37\n",
      "['step1_rr: 36', 'step2_rr: 36', 'step3_rr: 36', 'step4_rr: 36', 'step5_rr: 36']\n",
      "empirical response rate 0.05600983531564501\n",
      "Best fit parameters: {'XGB__learning_rate': 1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4204.676016429063\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.07472885491439725 0.07325864745766245 -0.001470207456734804\n",
      "37 0.07472885491439725 0.07325864745766245 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135796\n",
      "38\n",
      "['step1_rr: 37', 'step2_rr: 37', 'step3_rr: 37', 'step4_rr: 37', 'step5_rr: 37']\n",
      "empirical response rate 0.05458028362305581\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.038265149297317655 0.16643503555695943 0.12816988625964176\n",
      "remaining size for Round 3: 135891\n",
      "Calculated size for Round 3: 6609.5599731624525\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.01938845762884587 0.09156914800405502 0.07218069037520916\n",
      "remaining size for Round 4: 129282\n",
      "39\n",
      "['step1_rr: 38', 'step2_rr: 38', 'step3_rr: 38', 'step4_rr: 38', 'step5_rr: 38']\n",
      "empirical response rate 0.05535224153705398\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4160.97847079396\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.24529235064983368 0.24529235064983368 0.0\n",
      "39 0.24529235064983368 0.24529235064983368 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135840\n",
      "40\n",
      "['step1_rr: 39', 'step2_rr: 39', 'step3_rr: 39', 'step4_rr: 39', 'step5_rr: 39']\n",
      "empirical response rate 0.05489478499542543\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.2401895970106125 0.12009479850530624 -0.12009479850530624\n",
      "40 0.2401895970106125 0.12009479850530624 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135870\n",
      "41\n",
      "['step1_rr: 40', 'step2_rr: 40', 'step3_rr: 40', 'step4_rr: 40', 'step5_rr: 40']\n",
      "empirical response rate 0.05529505946935041\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4157.18026960777\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.020120598192412447 0.0813535675406456 0.06123296934823315\n",
      "remaining size for Round 3: 135843\n",
      "42\n",
      "['step1_rr: 41', 'step2_rr: 41', 'step3_rr: 41', 'step4_rr: 41', 'step5_rr: 41']\n",
      "empirical response rate 0.05363677950594693\n",
      "Best fit parameters: {'XGB__learning_rate': 1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.06866678523966821 0.12145765125751495 0.052790866017846744\n",
      "remaining size for Round 3: 135953\n",
      "43\n",
      "['step1_rr: 42', 'step2_rr: 42', 'step3_rr: 42', 'step4_rr: 42', 'step5_rr: 42']\n",
      "empirical response rate 0.05377973467520585\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.04223662242293358 0.16894648969173431 0.12670986726880074\n",
      "remaining size for Round 3: 135944\n",
      "44\n",
      "['step1_rr: 43', 'step2_rr: 43', 'step3_rr: 43', 'step4_rr: 43', 'step5_rr: 43']\n",
      "empirical response rate 0.05583828911253431\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4193.273425323935\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.3551523901340754 0.796098162719017 0.4409457725849416\n",
      "remaining size for Round 3: 135807\n",
      "Calculated size for Round 3: 6049.679411736004\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.06475057398569688 0.31295180518902055 0.24820123120332366\n",
      "remaining size for Round 4: 129758\n",
      "Calculated size for Round 4: 5673.814046844306\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.03559948434094433 0.10206186136780751 0.06646237702686318\n",
      "remaining size for last Round 5: 124085\n",
      "45\n",
      "['step1_rr: 44', 'step2_rr: 44', 'step3_rr: 44', 'step4_rr: 44', 'step5_rr: 44']\n",
      "empirical response rate 0.05555237877401647\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4174.274174005051\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.17781330817978916 0.12097912281751633 -0.05683418536227283\n",
      "45 0.17781330817978916 0.12097912281751633 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135826\n",
      "46\n",
      "['step1_rr: 45', 'step2_rr: 45', 'step3_rr: 45', 'step4_rr: 45', 'step5_rr: 45']\n",
      "empirical response rate 0.0536939615736505\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.061165325343608856 0.24466130137443542 0.18349597603082657\n",
      "remaining size for Round 3: 135950\n",
      "47\n",
      "['step1_rr: 46', 'step2_rr: 46', 'step3_rr: 46', 'step4_rr: 46', 'step5_rr: 46']\n",
      "empirical response rate 0.05449451052150046\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4104.032152159118\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.05113397728360008 0.20456934580489944 0.15343536852129935\n",
      "remaining size for Round 3: 135896\n",
      "Calculated size for Round 3: 9146.89642672227\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.039355537419581574 0.07947564125061035 0.04012010383102878\n",
      "remaining size for Round 4: 126750\n",
      "48\n",
      "['step1_rr: 47', 'step2_rr: 47', 'step3_rr: 47', 'step4_rr: 47', 'step5_rr: 47']\n",
      "empirical response rate 0.055380832570905765\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.38971693723496753 0.19511997494290606 -0.19459696229206147\n",
      "48 0.38971693723496753 0.19511997494290606 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135838\n",
      "49\n",
      "['step1_rr: 48', 'step2_rr: 48', 'step3_rr: 48', 'step4_rr: 48', 'step5_rr: 48']\n",
      "empirical response rate 0.0554951967063129\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4170.4750844497285\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.031240705798026003 0.06288201361894608 0.031641307820920075\n",
      "remaining size for Round 3: 135830\n",
      "50\n",
      "['step1_rr: 49', 'step2_rr: 49', 'step3_rr: 49', 'step4_rr: 49', 'step5_rr: 49']\n",
      "empirical response rate 0.05563815187557182\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4179.973283933777\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.23774392902851105 0.23774392902851105 0.0\n",
      "50 0.23774392902851105 0.23774392902851105 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135821\n",
      "51\n",
      "['step1_rr: 50', 'step2_rr: 50', 'step3_rr: 50', 'step4_rr: 50', 'step5_rr: 50']\n",
      "empirical response rate 0.05586688014638609\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4195.17369890541\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.015797428900341772 0.1253683865070343 0.10957095760669253\n",
      "remaining size for Round 3: 135805\n",
      "52\n",
      "['step1_rr: 51', 'step2_rr: 51', 'step3_rr: 51', 'step4_rr: 51', 'step5_rr: 51']\n",
      "empirical response rate 0.055809698078682524\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.013166037458199387 0.07891032099723816 0.06574428353903877\n",
      "remaining size for Round 3: 135809\n",
      "53\n",
      "['step1_rr: 52', 'step2_rr: 52', 'step3_rr: 52', 'step4_rr: 52', 'step5_rr: 52']\n",
      "empirical response rate 0.05661024702653248\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "54\n",
      "['step1_rr: 53', 'step2_rr: 53', 'step3_rr: 53', 'step4_rr: 53', 'step5_rr: 53']\n",
      "empirical response rate 0.054837602927721864\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.02240117410441817 0.13005463367074008 0.10765345956632191\n",
      "remaining size for Round 3: 135874\n",
      "Calculated size for Round 3: 5615.3988235223715\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.05772438415211342 0.07267565595957148 0.01495127180745806\n",
      "remaining size for Round 4: 130259\n",
      "Calculated size for Round 4: 6735.078438274807\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.038424681432417014 0.07306581348652057 0.03464113205410355\n",
      "remaining size for last Round 5: 123524\n",
      "55\n",
      "['step1_rr: 54', 'step2_rr: 54', 'step3_rr: 54', 'step4_rr: 54', 'step5_rr: 54']\n",
      "empirical response rate 0.05323650503202196\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4020.614713204558\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.34775459517439683 0.5739196908374063 0.22616509566300952\n",
      "remaining size for Round 3: 135980\n",
      "Calculated size for Round 3: 5875.29485998495\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.046854805327563975 0.23066505434183848 0.1838102490142745\n",
      "remaining size for Round 4: 130105\n",
      "Calculated size for Round 4: 5246.481157355735\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.019659633105497107 0.07425016975785917 0.05459053665236206\n",
      "remaining size for last Round 5: 124859\n",
      "56\n",
      "['step1_rr: 55', 'step2_rr: 55', 'step3_rr: 55', 'step4_rr: 55', 'step5_rr: 55']\n",
      "empirical response rate 0.054780420860018296\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.04334341496166354 0.07271994282017855 0.02937652785851501\n",
      "remaining size for Round 3: 135877\n",
      "Calculated size for Round 3: 7453.094353151416\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.19518599197652803 0.11794255360364675 -0.07724343837288128\n",
      "56 0.19518599197652803 0.11794255360364675 early stop at Round 3\n",
      "early stop, remaining size for Round4: 128424\n",
      "57\n",
      "['step1_rr: 56', 'step2_rr: 56', 'step3_rr: 56', 'step4_rr: 56', 'step5_rr: 56']\n",
      "empirical response rate 0.05446591948764867\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "58\n",
      "['step1_rr: 57', 'step2_rr: 57', 'step3_rr: 57', 'step4_rr: 57', 'step5_rr: 57']\n",
      "empirical response rate 0.053979871912168347\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4069.8918802880116\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.3042651414689507 0.18975512521236176 -0.11451001625658891\n",
      "58 0.3042651414689507 0.18975512521236176 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135931\n",
      "59\n",
      "['step1_rr: 58', 'step2_rr: 58', 'step3_rr: 58', 'step4_rr: 58', 'step5_rr: 58']\n",
      "empirical response rate 0.05546660567246112\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4168.575634817409\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.025726848727124108 0.07393721973472465 0.04821037100760055\n",
      "remaining size for Round 3: 135832\n",
      "Calculated size for Round 3: 5445.338805900535\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 100}\n",
      "orr termination 0.017586192603117473 0.07054340094327927 0.05295720834016179\n",
      "remaining size for Round 4: 130387\n",
      "60\n",
      "['step1_rr: 59', 'step2_rr: 59', 'step3_rr: 59', 'step4_rr: 59', 'step5_rr: 59']\n",
      "empirical response rate 0.05498055809698079\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4136.294704781159\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.13122773007811875 0.12760972101870408 -0.003618009059414673\n",
      "60 0.13122773007811875 0.12760972101870408 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135864\n",
      "61\n",
      "['step1_rr: 60', 'step2_rr: 60', 'step3_rr: 60', 'step4_rr: 60', 'step5_rr: 60']\n",
      "empirical response rate 0.055895471180237875\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "62\n",
      "['step1_rr: 61', 'step2_rr: 61', 'step3_rr: 61', 'step4_rr: 61', 'step5_rr: 61']\n",
      "empirical response rate 0.05312214089661482\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4013.037453633404\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.040922611951828 0.163690447807312 0.12276783585548401\n",
      "remaining size for Round 3: 135987\n",
      "63\n",
      "['step1_rr: 62', 'step2_rr: 62', 'step3_rr: 62', 'step4_rr: 62', 'step5_rr: 62']\n",
      "empirical response rate 0.05689615736505032\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4263.625650278873\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.10053628103311932 0.15092695131897926 0.050390670285859945\n",
      "remaining size for Round 3: 135737\n",
      "Calculated size for Round 3: 8135.8899041534305\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.035994987934827805 0.14397995173931122 0.10798496380448341\n",
      "remaining size for Round 4: 127602\n",
      "64\n",
      "['step1_rr: 63', 'step2_rr: 63', 'step3_rr: 63', 'step4_rr: 63', 'step5_rr: 63']\n",
      "empirical response rate 0.05458028362305581\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "65\n",
      "['step1_rr: 64', 'step2_rr: 64', 'step3_rr: 64', 'step4_rr: 64', 'step5_rr: 64']\n",
      "empirical response rate 0.05592406221408966\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.07237368796000387 0.17418788587023942 0.10181419791023555\n",
      "remaining size for Round 3: 135802\n",
      "Calculated size for Round 3: 7246.1815515364915\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.019880433550255254 0.09322529286146164 0.07334485931120638\n",
      "remaining size for Round 4: 128556\n",
      "66\n",
      "['step1_rr: 65', 'step2_rr: 65', 'step3_rr: 65', 'step4_rr: 65', 'step5_rr: 65']\n",
      "empirical response rate 0.05598124428179323\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.059135738320435005 0.08744731912462878 0.02831158080419377\n",
      "remaining size for Round 3: 135798\n",
      "Calculated size for Round 3: 11899.349197542513\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.042068885105025364 0.08420725911855698 0.04213837401353161\n",
      "remaining size for Round 4: 123899\n",
      "67\n",
      "['step1_rr: 66', 'step2_rr: 66', 'step3_rr: 66', 'step4_rr: 66', 'step5_rr: 66']\n",
      "empirical response rate 0.056781793229643183\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4256.015838229115\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.05067097449563004 0.11921446493654042 0.06854349044091038\n",
      "remaining size for Round 3: 135744\n",
      "Calculated size for Round 3: 7368.197224131923\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.061118350283090477 0.12396728247404099 0.0628489321909505\n",
      "remaining size for Round 4: 128376\n",
      "68\n",
      "['step1_rr: 67', 'step2_rr: 67', 'step3_rr: 67', 'step4_rr: 67', 'step5_rr: 67']\n",
      "empirical response rate 0.05609560841720036\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4210.378166320425\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.18886392594846263 0.2518591299578097 0.06299520400934705\n",
      "remaining size for Round 3: 135790\n",
      "Calculated size for Round 3: 9647.530375735338\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.036620755289483456 0.10795805324455951 0.07133729795507605\n",
      "remaining size for Round 4: 126143\n",
      "Calculated size for Round 4: 5976.078726838699\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.06454197045628735 0.12409386038780212 0.05955188993151478\n",
      "remaining size for last Round 5: 120167\n",
      "69\n",
      "['step1_rr: 68', 'step2_rr: 68', 'step3_rr: 68', 'step4_rr: 68', 'step5_rr: 68']\n",
      "empirical response rate 0.05486619396157365\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4128.701861019453\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.05052733439081996 0.14959367288054223 0.09906633848972227\n",
      "remaining size for Round 3: 135872\n",
      "Calculated size for Round 3: 4744.7004764327885\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.013222587223733278 0.08945811048457028 0.076235523260837\n",
      "remaining size for Round 4: 131128\n",
      "Calculated size for Round 4: 5262.374782323101\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.0575317907483336 0.1204552948474884 0.0629235040991548\n",
      "remaining size for last Round 5: 125866\n",
      "70\n",
      "['step1_rr: 69', 'step2_rr: 69', 'step3_rr: 69', 'step4_rr: 69', 'step5_rr: 69']\n",
      "empirical response rate 0.05363677950594693\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.26306872174793006 0.1190289367618382 -0.14403978498609185\n",
      "70 0.26306872174793006 0.1190289367618382 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135953\n",
      "71\n",
      "['step1_rr: 70', 'step2_rr: 70', 'step3_rr: 70', 'step4_rr: 70', 'step5_rr: 70']\n",
      "empirical response rate 0.055809698078682524\n",
      "Best fit parameters: {'XGB__learning_rate': 1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.04801021656912621 0.09041228938843154 0.04240207281930533\n",
      "remaining size for Round 3: 135809\n",
      "Calculated size for Round 3: 9248.36962422211\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.24401429295539856 0.12200714647769928 -0.12200714647769928\n",
      "71 0.24401429295539856 0.12200714647769928 early stop at Round 3\n",
      "early stop, remaining size for Round4: 126561\n",
      "72\n",
      "['step1_rr: 71', 'step2_rr: 71', 'step3_rr: 71', 'step4_rr: 71', 'step5_rr: 71']\n",
      "empirical response rate 0.05592406221408966\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.35461660847141974 0.22547344539585457 -0.12914316307556517\n",
      "72 0.35461660847141974 0.22547344539585457 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135802\n",
      "73\n",
      "['step1_rr: 72', 'step2_rr: 72', 'step3_rr: 72', 'step4_rr: 72', 'step5_rr: 72']\n",
      "empirical response rate 0.05721065873741994\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4284.557829370903\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 100}\n",
      "orr termination 0.03577210962304234 0.07401538640260696 0.03824327677956462\n",
      "remaining size for Round 3: 135716\n",
      "74\n",
      "['step1_rr: 73', 'step2_rr: 73', 'step3_rr: 73', 'step4_rr: 73', 'step5_rr: 73']\n",
      "empirical response rate 0.05572392497712717\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.06244933548808983 0.26479823516490486 0.20234889967681502\n",
      "remaining size for Round 3: 135815\n",
      "Calculated size for Round 3: 7580.931396095009\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.15107148294024092 0.12103599311378088 -0.030035489826460038\n",
      "74 0.15107148294024092 0.12103599311378088 early stop at Round 3\n",
      "early stop, remaining size for Round4: 128235\n",
      "75\n",
      "['step1_rr: 74', 'step2_rr: 74', 'step3_rr: 74', 'step4_rr: 74', 'step5_rr: 74']\n",
      "empirical response rate 0.056724611161939616\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4252.211310393531\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.022908062666080177 0.1727218631680737 0.14981380050199353\n",
      "remaining size for Round 3: 135748\n",
      "Calculated size for Round 3: 4843.8300059845305\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.08688646749236892 0.11796619451061166 0.031079727018242742\n",
      "remaining size for Round 4: 130905\n",
      "Calculated size for Round 4: 6550.087873367038\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.35037488490343094 0.1946527138352394 -0.15572217106819153\n",
      "75 0.35037488490343094 0.1946527138352394 early stop at Round 4\n",
      "early stop, remaining size for Round5: 124355\n",
      "76\n",
      "['step1_rr: 75', 'step2_rr: 75', 'step3_rr: 75', 'step4_rr: 75', 'step5_rr: 75']\n",
      "empirical response rate 0.053979871912168347\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4069.8918802880116\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 100}\n",
      "orr termination 0.04756749272255989 0.188377636660382 0.1408101439378221\n",
      "remaining size for Round 3: 135931\n",
      "Calculated size for Round 3: 6482.433987635056\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03778851843942386 0.07258533474625022 0.03479681630682636\n",
      "remaining size for Round 4: 129449\n",
      "Calculated size for Round 4: 6053.198186084157\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.3675013706088066 0.12250045686960219 -0.2450009137392044\n",
      "76 0.3675013706088066 0.12250045686960219 early stop at Round 4\n",
      "early stop, remaining size for Round5: 123396\n",
      "77\n",
      "['step1_rr: 76', 'step2_rr: 76', 'step3_rr: 76', 'step4_rr: 76', 'step5_rr: 76']\n",
      "empirical response rate 0.05618138151875572\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4216.080885454846\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.054008898667163505 0.9706552028656006 0.9166463041984371\n",
      "remaining size for Round 3: 135784\n",
      "Calculated size for Round 3: 5514.59607611137\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.036747466772794724 0.1469898670911789 0.11024240031838417\n",
      "remaining size for Round 4: 130270\n",
      "78\n",
      "['step1_rr: 77', 'step2_rr: 77', 'step3_rr: 77', 'step4_rr: 77', 'step5_rr: 77']\n",
      "empirical response rate 0.05303636779505947\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.004157353901992086 0.08798099309206009 0.08382363919006801\n",
      "remaining size for Round 3: 135993\n",
      "79\n",
      "['step1_rr: 78', 'step2_rr: 78', 'step3_rr: 78', 'step4_rr: 78', 'step5_rr: 78']\n",
      "empirical response rate 0.054923376029277216\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4132.498155686146\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.14985285008464144 0.8119419213698819 0.6620890712852404\n",
      "remaining size for Round 3: 135868\n",
      "Calculated size for Round 3: 6195.5170702835485\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.16126100030503 0.24131026302053155 0.08004926271550156\n",
      "remaining size for Round 4: 129673\n",
      "Calculated size for Round 4: 6164.2315313878935\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.045656867572730235 0.1827927662876703 0.13713589871494006\n",
      "remaining size for last Round 5: 123509\n",
      "80\n",
      "['step1_rr: 79', 'step2_rr: 79', 'step3_rr: 79', 'step4_rr: 79', 'step5_rr: 79']\n",
      "empirical response rate 0.05415141811527905\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "Best fit parameters: {'XGB__learning_rate': 1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.03893774362373546 0.08258070240217173 0.04364295877843627\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 6056.826357851512\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.33509646877212923 0.11916808092728376 -0.21592838784484547\n",
      "80 0.33509646877212923 0.11916808092728376 early stop at Round 3\n",
      "early stop, remaining size for Round4: 129863\n",
      "81\n",
      "['step1_rr: 80', 'step2_rr: 80', 'step3_rr: 80', 'step4_rr: 80', 'step5_rr: 80']\n",
      "empirical response rate 0.05518069533394328\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.025564425259167807 0.11928513646125793 0.09372071120209013\n",
      "remaining size for Round 3: 135851\n",
      "82\n",
      "['step1_rr: 81', 'step2_rr: 81', 'step3_rr: 81', 'step4_rr: 81', 'step5_rr: 81']\n",
      "empirical response rate 0.05572392497712717\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.012626346566416206 0.16584133664444042 0.15321499007802422\n",
      "remaining size for Round 3: 135815\n",
      "Calculated size for Round 3: 5389.115275611896\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.1984259580272193 0.11862027076335771 -0.07980568726386159\n",
      "82 0.1984259580272193 0.11862027076335771 early stop at Round 3\n",
      "early stop, remaining size for Round4: 130426\n",
      "83\n",
      "['step1_rr: 82', 'step2_rr: 82', 'step3_rr: 82', 'step4_rr: 82', 'step5_rr: 82']\n",
      "empirical response rate 0.05558096980786825\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4176.173813910594\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 100}\n",
      "orr termination 0.04126800397570661 0.07603335027460327 0.03476534629889666\n",
      "remaining size for Round 3: 135824\n",
      "Calculated size for Round 3: 5930.1000371629725\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.21836463560375852 0.12057953693758622 -0.0977850986661723\n",
      "83 0.21836463560375852 0.12057953693758622 early stop at Round 3\n",
      "early stop, remaining size for Round4: 129894\n",
      "84\n",
      "['step1_rr: 83', 'step2_rr: 83', 'step3_rr: 83', 'step4_rr: 83', 'step5_rr: 83']\n",
      "empirical response rate 0.056038426349496795\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4206.576669795643\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.037312135100364685 0.14924854040145874 0.11193640530109406\n",
      "remaining size for Round 3: 135794\n",
      "85\n",
      "['step1_rr: 84', 'step2_rr: 84', 'step3_rr: 84', 'step4_rr: 84', 'step5_rr: 84']\n",
      "empirical response rate 0.05466605672461116\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.06570485790964131 0.12110396474599838 0.05539910683635707\n",
      "remaining size for Round 3: 135885\n",
      "86\n",
      "['step1_rr: 85', 'step2_rr: 85', 'step3_rr: 85', 'step4_rr: 85', 'step5_rr: 85']\n",
      "empirical response rate 0.053579597438243365\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4043.352644626449\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.007074345322372902 0.22389809787273407 0.21682375255036118\n",
      "remaining size for Round 3: 135957\n",
      "Calculated size for Round 3: 4016.4400547557966\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.050188980996608734 0.20075592398643494 0.1505669429898262\n",
      "remaining size for Round 4: 131941\n",
      "87\n",
      "['step1_rr: 86', 'step2_rr: 86', 'step3_rr: 86', 'step4_rr: 86', 'step5_rr: 86']\n",
      "empirical response rate 0.054180009149130834\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4083.166195613249\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.04244787076746465 0.21160843968391418 0.16916056891644954\n",
      "remaining size for Round 3: 135917\n",
      "88\n",
      "['step1_rr: 87', 'step2_rr: 87', 'step3_rr: 87', 'step4_rr: 87', 'step5_rr: 87']\n",
      "empirical response rate 0.05400846294602013\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.31463521758671464 0.1899358675482875 -0.12469935003842714\n",
      "88 0.31463521758671464 0.1899358675482875 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135929\n",
      "89\n",
      "['step1_rr: 88', 'step2_rr: 88', 'step3_rr: 88', 'step4_rr: 88', 'step5_rr: 88']\n",
      "empirical response rate 0.057467978042086004\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4301.689819632026\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.12778926737301544 0.17788449311915466 0.05009522574613923\n",
      "remaining size for Round 3: 135699\n",
      "Calculated size for Round 3: 7360.783595918931\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.01869188090737169 0.08580369502305984 0.06711181411568816\n",
      "remaining size for Round 4: 128339\n",
      "90\n",
      "['step1_rr: 89', 'step2_rr: 89', 'step3_rr: 89', 'step4_rr: 89', 'step5_rr: 89']\n",
      "empirical response rate 0.05595265324794144\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.27905185150348655 0.12366442568893263 -0.15538742581455392\n",
      "90 0.27905185150348655 0.12366442568893263 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135800\n",
      "91\n",
      "['step1_rr: 90', 'step2_rr: 90', 'step3_rr: 90', 'step4_rr: 90', 'step5_rr: 90']\n",
      "empirical response rate 0.056209972552607505\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4217.9819182904175\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.043373558670282364 0.17349423468112946 0.1301206760108471\n",
      "remaining size for Round 3: 135783\n",
      "92\n",
      "['step1_rr: 91', 'step2_rr: 91', 'step3_rr: 91', 'step4_rr: 91', 'step5_rr: 91']\n",
      "empirical response rate 0.055666742909423604\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4181.87311403394\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.02429292020771464 0.35765221189633684 0.3333592916886222\n",
      "remaining size for Round 3: 135819\n",
      "Calculated size for Round 3: 5179.656463290243\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.36220767349004745 0.12073589116334915 -0.2414717823266983\n",
      "92 0.36220767349004745 0.12073589116334915 early stop at Round 3\n",
      "early stop, remaining size for Round4: 130640\n",
      "93\n",
      "['step1_rr: 92', 'step2_rr: 92', 'step3_rr: 92', 'step4_rr: 92', 'step5_rr: 92']\n",
      "empirical response rate 0.05609560841720036\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "94\n",
      "['step1_rr: 93', 'step2_rr: 93', 'step3_rr: 93', 'step4_rr: 93', 'step5_rr: 93']\n",
      "empirical response rate 0.05340805123513266\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4031.9825257930215\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.05583722784631013 0.07327472546915334 0.01743749762284321\n",
      "remaining size for Round 3: 135969\n",
      "Calculated size for Round 3: 6247.669222119847\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.3600199310893635 0.11998380802490373 -0.24003612306445976\n",
      "94 0.3600199310893635 0.11998380802490373 early stop at Round 3\n",
      "early stop, remaining size for Round4: 129722\n",
      "95\n",
      "['step1_rr: 94', 'step2_rr: 94', 'step3_rr: 94', 'step4_rr: 94', 'step5_rr: 94']\n",
      "empirical response rate 0.05349382433668801\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4037.6672970440713\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.009326880506832022 0.20410141348838806 0.19477453298155603\n",
      "remaining size for Round 3: 135963\n",
      "96\n",
      "['step1_rr: 95', 'step2_rr: 95', 'step3_rr: 95', 'step4_rr: 95', 'step5_rr: 95']\n",
      "empirical response rate 0.05443732845379689\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4100.237767911125\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.6005271524190902 0.4083584636449814 -0.19216868877410875\n",
      "96 0.6005271524190902 0.4083584636449814 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135900\n",
      "97\n",
      "['step1_rr: 96', 'step2_rr: 96', 'step3_rr: 96', 'step4_rr: 96', 'step5_rr: 96']\n",
      "empirical response rate 0.05200709057639524\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 3939.2130430862803\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 100}\n",
      "orr termination 0.12574869377233844 0.12578363457114972 3.4940798811278206e-05\n",
      "97 0.12574869377233844 0.12578363457114972 early stop at Round 2\n",
      "early stop, remaining size for Round3: 136061\n",
      "98\n",
      "['step1_rr: 97', 'step2_rr: 97', 'step3_rr: 97', 'step4_rr: 97', 'step5_rr: 97']\n",
      "empirical response rate 0.05652447392497713\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "99\n",
      "['step1_rr: 98', 'step2_rr: 98', 'step3_rr: 98', 'step4_rr: 98', 'step5_rr: 98']\n",
      "empirical response rate 0.05460887465690759\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.24075157440857514 0.4594083857489609 0.21865681134038578\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 5910.398928041415\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 200}\n",
      "orr termination 0.05944206993498673 0.33672866532269774 0.277286595387711\n",
      "remaining size for Round 4: 129979\n",
      "Calculated size for Round 4: 6542.64749412442\n",
      "Best fit parameters: {'XGB__learning_rate': 0.1, 'XGB__n_estimators': 50}\n",
      "orr termination 0.0490648145224729 0.07269070051665415 0.02362588599418125\n",
      "remaining size for last Round 5: 123437\n",
      "100\n",
      "['step1_rr: 99', 'step2_rr: 99', 'step3_rr: 99', 'step4_rr: 99', 'step5_rr: 99']\n",
      "empirical response rate 0.055380832570905765\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "Best fit parameters: {'XGB__learning_rate': 0.01, 'XGB__n_estimators': 50}\n",
      "orr termination 0.36968716979026794 0.12322905659675598 -0.24645811319351196\n",
      "100 0.36968716979026794 0.12322905659675598 early stop at Round 2\n",
      "early stop, remaining size for Round3: 135838\n"
     ]
    }
   ],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TysTqb-hKSGB",
   "metadata": {
    "id": "TysTqb-hKSGB"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3rE5NPrzKSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1707448236231,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "3rE5NPrzKSGB",
    "outputId": "338e681d-1cf5-4fba-cdf9-37d207e4cf10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step1_rr</th>\n",
       "      <th>step2_rr</th>\n",
       "      <th>step3_rr</th>\n",
       "      <th>step4_rr</th>\n",
       "      <th>step5_rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.058487</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.060294</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.062540</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.065806</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.062062</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    step1_rr  step2_rr  step3_rr  step4_rr  step5_rr\n",
       "0      0.055  0.068471  0.068471       NaN       NaN\n",
       "1      0.055  0.058487  0.059121  0.068471       NaN\n",
       "2      0.055  0.060294  0.068471       NaN       NaN\n",
       "3      0.055  0.062540  0.068471  0.068471       NaN\n",
       "4      0.055  0.064038  0.068471  0.068471       NaN\n",
       "..       ...       ...       ...       ...       ...\n",
       "95     0.055  0.068471  0.068471       NaN       NaN\n",
       "96     0.055  0.065806  0.068471       NaN       NaN\n",
       "97     0.055  0.068471       NaN       NaN       NaN\n",
       "98     0.055  0.062062  0.068471  0.068471  0.068471\n",
       "99     0.055  0.068471  0.068471       NaN       NaN\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "51GW3qKgLfRz",
   "metadata": {
    "id": "51GW3qKgLfRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 (0.8)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7BpBmgNvKSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1707448237526,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "7BpBmgNvKSGB",
    "outputId": "27d70514-4ac7-40f9-8373-5ed213bdb833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_rr: 0.055 (0.000)\n",
      "step2_rr: 0.065 (0.004)\n",
      "step3_rr: 0.067 (0.003)\n",
      "step4_rr: 0.068 (0.001)\n",
      "step5_rr: 0.068 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# orr for each round:\n",
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "DeeO4i9AKSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707448339675,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "DeeO4i9AKSGB",
    "outputId": "44c42256-3c95-48ff-b6a1-2d7484750b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.065, StD: 0.002\n"
     ]
    }
   ],
   "source": [
    "# overall orr:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "N_ACdIs4KSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1707448339008,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "N_ACdIs4KSGB",
    "outputId": "3e8dab14-08fa-4902-87dd-f18235e86888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068470526432204\n",
      "1.3877787807814457e-17\n"
     ]
    }
   ],
   "source": [
    "# highest true rr:\n",
    "print(np.mean(highest_true_rr))\n",
    "print(np.std(highest_true_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "azjdUixVKSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1707447643064,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "azjdUixVKSGB",
    "outputId": "d8e676ad-a73e-4e62-f939-ebf6efadaa9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.068, StD: 0.003\n"
     ]
    }
   ],
   "source": [
    "# adaptive learning orr:\n",
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "xe_GmWf7KSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1707448246018,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "xe_GmWf7KSGB",
    "outputId": "7e9f5fc0-3a8c-4472-f0c2-bb0392711f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_plan_number: nan (nan)\n",
      "step2_plan_number: 17.0 (21.4)\n",
      "step3_plan_number: 5.2 (7.3)\n",
      "step4_plan_number: 2.4 (2.1)\n",
      "step5_plan_number: 1.8 (0.7)\n"
     ]
    }
   ],
   "source": [
    "# average plan number for each round:\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fMmvSSjvKSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1707448245147,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "fMmvSSjvKSGB",
    "outputId": "b4a9a3b4-4878-418d-da2f-545cc90cc55b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': 0.88,\n",
       " 'early_stopping_plan': 0.52,\n",
       " 'early_stopping_orr': 0.36,\n",
       " 'early_stopping_size': 0.0}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# early stopping probabilities:\n",
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "oix1Ryk3KSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1707447645503,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "oix1Ryk3KSGB",
    "outputId": "8d467010-aa11-47ae-85d1-b6e431ff7e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132328.45 4911.178645447546\n"
     ]
    }
   ],
   "source": [
    "# sample size for the last round:\n",
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "QGhgm_aVKSGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1707447644111,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "QGhgm_aVKSGB",
    "outputId": "05483b1d-c213-419c-c926-cb56090014dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_sample_size: 34976.000 (0.000)\n",
      "step2_sample_size: 34573.711 (55774.721)\n",
      "step3_sample_size: 65610.153 (63545.937)\n",
      "step4_sample_size: 79584.757 (59983.292)\n",
      "step5_sample_size: 123780.583 (1380.933)\n"
     ]
    }
   ],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5YVfZ2WrL_ug",
   "metadata": {
    "id": "5YVfZ2WrL_ug"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities for better performance compared to the benchmark:\n",
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NHSqkmgoMEov",
   "metadata": {
    "id": "NHSqkmgoMEov"
   },
   "source": [
    "## Ensemble learning - 3 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "jtIwqgVgMEo6",
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1707455790321,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "jtIwqgVgMEo6"
   },
   "outputs": [],
   "source": [
    "# def ensemble_model_fit(data, data_pred):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "#         data['response'],\n",
    "#         test_size=0.2,\n",
    "#         random_state=0\n",
    "#     )\n",
    "\n",
    "#     # Define the VotingClassifier with the individual classifiers\n",
    "#     voting_classifier = ensemble.VotingClassifier(\n",
    "#         estimators=[\n",
    "#             ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0)),\n",
    "# #             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "#                     # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "#                     ('RF', ensemble.RandomForestClassifier(criterion='gini', random_state=0)),\n",
    "#                     ('XGB', XGBClassifier(learning_rate=0.1, random_state=0))\n",
    "#                    ],\n",
    "#         voting='soft'\n",
    "#     )\n",
    "\n",
    "#     # Define the hyperparameter grid to search\n",
    "#     # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "#     param_grid = {\n",
    "#         # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "#         'LR__C': [0.01, 0.05, 0.1],\n",
    "#         # 'Ridge__C': [0.01]\n",
    "#         # 'SVM__C': [0.01, 0.05, 0.1]\n",
    "#         'RF__n_estimators': [50, 100, 200],\n",
    "#         'XGB__n_estimators': [50, 100, 200]\n",
    "#     }\n",
    "\n",
    "#     # Create a GridSearchCV object\n",
    "#     # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "#     grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "#     # Perform the grid search on the training data\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     # Get the best hyperparameters\n",
    "#     best_params = grid_search.best_params_\n",
    "#     # Print the best fitted parameters\n",
    "#     print(\"Best fitted parameters:\")\n",
    "#     print(best_params)\n",
    "\n",
    "#     # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "#     final_voting_classifier = grid_search.best_estimator_\n",
    "#     final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "#     # Predict probabilities instead of binary outcomes on the test set\n",
    "#     y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "#     y_pred_test = final_voting_classifier.predict(X_test)\n",
    "#     X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "#     y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "M9zTZ8-xS8uY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 651981,
     "status": "ok",
     "timestamp": 1707456468497,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "M9zTZ8-xS8uY",
    "outputId": "d3ce2cbb-f041-49ca-cc2d-b6ed270a8891"
   },
   "outputs": [],
   "source": [
    "# ensemble_model_fit(dt_design_5, dt_design_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "nf1VuXIFMEo6",
   "metadata": {
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1707456609421,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "nf1VuXIFMEo6"
   },
   "outputs": [],
   "source": [
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0)),\n",
    "#             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "                    # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "                    ('RF', ensemble.RandomForestClassifier(criterion='gini', random_state=0)),\n",
    "                    ('XGB', XGBClassifier(learning_rate=0.1, random_state=0))\n",
    "                   ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "    param_grid = {\n",
    "        # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "        'LR__C': [0.05],\n",
    "        # 'Ridge__C': [0.01]\n",
    "        # 'SVM__C': [0.05]\n",
    "        'RF__n_estimators': [100],\n",
    "        'XGB__n_estimators': [50]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beNEkYR6MEo6",
   "metadata": {
    "id": "beNEkYR6MEo6"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "xuzbbQ0wMEo6",
   "metadata": {
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1707456614862,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "xuzbbQ0wMEo6"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "AB5nx86KMEo6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB5nx86KMEo6",
    "outputId": "636624e6-c5db-4e85-b5c1-cc50bda3e2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['step1_rr: 0', 'step2_rr: 0', 'step3_rr: 0', 'step4_rr: 0', 'step5_rr: 0']\n",
      "empirical response rate 0.05655306495882891\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4240.799240494033\n",
      "orr termination 0.023692156640350504 0.07230555879718663 0.04861340215683613\n",
      "remaining size for Round 3: 135760\n",
      "2\n",
      "['step1_rr: 1', 'step2_rr: 1', 'step3_rr: 1', 'step4_rr: 1', 'step5_rr: 1']\n",
      "empirical response rate 0.054637465690759376\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "orr termination 0.04739092921486517 0.07127662623484328 0.023885697019978107\n",
      "remaining size for Round 3: 135887\n",
      "Calculated size for Round 3: 9827.715869701693\n",
      "orr termination 0.03824708261820013 0.07222230506546733 0.033975222447267195\n",
      "remaining size for Round 4: 126060\n",
      "3\n",
      "['step1_rr: 2', 'step2_rr: 2', 'step3_rr: 2', 'step4_rr: 2', 'step5_rr: 2']\n",
      "empirical response rate 0.05303636779505947\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "orr termination 0.04362661732628417 0.06589104962316589 0.022264432296881714\n",
      "remaining size for Round 3: 135993\n",
      "Calculated size for Round 3: 9458.687273545209\n",
      "orr termination 0.03623992349686623 0.07176704562490213 0.0355271221280359\n",
      "remaining size for Round 4: 126535\n",
      "4\n",
      "['step1_rr: 3', 'step2_rr: 3', 'step3_rr: 3', 'step4_rr: 3', 'step5_rr: 3']\n",
      "empirical response rate 0.054265782250686186\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4088.8561455390104\n",
      "orr termination 0.03364873503132379 0.06636360492597516 0.032714869894651374\n",
      "remaining size for Round 3: 135912\n",
      "Calculated size for Round 3: 6843.466453348948\n",
      "orr termination 0.04631219389468297 0.06954731198858063 0.023235118093897666\n",
      "remaining size for Round 4: 129069\n",
      "Calculated size for Round 4: 6090.922998166232\n",
      "orr termination 0.03487060008638754 0.06671060649606093 0.031840006409673396\n",
      "remaining size for last Round 5: 122979\n",
      "5\n",
      "['step1_rr: 4', 'step2_rr: 4', 'step3_rr: 4', 'step4_rr: 4', 'step5_rr: 4']\n",
      "empirical response rate 0.05772529734675206\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4318.826898633964\n",
      "orr termination 0.017937192939467488 0.07220082531615783 0.054263632376690345\n",
      "remaining size for Round 3: 135682\n",
      "6\n",
      "['step1_rr: 5', 'step2_rr: 5', 'step3_rr: 5', 'step4_rr: 5', 'step5_rr: 5']\n",
      "empirical response rate 0.05458028362305581\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "orr termination 0.03156246175149742 0.07733406235147922 0.045771600599981796\n",
      "remaining size for Round 3: 135891\n",
      "Calculated size for Round 3: 7559.401472090043\n",
      "orr termination 0.03729318710608487 0.07464413368137447 0.037350946575289604\n",
      "remaining size for Round 4: 128332\n",
      "7\n",
      "['step1_rr: 6', 'step2_rr: 6', 'step3_rr: 6', 'step4_rr: 6', 'step5_rr: 6']\n",
      "empirical response rate 0.05775388838060384\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4320.7313323598355\n",
      "orr termination 0.0181325010299599 0.08347484993758918 0.06534234890762927\n",
      "remaining size for Round 3: 135680\n",
      "8\n",
      "['step1_rr: 7', 'step2_rr: 7', 'step3_rr: 7', 'step4_rr: 7', 'step5_rr: 7']\n",
      "empirical response rate 0.05749656907593779\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4303.593688344371\n",
      "orr termination 0.037917216711128014 0.07875922798759485 0.04084201127646684\n",
      "remaining size for Round 3: 135697\n",
      "9\n",
      "['step1_rr: 8', 'step2_rr: 8', 'step3_rr: 8', 'step4_rr: 8', 'step5_rr: 8']\n",
      "empirical response rate 0.0553236505032022\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4159.079338458144\n",
      "orr termination 0.02569843898375568 0.07699020623329444 0.05129176724953877\n",
      "remaining size for Round 3: 135841\n",
      "10\n",
      "['step1_rr: 9', 'step2_rr: 9', 'step3_rr: 9', 'step4_rr: 9', 'step5_rr: 9']\n",
      "empirical response rate 0.0536939615736505\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "orr termination 0.0186347077814076 0.08298196436822998 0.06434725658682239\n",
      "remaining size for Round 3: 135950\n",
      "11\n",
      "['step1_rr: 10', 'step2_rr: 10', 'step3_rr: 10', 'step4_rr: 10', 'step5_rr: 10']\n",
      "empirical response rate 0.05460887465690759\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "orr termination 0.05766033638787818 0.07313273689430366 0.015472400506425482\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 8123.150284521362\n",
      "orr termination 0.02053019588608777 0.07845002916917819 0.057919833283090416\n",
      "remaining size for Round 4: 127766\n",
      "12\n",
      "['step1_rr: 11', 'step2_rr: 11', 'step3_rr: 11', 'step4_rr: 11', 'step5_rr: 11']\n",
      "empirical response rate 0.05275045745654163\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 3988.418451118696\n",
      "orr termination 0.03137079346763787 0.07120754217450936 0.0398367487068715\n",
      "remaining size for Round 3: 136012\n",
      "Calculated size for Round 3: 5315.837511771787\n",
      "orr termination 0.0451523215750046 0.07460649857669827 0.029454177001693664\n",
      "remaining size for Round 4: 130697\n",
      "Calculated size for Round 4: 6637.700717975327\n",
      "orr termination 0.02664367276898622 0.07547756507671248 0.048833892307726265\n",
      "remaining size for last Round 5: 124060\n",
      "13\n",
      "['step1_rr: 12', 'step2_rr: 12', 'step3_rr: 12', 'step4_rr: 12', 'step5_rr: 12']\n",
      "empirical response rate 0.05626715462031107\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4221.784173594918\n",
      "orr termination 0.03829535292914402 0.07659708670007338 0.03830173377092936\n",
      "remaining size for Round 3: 135779\n",
      "14\n",
      "['step1_rr: 13', 'step2_rr: 13', 'step3_rr: 13', 'step4_rr: 13', 'step5_rr: 13']\n",
      "empirical response rate 0.05466605672461116\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "orr termination 0.02129935014495964 0.07747050267827112 0.05617115253331148\n",
      "remaining size for Round 3: 135885\n",
      "15\n",
      "['step1_rr: 14', 'step2_rr: 14', 'step3_rr: 14', 'step4_rr: 14', 'step5_rr: 14']\n",
      "empirical response rate 0.05375114364135407\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "orr termination 0.030144364733278993 0.07314550515818982 0.04300114042491083\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 8089.807211411245\n",
      "orr termination 0.034585024417589934 0.0680874358204152 0.03350241140282526\n",
      "remaining size for Round 4: 127857\n",
      "16\n",
      "['step1_rr: 15', 'step2_rr: 15', 'step3_rr: 15', 'step4_rr: 15', 'step5_rr: 15']\n",
      "empirical response rate 0.05466605672461116\n",
      "remaining size for Round 2: 140000\n",
      "17\n",
      "['step1_rr: 16', 'step2_rr: 16', 'step3_rr: 16', 'step4_rr: 16', 'step5_rr: 16']\n",
      "empirical response rate 0.05595265324794144\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "orr termination 0.028495785020186203 0.07380704574503305 0.04531126072484685\n",
      "remaining size for Round 3: 135800\n",
      "Calculated size for Round 3: 6462.059874095709\n",
      "orr termination 0.02469331033466731 0.07397784672747264 0.04928453639280533\n",
      "remaining size for Round 4: 129338\n",
      "18\n",
      "['step1_rr: 17', 'step2_rr: 17', 'step3_rr: 17', 'step4_rr: 17', 'step5_rr: 17']\n",
      "empirical response rate 0.05480901189387008\n",
      "remaining size for Round 2: 140000\n",
      "19\n",
      "['step1_rr: 18', 'step2_rr: 18', 'step3_rr: 18', 'step4_rr: 18', 'step5_rr: 18']\n",
      "empirical response rate 0.05598124428179323\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "orr termination 0.03681518984228582 0.07285283866074592 0.0360376488184601\n",
      "remaining size for Round 3: 135798\n",
      "20\n",
      "['step1_rr: 19', 'step2_rr: 19', 'step3_rr: 19', 'step4_rr: 19', 'step5_rr: 19']\n",
      "empirical response rate 0.05489478499542543\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "orr termination 0.034533005114756786 0.06929300474728198 0.03475999963252519\n",
      "remaining size for Round 3: 135870\n",
      "21\n",
      "['step1_rr: 20', 'step2_rr: 20', 'step3_rr: 20', 'step4_rr: 20', 'step5_rr: 20']\n",
      "empirical response rate 0.05486619396157365\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4128.701861019453\n",
      "orr termination 0.04665977017629071 0.07028129810241117 0.02362152792612046\n",
      "remaining size for Round 3: 135872\n",
      "Calculated size for Round 3: 7012.097971279894\n",
      "orr termination 0.03493218284408754 0.06903374233984336 0.034101559495755815\n",
      "remaining size for Round 4: 128860\n",
      "Calculated size for Round 4: 5920.136062635101\n",
      "orr termination 0.036244800127002 0.07308794495089103 0.036843144823889035\n",
      "remaining size for last Round 5: 122940\n",
      "22\n",
      "['step1_rr: 21', 'step2_rr: 21', 'step3_rr: 21', 'step4_rr: 21', 'step5_rr: 21']\n",
      "empirical response rate 0.05518069533394328\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "orr termination 0.016993955588770548 0.08278377175815715 0.0657898161693866\n",
      "remaining size for Round 3: 135851\n",
      "23\n",
      "['step1_rr: 22', 'step2_rr: 22', 'step3_rr: 22', 'step4_rr: 22', 'step5_rr: 22']\n",
      "empirical response rate 0.054780420860018296\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "orr termination 0.027324034434158637 0.08054970949286787 0.05322567505870923\n",
      "remaining size for Round 3: 135877\n",
      "24\n",
      "['step1_rr: 23', 'step2_rr: 23', 'step3_rr: 23', 'step4_rr: 23', 'step5_rr: 23']\n",
      "empirical response rate 0.05415141811527905\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "orr termination 0.021509631023472274 0.08030282609837999 0.05879319507490772\n",
      "remaining size for Round 3: 135919\n",
      "25\n",
      "['step1_rr: 24', 'step2_rr: 24', 'step3_rr: 24', 'step4_rr: 24', 'step5_rr: 24']\n",
      "empirical response rate 0.05400846294602013\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "orr termination 0.03515197485479458 0.07291111884242955 0.037759143987634976\n",
      "remaining size for Round 3: 135929\n",
      "26\n",
      "['step1_rr: 25', 'step2_rr: 25', 'step3_rr: 25', 'step4_rr: 25', 'step5_rr: 25']\n",
      "empirical response rate 0.056038426349496795\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4206.576669795643\n",
      "orr termination 0.03837228289289368 0.0750605464777891 0.03668826358489542\n",
      "remaining size for Round 3: 135794\n",
      "27\n",
      "['step1_rr: 26', 'step2_rr: 26', 'step3_rr: 26', 'step4_rr: 26', 'step5_rr: 26']\n",
      "empirical response rate 0.05377973467520585\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "orr termination 0.06226430585954235 0.07166366790794547 0.009399362048403116\n",
      "remaining size for Round 3: 135944\n",
      "Calculated size for Round 3: 6735.398862948885\n",
      "orr termination 0.016839244461479354 0.0804125063121432 0.06357326185066384\n",
      "remaining size for Round 4: 129209\n",
      "28\n",
      "['step1_rr: 27', 'step2_rr: 27', 'step3_rr: 27', 'step4_rr: 27', 'step5_rr: 27']\n",
      "empirical response rate 0.0529791857273559\n",
      "remaining size for Round 2: 140000\n",
      "29\n",
      "['step1_rr: 28', 'step2_rr: 28', 'step3_rr: 28', 'step4_rr: 28', 'step5_rr: 28']\n",
      "empirical response rate 0.05312214089661482\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4013.037453633404\n",
      "orr termination 0.0256655456605411 0.07190069654186028 0.04623515088131918\n",
      "remaining size for Round 3: 135987\n",
      "30\n",
      "['step1_rr: 29', 'step2_rr: 29', 'step3_rr: 29', 'step4_rr: 29', 'step5_rr: 29']\n",
      "empirical response rate 0.054837602927721864\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "orr termination 0.048803831364411326 0.07213188266899741 0.02332805130458608\n",
      "remaining size for Round 3: 135874\n",
      "Calculated size for Round 3: 10029.091904593639\n",
      "orr termination 0.034603696707541515 0.07099174837490144 0.03638805166735992\n",
      "remaining size for Round 4: 125845\n",
      "31\n",
      "['step1_rr: 30', 'step2_rr: 30', 'step3_rr: 30', 'step4_rr: 30', 'step5_rr: 30']\n",
      "empirical response rate 0.05518069533394328\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "orr termination 0.061726363479030766 0.07321973050121719 0.011493367022186424\n",
      "remaining size for Round 3: 135851\n",
      "Calculated size for Round 3: 7050.1003983182045\n",
      "orr termination 0.015331132356467499 0.06928418414250012 0.05395305178603262\n",
      "remaining size for Round 4: 128801\n",
      "32\n",
      "['step1_rr: 31', 'step2_rr: 31', 'step3_rr: 31', 'step4_rr: 31', 'step5_rr: 31']\n",
      "empirical response rate 0.05435155535224154\n",
      "remaining size for Round 2: 140000\n",
      "33\n",
      "['step1_rr: 32', 'step2_rr: 32', 'step3_rr: 32', 'step4_rr: 32', 'step5_rr: 32']\n",
      "empirical response rate 0.05332227813357731\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4026.2983311032726\n",
      "orr termination 0.03506033939370855 0.06986474577662563 0.03480440638291708\n",
      "remaining size for Round 3: 135974\n",
      "34\n",
      "['step1_rr: 33', 'step2_rr: 33', 'step3_rr: 33', 'step4_rr: 33', 'step5_rr: 33']\n",
      "empirical response rate 0.05375114364135407\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "orr termination 0.03595883053554041 0.06922615024587764 0.03326731971033723\n",
      "remaining size for Round 3: 135946\n",
      "35\n",
      "['step1_rr: 34', 'step2_rr: 34', 'step3_rr: 34', 'step4_rr: 34', 'step5_rr: 34']\n",
      "empirical response rate 0.054637465690759376\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "orr termination 0.03927597914262563 0.07520399007862984 0.03592801093600421\n",
      "remaining size for Round 3: 135887\n",
      "Calculated size for Round 3: 7665.523343960212\n",
      "orr termination 0.03988723338850183 0.07270573372549481 0.03281850033699298\n",
      "remaining size for Round 4: 128222\n",
      "36\n",
      "['step1_rr: 35', 'step2_rr: 35', 'step3_rr: 35', 'step4_rr: 35', 'step5_rr: 35']\n",
      "empirical response rate 0.05669602012808783\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4250.309141054068\n",
      "orr termination 0.031039118779391237 0.07784383577542624 0.046804716996035\n",
      "remaining size for Round 3: 135750\n",
      "Calculated size for Round 3: 7314.109136502298\n",
      "orr termination 0.03560285419468575 0.06991246936767091 0.03430961517298516\n",
      "remaining size for Round 4: 128436\n",
      "37\n",
      "['step1_rr: 36', 'step2_rr: 36', 'step3_rr: 36', 'step4_rr: 36', 'step5_rr: 36']\n",
      "empirical response rate 0.05600983531564501\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4204.676016429063\n",
      "orr termination 0.055460145535686206 0.07281836468683137 0.01735821915114516\n",
      "remaining size for Round 3: 135796\n",
      "Calculated size for Round 3: 6644.006139416844\n",
      "orr termination 0.03710429790256291 0.07333847328609482 0.03623417538353191\n",
      "remaining size for Round 4: 129152\n",
      "Calculated size for Round 4: 6097.172196149311\n",
      "orr termination 0.04759942945570282 0.0711993576151995 0.023599928159496672\n",
      "remaining size for last Round 5: 123055\n",
      "38\n",
      "['step1_rr: 37', 'step2_rr: 37', 'step3_rr: 37', 'step4_rr: 37', 'step5_rr: 37']\n",
      "empirical response rate 0.05458028362305581\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "orr termination 0.017474126601600515 0.0704171319141137 0.05294300531251318\n",
      "remaining size for Round 3: 135891\n",
      "39\n",
      "['step1_rr: 38', 'step2_rr: 38', 'step3_rr: 38', 'step4_rr: 38', 'step5_rr: 38']\n",
      "empirical response rate 0.05535224153705398\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4160.97847079396\n",
      "orr termination 0.036904201537755574 0.07546876378414949 0.038564562246393916\n",
      "remaining size for Round 3: 135840\n",
      "40\n",
      "['step1_rr: 39', 'step2_rr: 39', 'step3_rr: 39', 'step4_rr: 39', 'step5_rr: 39']\n",
      "empirical response rate 0.05489478499542543\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "orr termination 0.025475727292094894 0.07833434863299255 0.05285862134089765\n",
      "remaining size for Round 3: 135870\n",
      "41\n",
      "['step1_rr: 40', 'step2_rr: 40', 'step3_rr: 40', 'step4_rr: 40', 'step5_rr: 40']\n",
      "empirical response rate 0.05529505946935041\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4157.18026960777\n",
      "orr termination 0.01753229743524198 0.07232437694183612 0.054792079506594135\n",
      "remaining size for Round 3: 135843\n",
      "42\n",
      "['step1_rr: 41', 'step2_rr: 41', 'step3_rr: 41', 'step4_rr: 41', 'step5_rr: 41']\n",
      "empirical response rate 0.05363677950594693\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "orr termination 0.04081225088431826 0.07488739467222906 0.0340751437879108\n",
      "remaining size for Round 3: 135953\n",
      "43\n",
      "['step1_rr: 42', 'step2_rr: 42', 'step3_rr: 42', 'step4_rr: 42', 'step5_rr: 42']\n",
      "empirical response rate 0.05377973467520585\n",
      "remaining size for Round 2: 140000\n",
      "44\n",
      "['step1_rr: 43', 'step2_rr: 43', 'step3_rr: 43', 'step4_rr: 43', 'step5_rr: 43']\n",
      "empirical response rate 0.05583828911253431\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4193.273425323935\n",
      "orr termination 0.044594494806204595 0.07357858651067731 0.028984091704472713\n",
      "remaining size for Round 3: 135807\n",
      "Calculated size for Round 3: 7372.187214443973\n",
      "orr termination 0.04866504117945729 0.07467571348544015 0.026010672305982863\n",
      "remaining size for Round 4: 128435\n",
      "Calculated size for Round 4: 6682.503517179387\n",
      "orr termination 0.03581095002259222 0.07228234151435244 0.036471391491760215\n",
      "remaining size for last Round 5: 121753\n",
      "45\n",
      "['step1_rr: 44', 'step2_rr: 44', 'step3_rr: 44', 'step4_rr: 44', 'step5_rr: 44']\n",
      "empirical response rate 0.05555237877401647\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4174.274174005051\n",
      "orr termination 0.04927729577044382 0.07215226960027253 0.022874973829828713\n",
      "remaining size for Round 3: 135826\n",
      "Calculated size for Round 3: 6166.783463666277\n",
      "orr termination 0.04020309689379185 0.07787922662703736 0.037676129733245516\n",
      "remaining size for Round 4: 129660\n",
      "Calculated size for Round 4: 6161.201648254152\n",
      "orr termination 0.02608452556680809 0.0748012560248106 0.048716730458002504\n",
      "remaining size for last Round 5: 123499\n",
      "46\n",
      "['step1_rr: 45', 'step2_rr: 45', 'step3_rr: 45', 'step4_rr: 45', 'step5_rr: 45']\n",
      "empirical response rate 0.0536939615736505\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "orr termination 0.0375071599289388 0.07552898040363668 0.038021820474697876\n",
      "remaining size for Round 3: 135950\n",
      "47\n",
      "['step1_rr: 46', 'step2_rr: 46', 'step3_rr: 46', 'step4_rr: 46', 'step5_rr: 46']\n",
      "empirical response rate 0.05449451052150046\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4104.032152159118\n",
      "orr termination 0.06094270919146877 0.07251997599232296 0.011577266800854191\n",
      "remaining size for Round 3: 135896\n",
      "Calculated size for Round 3: 7439.1945580919055\n",
      "orr termination 0.05616630801604011 0.07023290817671754 0.014066600160677428\n",
      "remaining size for Round 4: 128457\n",
      "Calculated size for Round 4: 6138.160126194844\n",
      "orr termination 0.03573317999934482 0.07197319770176241 0.036240017702417596\n",
      "remaining size for last Round 5: 122319\n",
      "48\n",
      "['step1_rr: 47', 'step2_rr: 47', 'step3_rr: 47', 'step4_rr: 47', 'step5_rr: 47']\n",
      "empirical response rate 0.055380832570905765\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "orr termination 0.0526081519462128 0.07662777612381973 0.024019624177606926\n",
      "remaining size for Round 3: 135838\n",
      "Calculated size for Round 3: 7959.359077287151\n",
      "orr termination 0.02022438628278163 0.07764111172724596 0.05741672544446433\n",
      "remaining size for Round 4: 127879\n",
      "49\n",
      "['step1_rr: 48', 'step2_rr: 48', 'step3_rr: 48', 'step4_rr: 48', 'step5_rr: 48']\n",
      "empirical response rate 0.0554951967063129\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4170.4750844497285\n",
      "orr termination 0.048114247296183146 0.07155148123203926 0.023437233935856117\n",
      "remaining size for Round 3: 135830\n",
      "Calculated size for Round 3: 10064.04891663204\n",
      "orr termination 0.03506050384203608 0.06964739800030922 0.034586894158273145\n",
      "remaining size for Round 4: 125766\n",
      "50\n",
      "['step1_rr: 49', 'step2_rr: 49', 'step3_rr: 49', 'step4_rr: 49', 'step5_rr: 49']\n",
      "empirical response rate 0.05563815187557182\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4179.973283933777\n",
      "orr termination 0.03398944621965709 0.06903636526922338 0.03504691904956629\n",
      "remaining size for Round 3: 135821\n",
      "Calculated size for Round 3: 6158.305313073019\n",
      "orr termination 0.019237580205490518 0.07630817214547411 0.057070591939983595\n",
      "remaining size for Round 4: 129663\n",
      "51\n",
      "['step1_rr: 50', 'step2_rr: 50', 'step3_rr: 50', 'step4_rr: 50', 'step5_rr: 50']\n",
      "empirical response rate 0.05586688014638609\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4195.17369890541\n",
      "orr termination 0.038024074656440254 0.07497044148586636 0.036946366829426106\n",
      "remaining size for Round 3: 135805\n",
      "Calculated size for Round 3: 8543.418606931293\n",
      "orr termination 0.03338549607732756 0.06907413452006647 0.03568863844273891\n",
      "remaining size for Round 4: 127262\n",
      "52\n",
      "['step1_rr: 51', 'step2_rr: 51', 'step3_rr: 51', 'step4_rr: 51', 'step5_rr: 51']\n",
      "empirical response rate 0.055809698078682524\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "orr termination 0.05417167796945073 0.06547729470264564 0.011305616733194912\n",
      "remaining size for Round 3: 135809\n",
      "Calculated size for Round 3: 5075.052219281253\n",
      "orr termination 0.049709130285037165 0.07026747825101061 0.020558347965973445\n",
      "remaining size for Round 4: 130734\n",
      "Calculated size for Round 4: 5197.153950854153\n",
      "orr termination 0.055252435585411715 0.06940206787552827 0.014149632290116558\n",
      "remaining size for last Round 5: 125537\n",
      "53\n",
      "['step1_rr: 52', 'step2_rr: 52', 'step3_rr: 52', 'step4_rr: 52', 'step5_rr: 52']\n",
      "empirical response rate 0.05661024702653248\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4244.60301145521\n",
      "orr termination 0.04070533687641186 0.07922171567798779 0.03851637880157593\n",
      "remaining size for Round 3: 135756\n",
      "54\n",
      "['step1_rr: 53', 'step2_rr: 53', 'step3_rr: 53', 'step4_rr: 53', 'step5_rr: 53']\n",
      "empirical response rate 0.054837602927721864\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "orr termination 0.024335115422423344 0.07416363454389344 0.04982851912147009\n",
      "remaining size for Round 3: 135874\n",
      "55\n",
      "['step1_rr: 54', 'step2_rr: 54', 'step3_rr: 54', 'step4_rr: 54', 'step5_rr: 54']\n",
      "empirical response rate 0.05323650503202196\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4020.614713204558\n",
      "orr termination 0.019621281506986613 0.07976205277658854 0.060140771269601934\n",
      "remaining size for Round 3: 135980\n",
      "56\n",
      "['step1_rr: 55', 'step2_rr: 55', 'step3_rr: 55', 'step4_rr: 55', 'step5_rr: 55']\n",
      "empirical response rate 0.054780420860018296\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "orr termination 0.044936169865278944 0.06779208588542186 0.02285591602014292\n",
      "remaining size for Round 3: 135877\n",
      "Calculated size for Round 3: 6763.507895647328\n",
      "orr termination 0.03614267659853305 0.07054535802305205 0.034402681424519\n",
      "remaining size for Round 4: 129114\n",
      "Calculated size for Round 4: 5943.67687840074\n",
      "orr termination 0.034046159227968206 0.06834645170729174 0.034300292479323535\n",
      "remaining size for last Round 5: 123171\n",
      "57\n",
      "['step1_rr: 56', 'step2_rr: 56', 'step3_rr: 56', 'step4_rr: 56', 'step5_rr: 56']\n",
      "empirical response rate 0.05446591948764867\n",
      "remaining size for Round 2: 140000\n",
      "58\n",
      "['step1_rr: 57', 'step2_rr: 57', 'step3_rr: 57', 'step4_rr: 57', 'step5_rr: 57']\n",
      "empirical response rate 0.053979871912168347\n",
      "remaining size for Round 2: 140000\n",
      "59\n",
      "['step1_rr: 58', 'step2_rr: 58', 'step3_rr: 58', 'step4_rr: 58', 'step5_rr: 58']\n",
      "empirical response rate 0.05546660567246112\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4168.575634817409\n",
      "orr termination 0.00614394349970076 0.07798500542097839 0.07184106192127762\n",
      "remaining size for Round 3: 135832\n",
      "60\n",
      "['step1_rr: 59', 'step2_rr: 59', 'step3_rr: 59', 'step4_rr: 59', 'step5_rr: 59']\n",
      "empirical response rate 0.05498055809698079\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4136.294704781159\n",
      "orr termination 0.05332449490664973 0.07130879622138013 0.017984301314730403\n",
      "remaining size for Round 3: 135864\n",
      "Calculated size for Round 3: 8229.694261675191\n",
      "orr termination 0.049176518226144744 0.0717159251999519 0.022539406973807158\n",
      "remaining size for Round 4: 127635\n",
      "Calculated size for Round 4: 6092.033571663479\n",
      "orr termination 0.03946972013040492 0.07572886696272006 0.03625914683231514\n",
      "remaining size for last Round 5: 121543\n",
      "61\n",
      "['step1_rr: 60', 'step2_rr: 60', 'step3_rr: 60', 'step4_rr: 60', 'step5_rr: 60']\n",
      "empirical response rate 0.055895471180237875\n",
      "remaining size for Round 2: 140000\n",
      "62\n",
      "['step1_rr: 61', 'step2_rr: 61', 'step3_rr: 61', 'step4_rr: 61', 'step5_rr: 61']\n",
      "empirical response rate 0.05312214089661482\n",
      "remaining size for Round 2: 140000\n",
      "63\n",
      "['step1_rr: 62', 'step2_rr: 62', 'step3_rr: 62', 'step4_rr: 62', 'step5_rr: 62']\n",
      "empirical response rate 0.05689615736505032\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4263.625650278873\n",
      "orr termination 0.01949896587661262 0.07558003965650897 0.05608107377989635\n",
      "remaining size for Round 3: 135737\n",
      "Calculated size for Round 3: 5633.10360397346\n",
      "orr termination 0.051533507011590665 0.07734478495913011 0.025811277947539443\n",
      "remaining size for Round 4: 130104\n",
      "Calculated size for Round 4: 8228.706535363952\n",
      "orr termination 0.035227972879895375 0.07315564829979712 0.037927675419901746\n",
      "remaining size for last Round 5: 121876\n",
      "64\n",
      "['step1_rr: 63', 'step2_rr: 63', 'step3_rr: 63', 'step4_rr: 63', 'step5_rr: 63']\n",
      "empirical response rate 0.05458028362305581\n",
      "remaining size for Round 2: 140000\n",
      "65\n",
      "['step1_rr: 64', 'step2_rr: 64', 'step3_rr: 64', 'step4_rr: 64', 'step5_rr: 64']\n",
      "empirical response rate 0.05592406221408966\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "orr termination 0.03645206381177569 0.07361839196323687 0.03716632815146118\n",
      "remaining size for Round 3: 135802\n",
      "66\n",
      "['step1_rr: 65', 'step2_rr: 65', 'step3_rr: 65', 'step4_rr: 65', 'step5_rr: 65']\n",
      "empirical response rate 0.05598124428179323\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "orr termination 0.04445643346997556 0.0834696819158942 0.039013248445918636\n",
      "remaining size for Round 3: 135798\n",
      "67\n",
      "['step1_rr: 66', 'step2_rr: 66', 'step3_rr: 66', 'step4_rr: 66', 'step5_rr: 66']\n",
      "empirical response rate 0.056781793229643183\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4256.015838229115\n",
      "orr termination 0.05932703183251892 0.06937144102774995 0.01004440919523103\n",
      "remaining size for Round 3: 135744\n",
      "Calculated size for Round 3: 6640.593266106684\n",
      "orr termination 0.03938117926144025 0.07620710736171525 0.036825928100275004\n",
      "remaining size for Round 4: 129104\n",
      "Calculated size for Round 4: 6097.074389162626\n",
      "orr termination 0.024664796755082655 0.0725142079482262 0.04784941119314355\n",
      "remaining size for last Round 5: 123007\n",
      "68\n",
      "['step1_rr: 67', 'step2_rr: 67', 'step3_rr: 67', 'step4_rr: 67', 'step5_rr: 67']\n",
      "empirical response rate 0.05609560841720036\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4210.378166320425\n",
      "orr termination 0.007445575850372238 0.08112007156741562 0.07367449571704338\n",
      "remaining size for Round 3: 135790\n",
      "69\n",
      "['step1_rr: 68', 'step2_rr: 68', 'step3_rr: 68', 'step4_rr: 68', 'step5_rr: 68']\n",
      "empirical response rate 0.05486619396157365\n",
      "remaining size for Round 2: 140000\n",
      "70\n",
      "['step1_rr: 69', 'step2_rr: 69', 'step3_rr: 69', 'step4_rr: 69', 'step5_rr: 69']\n",
      "empirical response rate 0.05363677950594693\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "orr termination 0.03642081351762815 0.07340031952776352 0.03697950601013537\n",
      "remaining size for Round 3: 135953\n",
      "71\n",
      "['step1_rr: 70', 'step2_rr: 70', 'step3_rr: 70', 'step4_rr: 70', 'step5_rr: 70']\n",
      "empirical response rate 0.055809698078682524\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "orr termination 0.00686774764369084 0.07543171898763058 0.06856397134393974\n",
      "remaining size for Round 3: 135809\n",
      "72\n",
      "['step1_rr: 71', 'step2_rr: 71', 'step3_rr: 71', 'step4_rr: 71', 'step5_rr: 71']\n",
      "empirical response rate 0.05592406221408966\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "orr termination 0.03106857306010361 0.07515514238103985 0.044086569320936235\n",
      "remaining size for Round 3: 135802\n",
      "Calculated size for Round 3: 6081.104187317394\n",
      "orr termination 0.038757085496283344 0.07655557737616216 0.03779849187987881\n",
      "remaining size for Round 4: 129721\n",
      "Calculated size for Round 4: 7402.517308064287\n",
      "orr termination 0.03542826079168556 0.07093333997931779 0.03550507918763223\n",
      "remaining size for last Round 5: 122319\n",
      "73\n",
      "['step1_rr: 72', 'step2_rr: 72', 'step3_rr: 72', 'step4_rr: 72', 'step5_rr: 72']\n",
      "empirical response rate 0.05721065873741994\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4284.557829370903\n",
      "orr termination 0.015757841612831766 0.07922447191388925 0.06346663030105748\n",
      "remaining size for Round 3: 135716\n",
      "74\n",
      "['step1_rr: 73', 'step2_rr: 73', 'step3_rr: 73', 'step4_rr: 73', 'step5_rr: 73']\n",
      "empirical response rate 0.05572392497712717\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "orr termination 0.01669895079041995 0.07658848291177375 0.059889532121353804\n",
      "remaining size for Round 3: 135815\n",
      "75\n",
      "['step1_rr: 74', 'step2_rr: 74', 'step3_rr: 74', 'step4_rr: 74', 'step5_rr: 74']\n",
      "empirical response rate 0.056724611161939616\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4252.211310393531\n",
      "orr termination 0.05031165870324043 0.07468689826704838 0.02437523956380795\n",
      "remaining size for Round 3: 135748\n",
      "Calculated size for Round 3: 9462.885960825264\n",
      "orr termination 0.034685231864199806 0.06928337008428725 0.03459813822008745\n",
      "remaining size for Round 4: 126286\n",
      "76\n",
      "['step1_rr: 75', 'step2_rr: 75', 'step3_rr: 75', 'step4_rr: 75', 'step5_rr: 75']\n",
      "empirical response rate 0.053979871912168347\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4069.8918802880116\n",
      "orr termination 0.03548011548726008 0.0701670626286463 0.034686947141386225\n",
      "remaining size for Round 3: 135931\n",
      "77\n",
      "['step1_rr: 76', 'step2_rr: 76', 'step3_rr: 76', 'step4_rr: 76', 'step5_rr: 76']\n",
      "empirical response rate 0.05618138151875572\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4216.080885454846\n",
      "orr termination 0.03846798283278029 0.0767480498495835 0.03828006701680321\n",
      "remaining size for Round 3: 135784\n",
      "Calculated size for Round 3: 9153.09863234734\n",
      "orr termination 0.03695665808646219 0.07377034024170823 0.03681368215524604\n",
      "remaining size for Round 4: 126631\n",
      "78\n",
      "['step1_rr: 77', 'step2_rr: 77', 'step3_rr: 77', 'step4_rr: 77', 'step5_rr: 77']\n",
      "empirical response rate 0.05303636779505947\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "orr termination 0.035521620843925635 0.06893575315151163 0.03341413230758599\n",
      "remaining size for Round 3: 135993\n",
      "79\n",
      "['step1_rr: 78', 'step2_rr: 78', 'step3_rr: 78', 'step4_rr: 78', 'step5_rr: 78']\n",
      "empirical response rate 0.054923376029277216\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4132.498155686146\n",
      "orr termination 0.05081129073444009 0.07619693054643523 0.02538563981199514\n",
      "remaining size for Round 3: 135868\n",
      "Calculated size for Round 3: 10415.583036743721\n",
      "orr termination 0.03560777231994118 0.07204710631820836 0.03643933399826718\n",
      "remaining size for Round 4: 125453\n",
      "80\n",
      "['step1_rr: 79', 'step2_rr: 79', 'step3_rr: 79', 'step4_rr: 79', 'step5_rr: 79']\n",
      "empirical response rate 0.05415141811527905\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "orr termination 0.0355501064608736 0.06965094100733024 0.03410083454645664\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 6928.9771292216565\n",
      "orr termination 0.04814653447235604 0.07033526722920122 0.02218873275684518\n",
      "remaining size for Round 4: 128991\n",
      "Calculated size for Round 4: 6738.625380527905\n",
      "orr termination 0.03470049854201988 0.07000434779641139 0.03530384925439151\n",
      "remaining size for last Round 5: 122253\n",
      "81\n",
      "['step1_rr: 80', 'step2_rr: 80', 'step3_rr: 80', 'step4_rr: 80', 'step5_rr: 80']\n",
      "empirical response rate 0.05518069533394328\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "orr termination 0.01626769541923377 0.07549630153872773 0.05922860611949396\n",
      "remaining size for Round 3: 135851\n",
      "82\n",
      "['step1_rr: 81', 'step2_rr: 81', 'step3_rr: 81', 'step4_rr: 81', 'step5_rr: 81']\n",
      "empirical response rate 0.05572392497712717\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "orr termination 0.04788103159588931 0.07236599520187512 0.02448496360598581\n",
      "remaining size for Round 3: 135815\n",
      "Calculated size for Round 3: 9648.071957498127\n",
      "orr termination 0.03625895188281606 0.06997613205834863 0.03371718017553257\n",
      "remaining size for Round 4: 126167\n",
      "83\n",
      "['step1_rr: 82', 'step2_rr: 82', 'step3_rr: 82', 'step4_rr: 82', 'step5_rr: 82']\n",
      "empirical response rate 0.05558096980786825\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4176.173813910594\n",
      "orr termination 0.0612839124128091 0.06860491535878643 0.007321002945977331\n",
      "remaining size for Round 3: 135824\n",
      "Calculated size for Round 3: 6195.442321147424\n",
      "orr termination 0.04534995279413931 0.07002765785091165 0.024677705056772345\n",
      "remaining size for Round 4: 129629\n",
      "Calculated size for Round 4: 5561.17473373834\n",
      "orr termination 0.04499047681023334 0.07166276123776136 0.026672284427528017\n",
      "remaining size for last Round 5: 124068\n",
      "84\n",
      "['step1_rr: 83', 'step2_rr: 83', 'step3_rr: 83', 'step4_rr: 83', 'step5_rr: 83']\n",
      "empirical response rate 0.056038426349496795\n",
      "remaining size for Round 2: 140000\n",
      "85\n",
      "['step1_rr: 84', 'step2_rr: 84', 'step3_rr: 84', 'step4_rr: 84', 'step5_rr: 84']\n",
      "empirical response rate 0.05466605672461116\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "orr termination 0.04557124487899221 0.0668588451972304 0.02128760031823819\n",
      "remaining size for Round 3: 135885\n",
      "Calculated size for Round 3: 8419.704587834109\n",
      "orr termination 0.03771094017347031 0.07571989042384046 0.03800895025037015\n",
      "remaining size for Round 4: 127466\n",
      "86\n",
      "['step1_rr: 85', 'step2_rr: 85', 'step3_rr: 85', 'step4_rr: 85', 'step5_rr: 85']\n",
      "empirical response rate 0.053579597438243365\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4043.352644626449\n",
      "orr termination 0.014820562710355468 0.0738414497347434 0.05902088702438793\n",
      "remaining size for Round 3: 135957\n",
      "87\n",
      "['step1_rr: 86', 'step2_rr: 86', 'step3_rr: 86', 'step4_rr: 86', 'step5_rr: 86']\n",
      "empirical response rate 0.054180009149130834\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4083.166195613249\n",
      "orr termination 0.026063602690447295 0.07724427304785407 0.051180670357406775\n",
      "remaining size for Round 3: 135917\n",
      "88\n",
      "['step1_rr: 87', 'step2_rr: 87', 'step3_rr: 87', 'step4_rr: 87', 'step5_rr: 87']\n",
      "empirical response rate 0.05400846294602013\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "orr termination 0.03735239685309178 0.07731684602944716 0.03996444917635538\n",
      "remaining size for Round 3: 135929\n",
      "89\n",
      "['step1_rr: 88', 'step2_rr: 88', 'step3_rr: 88', 'step4_rr: 88', 'step5_rr: 88']\n",
      "empirical response rate 0.057467978042086004\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4301.689819632026\n",
      "orr termination 0.05113832448711783 0.06735177201836864 0.016213447531250813\n",
      "remaining size for Round 3: 135699\n",
      "Calculated size for Round 3: 6175.990679829513\n",
      "orr termination 0.0131639510518929 0.07203254724626479 0.05886859619437189\n",
      "remaining size for Round 4: 129524\n",
      "90\n",
      "['step1_rr: 89', 'step2_rr: 89', 'step3_rr: 89', 'step4_rr: 89', 'step5_rr: 89']\n",
      "empirical response rate 0.05595265324794144\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "orr termination 0.020788382612117122 0.07893078855589904 0.058142405943781915\n",
      "remaining size for Round 3: 135800\n",
      "91\n",
      "['step1_rr: 90', 'step2_rr: 90', 'step3_rr: 90', 'step4_rr: 90', 'step5_rr: 90']\n",
      "empirical response rate 0.056209972552607505\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4217.9819182904175\n",
      "orr termination 0.03765121004331989 0.07387875647762364 0.03622754643430375\n",
      "remaining size for Round 3: 135783\n",
      "92\n",
      "['step1_rr: 91', 'step2_rr: 91', 'step3_rr: 91', 'step4_rr: 91', 'step5_rr: 91']\n",
      "empirical response rate 0.055666742909423604\n",
      "remaining size for Round 2: 140000\n",
      "93\n",
      "['step1_rr: 92', 'step2_rr: 92', 'step3_rr: 92', 'step4_rr: 92', 'step5_rr: 92']\n",
      "empirical response rate 0.05609560841720036\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4210.378166320425\n",
      "orr termination 0.025795045909284404 0.0739729378841921 0.0481778919749077\n",
      "remaining size for Round 3: 135790\n",
      "94\n",
      "['step1_rr: 93', 'step2_rr: 93', 'step3_rr: 93', 'step4_rr: 93', 'step5_rr: 93']\n",
      "empirical response rate 0.05340805123513266\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4031.9825257930215\n",
      "orr termination 0.04994529621807342 0.0699264693058862 0.019981173087812776\n",
      "remaining size for Round 3: 135969\n",
      "Calculated size for Round 3: 5763.829404517293\n",
      "orr termination 0.010804048049603894 0.07297060325688591 0.062166555207282016\n",
      "remaining size for Round 4: 130206\n",
      "95\n",
      "['step1_rr: 94', 'step2_rr: 94', 'step3_rr: 94', 'step4_rr: 94', 'step5_rr: 94']\n",
      "empirical response rate 0.05349382433668801\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4037.6672970440713\n",
      "orr termination 0.032000794453485026 0.07342002438000277 0.04141922992651774\n",
      "remaining size for Round 3: 135963\n",
      "Calculated size for Round 3: 6927.671376453358\n",
      "orr termination 0.025417230372143298 0.07755590584460428 0.05213867547246098\n",
      "remaining size for Round 4: 129036\n",
      "96\n",
      "['step1_rr: 95', 'step2_rr: 95', 'step3_rr: 95', 'step4_rr: 95', 'step5_rr: 95']\n",
      "empirical response rate 0.05443732845379689\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4100.237767911125\n",
      "orr termination 0.03757835760949792 0.0752231954501369 0.03764483784063899\n",
      "remaining size for Round 3: 135900\n",
      "Calculated size for Round 3: 8787.96644049996\n",
      "orr termination 0.03558327591890494 0.0729625205000857 0.037379244581180755\n",
      "remaining size for Round 4: 127113\n",
      "97\n",
      "['step1_rr: 96', 'step2_rr: 96', 'step3_rr: 96', 'step4_rr: 96', 'step5_rr: 96']\n",
      "empirical response rate 0.05200709057639524\n",
      "remaining size for Round 2: 140000\n",
      "98\n",
      "['step1_rr: 97', 'step2_rr: 97', 'step3_rr: 97', 'step4_rr: 97', 'step5_rr: 97']\n",
      "empirical response rate 0.05652447392497713\n",
      "remaining size for Round 2: 140000\n",
      "99\n",
      "['step1_rr: 98', 'step2_rr: 98', 'step3_rr: 98', 'step4_rr: 98', 'step5_rr: 98']\n",
      "empirical response rate 0.05460887465690759\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "orr termination 0.061047598634539756 0.07094290052253363 0.009895301887993875\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 6575.031418617556\n",
      "orr termination 0.04043734983021012 0.07636683664316403 0.03592948681295391\n",
      "remaining size for Round 4: 129314\n",
      "Calculated size for Round 4: 5890.374716615266\n",
      "orr termination 0.02442423496594923 0.07178227267219017 0.047358037706240946\n",
      "remaining size for last Round 5: 123424\n",
      "100\n",
      "['step1_rr: 99', 'step2_rr: 99', 'step3_rr: 99', 'step4_rr: 99', 'step5_rr: 99']\n",
      "empirical response rate 0.055380832570905765\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "orr termination 0.016277148908625916 0.0789707816171778 0.06269363270855188\n",
      "remaining size for Round 3: 135838\n"
     ]
    }
   ],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equ-RpwzMEo7",
   "metadata": {
    "id": "equ-RpwzMEo7"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "gZTkQ-gRMEo7",
   "metadata": {
    "id": "gZTkQ-gRMEo7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step1_rr</th>\n",
       "      <th>step2_rr</th>\n",
       "      <th>step3_rr</th>\n",
       "      <th>step4_rr</th>\n",
       "      <th>step5_rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.061833</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.064735</td>\n",
       "      <td>0.066419</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    step1_rr  step2_rr  step3_rr  step4_rr  step5_rr\n",
       "0      0.055  0.068471  0.068471       NaN       NaN\n",
       "1      0.055  0.063950  0.068471  0.068471       NaN\n",
       "2      0.055  0.068471  0.068471  0.068471       NaN\n",
       "3      0.055  0.061833  0.063991  0.068471  0.068471\n",
       "4      0.055  0.065161  0.068471       NaN       NaN\n",
       "..       ...       ...       ...       ...       ...\n",
       "95     0.055  0.068471  0.068471  0.068471       NaN\n",
       "96     0.055  0.068471       NaN       NaN       NaN\n",
       "97     0.055  0.068471       NaN       NaN       NaN\n",
       "98     0.055  0.064735  0.066419  0.068471  0.068471\n",
       "99     0.055  0.065964  0.068471       NaN       NaN\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "BwsZMji-MEo7",
   "metadata": {
    "id": "BwsZMji-MEo7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4 (0.9)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "eUIMiTdEMEo7",
   "metadata": {
    "id": "eUIMiTdEMEo7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_rr: 0.055 (0.000)\n",
      "step2_rr: 0.066 (0.003)\n",
      "step3_rr: 0.068 (0.001)\n",
      "step4_rr: 0.068 (0.001)\n",
      "step5_rr: 0.068 (0.000)\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "KetRvXYDMEo7",
   "metadata": {
    "id": "KetRvXYDMEo7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.066, StD: 0.002\n"
     ]
    }
   ],
   "source": [
    "# Overall orr:\n",
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fJ4Sy4igMEo7",
   "metadata": {
    "id": "fJ4Sy4igMEo7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068470526432204\n",
      "1.3877787807814457e-17\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(highest_true_rr))\n",
    "print(np.std(highest_true_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "RbNxS-49MEo8",
   "metadata": {
    "id": "RbNxS-49MEo8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.068, StD: 0.002\n"
     ]
    }
   ],
   "source": [
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "EwuXO4KlMEo8",
   "metadata": {
    "id": "EwuXO4KlMEo8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_plan_number: nan (nan)\n",
      "step2_plan_number: 4.3 (3.2)\n",
      "step3_plan_number: 2.3 (2.1)\n",
      "step4_plan_number: 1.8 (1.5)\n",
      "step5_plan_number: 1.6 (1.5)\n"
     ]
    }
   ],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "TFLSgDLvMEo8",
   "metadata": {
    "id": "TFLSgDLvMEo8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': 0.84,\n",
       " 'early_stopping_plan': 0.84,\n",
       " 'early_stopping_orr': 0.0,\n",
       " 'early_stopping_size': 0.0}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "xxj1uDGnMEo8",
   "metadata": {
    "id": "xxj1uDGnMEo8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132461.36 5840.641710497229\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bnDgAaq6MEo8",
   "metadata": {
    "id": "bnDgAaq6MEo8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_sample_size: 34976.000 (0.000)\n",
      "step2_sample_size: 24523.433 (48509.914)\n",
      "step3_sample_size: 75461.071 (64064.865)\n",
      "step4_sample_size: 79143.303 (59483.378)\n",
      "step5_sample_size: 122987.688 (987.106)\n"
     ]
    }
   ],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43JPK1OrNIH6",
   "metadata": {
    "id": "43JPK1OrNIH6"
   },
   "source": [
    "## Ensemble learning - 7 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "wuWSEB4bNIH9",
   "metadata": {
    "id": "wuWSEB4bNIH9"
   },
   "outputs": [],
   "source": [
    "# def ensemble_model_fit(data, data_pred):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         data.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1),\n",
    "#         data['response'],\n",
    "#         test_size=0.2,\n",
    "#         random_state=0\n",
    "#     )\n",
    "\n",
    "#     # Define the VotingClassifier with the individual classifiers\n",
    "#     voting_classifier = ensemble.VotingClassifier(\n",
    "#         estimators=[\n",
    "#             ('LR', linear_model.LogisticRegression(max_iter=200, random_state=0))\n",
    "# #             ('Ridge', linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, random_state=0))\n",
    "#                     # ('SVM', svm.SVC(kernel='linear', C=1.0, random_state=0, probability=True, class_weight='balanced'))\n",
    "# #                     ('RF', ensemble.RandomForestClassifier(n_estimators=200, criterion='gini', random_state=0))\n",
    "#                     # ('XGB', XGBClassifier(n_estimators=50, learning_rate=0.1, random_state=0))\n",
    "#                    ],\n",
    "#         voting='soft'\n",
    "#     )\n",
    "\n",
    "#     # Define the hyperparameter grid to search\n",
    "#     # Best Hyperparameters: {'LR__C': 0.01, 'RF__n_estimators': 50, 'XGB__n_estimators': 50}\n",
    "#     param_grid = {\n",
    "#         # 'NB__alpha': [0.01, 0.05, 0.1],  # '__' is used to specify hyperparameters for individual classifiers\n",
    "#         'LR__C': [0.01] # [0.01, 0.05, 0.1]\n",
    "#         # 'Ridge__C': [0.01]\n",
    "#         # 'SVM__C': [0.01, 0.05, 0.1]\n",
    "# #         'RF__n_estimators': [50] # [10, 30, 50]\n",
    "#         # 'XGB__n_estimators': [50]\n",
    "#     }\n",
    "\n",
    "#     # Create a GridSearchCV object\n",
    "#     # custom_scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
    "#     grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "#     # Perform the grid search on the training data\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     # Get the best hyperparameters\n",
    "#     best_params = grid_search.best_params_\n",
    "\n",
    "#     # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "#     final_voting_classifier = grid_search.best_estimator_\n",
    "#     final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "#     # Predict probabilities instead of binary outcomes on the test set\n",
    "#     y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "#     y_pred_test = final_voting_classifier.predict(X_test)\n",
    "#     X_dt = data_pred.drop(['recruitment_plan','plan_response_rate','group_size','response'], axis=1)\n",
    "#     y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ixImG0x4NIH-",
   "metadata": {
    "id": "ixImG0x4NIH-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import ensemble, linear_model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def ensemble_model_fit(data, data_pred):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['recruitment_plan', 'plan_response_rate', 'group_size', 'response'], axis=1),\n",
    "        data['response'],\n",
    "        test_size=0.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Define the VotingClassifier with the individual classifiers\n",
    "    voting_classifier = ensemble.VotingClassifier(\n",
    "        estimators=[\n",
    "            ('LR', linear_model.LogisticRegression(penalty = 'none', max_iter=200, random_state=0)),\n",
    "            ('Lasso', linear_model.LogisticRegression(penalty = \"l1\", max_iter=200, random_state=0,\n",
    "                                                     solver=\"liblinear\")),\n",
    "            ('Ridge', linear_model.LogisticRegression(penalty = \"l2\", max_iter=200, random_state=0)),\n",
    "            ('GBM', ensemble.GradientBoostingClassifier(random_state=0)),\n",
    "            ('RF', ensemble.RandomForestClassifier(random_state=0)),\n",
    "            ('XGB', XGBClassifier(random_state=0)),\n",
    "            ('NN', MLPClassifier(random_state=0))\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "#     param_grid = {\n",
    "# #         'LR__C': [0.01, 0.1, 1.0],  # Regularization parameter for logistic regression\n",
    "#         'Lasso__C': [0.01, 0.1, 1.0],  # Regularization parameter for lasso regression\n",
    "#         'Ridge__C': [0.01, 0.1, 1.0],  # Regularization parameter for ridge regression\n",
    "#         'GBM__learning_rate': [0.01, 0.1, 0.5],  # Learning rate for gradient boosting machine\n",
    "#         'GBM__n_estimators': [50, 100, 200],  # Number of trees for gradient boosting machine\n",
    "#         'RF__n_estimators': [50, 100, 200],  # Number of trees for random forest\n",
    "# #         'RF__max_depth': [10, 20],  # Maximum depth of trees for random forest\n",
    "#         'XGB__learning_rate': [0.01, 0.1, 0.5],  # Learning rate for XGBoost\n",
    "#         'XGB__n_estimators': [50, 100, 200],  # Number of trees for XGBoost\n",
    "#         'NN__hidden_layer_sizes': [(50,), (100,), (50, 50)],  # Size of hidden layers for neural networks\n",
    "#         'NN__alpha': [0.0001, 0.001, 0.01]  # Regularization parameter for neural networks\n",
    "#     }\n",
    "    param_grid = {\n",
    "#         'LR__C': [0.01, 0.1, 1.0],  # Regularization parameter for logistic regression\n",
    "        'Lasso__C': [0.1],  # Regularization parameter for lasso regression\n",
    "        'Ridge__C': [0.01],  # Regularization parameter for ridge regression\n",
    "        'GBM__learning_rate': [0.01],  # Learning rate for gradient boosting machine\n",
    "        'GBM__n_estimators': [50],  # Number of trees for gradient boosting machine\n",
    "        'RF__n_estimators': [50],  # Number of trees for random forest\n",
    "#         'RF__max_depth': [10, 20],  # Maximum depth of trees for random forest\n",
    "        'XGB__learning_rate': [0.01],  # Learning rate for XGBoost\n",
    "        'XGB__n_estimators': [50],  # Number of trees for XGBoost\n",
    "        'NN__hidden_layer_sizes': [(50,)],  # Size of hidden layers for neural networks\n",
    "        'NN__alpha': [0.01]  # Regularization parameter for neural networks\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=10, scoring='roc_auc')\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "#     print(\"Best fit parameters:\", best_params)\n",
    "\n",
    "    # Train the final VotingClassifier with the best hyperparameters on the full training set\n",
    "    final_voting_classifier = grid_search.best_estimator_\n",
    "    final_voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities instead of binary outcomes on the test set\n",
    "    y_pred_proba_test = final_voting_classifier.predict_proba(X_test)\n",
    "    y_pred_test = final_voting_classifier.predict(X_test)\n",
    "    X_dt = data_pred.drop(['recruitment_plan', 'plan_response_rate', 'group_size', 'response'], axis=1)\n",
    "    y_pred = final_voting_classifier.predict_proba(X_dt)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1f815bfe-ceb5-4354-bc23-2a441f28c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_model_fit(dt_design_5, dt_design_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gXsJYLIiNIH-",
   "metadata": {
    "id": "gXsJYLIiNIH-"
   },
   "source": [
    "### Simulation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "IT4WmJdVNIH-",
   "metadata": {
    "id": "IT4WmJdVNIH-"
   },
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "# create a list of random seeds\n",
    "random.seed(42)\n",
    "random_seeds = [random.randint(1, 100000) for _ in range(n_sim)]\n",
    "\n",
    "design_list = [5,8,10]\n",
    "patient_n_list = [5468,680,170] # n_patient_per_plan\n",
    "\n",
    "n_design = 5\n",
    "n_patient_per_plan = 5468\n",
    "n_rounds = 5\n",
    "total_n = n_patient_per_plan * (2**n_design)\n",
    "\n",
    "## sample size determination\n",
    "beta = 0.2\n",
    "power = 1 - beta\n",
    "alpha = 0.05\n",
    "delta = 0.01 # effect size\n",
    "\n",
    "## early stopping\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6WNHSDDGNIH-",
   "metadata": {
    "id": "6WNHSDDGNIH-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['step1_rr: 0', 'step2_rr: 0', 'step3_rr: 0', 'step4_rr: 0', 'step5_rr: 0']\n",
      "empirical response rate 0.05655306495882891\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4240.799240494033\n",
      "orr termination 0.028050578004677983 0.07747640179726747 0.04942582379258949\n",
      "remaining size for Round 3: 135760\n",
      "Calculated size for Round 3: 5262.438447913083\n",
      "orr termination 0.06434239544326537 0.08008295682627871 0.015740561383013343\n",
      "remaining size for Round 4: 130498\n",
      "Calculated size for Round 4: 6733.849778617701\n",
      "orr termination 0.05940425964963364 0.07882647321925763 0.019422213569623994\n",
      "remaining size for last Round 5: 123765\n",
      "2\n",
      "['step1_rr: 1', 'step2_rr: 1', 'step3_rr: 1', 'step4_rr: 1', 'step5_rr: 1']\n",
      "empirical response rate 0.054637465690759376\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "orr termination 0.05258566545057533 0.07778894936772027 0.025203283917144936\n",
      "remaining size for Round 3: 135887\n",
      "Calculated size for Round 3: 9863.91282316467\n",
      "orr termination 0.04156100987313785 0.07837862701813839 0.036817617145000536\n",
      "remaining size for Round 4: 126024\n",
      "3\n",
      "['step1_rr: 2', 'step2_rr: 2', 'step3_rr: 2', 'step4_rr: 2', 'step5_rr: 2']\n",
      "empirical response rate 0.05303636779505947\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4007.355182472531\n",
      "orr termination 0.03995281020219273 0.07919483475017994 0.039242024547987205\n",
      "remaining size for Round 3: 135993\n",
      "Calculated size for Round 3: 6382.27009200632\n",
      "orr termination 0.03932635923108842 0.07885409937115075 0.03952774014006233\n",
      "remaining size for Round 4: 129611\n",
      "Calculated size for Round 4: 6665.806856934351\n",
      "orr termination 0.03768807817670821 0.07496391293287097 0.03727583475616276\n",
      "remaining size for last Round 5: 122946\n",
      "4\n",
      "['step1_rr: 3', 'step2_rr: 3', 'step3_rr: 3', 'step4_rr: 3', 'step5_rr: 3']\n",
      "empirical response rate 0.054265782250686186\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4088.8561455390104\n",
      "orr termination 0.0616824580861379 0.07432120202934331 0.01263874394320541\n",
      "remaining size for Round 3: 135912\n",
      "Calculated size for Round 3: 6817.978557779549\n",
      "orr termination 0.029584984392169108 0.07379141714988359 0.04420643275771448\n",
      "remaining size for Round 4: 129095\n",
      "Calculated size for Round 4: 5684.09278691487\n",
      "orr termination 0.03701823488432154 0.07488350044136616 0.03786526555704462\n",
      "remaining size for last Round 5: 123411\n",
      "5\n",
      "['step1_rr: 4', 'step2_rr: 4', 'step3_rr: 4', 'step4_rr: 4', 'step5_rr: 4']\n",
      "empirical response rate 0.05772529734675206\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4318.826898633964\n",
      "orr termination 0.03227121024213632 0.08093039418095618 0.048659183938819864\n",
      "remaining size for Round 3: 135682\n",
      "Calculated size for Round 3: 7882.070213727441\n",
      "orr termination 0.03843811728048902 0.07704281612738346 0.03860469884689444\n",
      "remaining size for Round 4: 127800\n",
      "6\n",
      "['step1_rr: 5', 'step2_rr: 5', 'step3_rr: 5', 'step4_rr: 5', 'step5_rr: 5']\n",
      "empirical response rate 0.05458028362305581\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "orr termination 0.022267950096103127 0.07968263934453455 0.057414689248431426\n",
      "remaining size for Round 3: 135891\n",
      "Calculated size for Round 3: 5599.69242158022\n",
      "orr termination 0.026217110195850463 0.07871379329770813 0.052496683101857664\n",
      "remaining size for Round 4: 130292\n",
      "7\n",
      "['step1_rr: 6', 'step2_rr: 6', 'step3_rr: 6', 'step4_rr: 6', 'step5_rr: 6']\n",
      "empirical response rate 0.05775388838060384\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4320.7313323598355\n",
      "orr termination 0.05438643778041385 0.08082188562074458 0.02643544784033073\n",
      "remaining size for Round 3: 135680\n",
      "Calculated size for Round 3: 11316.339253327113\n",
      "orr termination 0.03782080721205894 0.07748371459183459 0.03966290737977565\n",
      "remaining size for Round 4: 124364\n",
      "8\n",
      "['step1_rr: 7', 'step2_rr: 7', 'step3_rr: 7', 'step4_rr: 7', 'step5_rr: 7']\n",
      "empirical response rate 0.05749656907593779\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4303.593688344371\n",
      "orr termination 0.04295546592215553 0.0775107950043378 0.03455532908218227\n",
      "remaining size for Round 3: 135697\n",
      "Calculated size for Round 3: 5689.2878508516615\n",
      "orr termination 0.05268353709465862 0.07860062686812073 0.025917089773462118\n",
      "remaining size for Round 4: 130008\n",
      "Calculated size for Round 4: 6374.579916138334\n",
      "orr termination 0.04214391462670132 0.08341378074313896 0.04126986611643764\n",
      "remaining size for last Round 5: 123634\n",
      "9\n",
      "['step1_rr: 8', 'step2_rr: 8', 'step3_rr: 8', 'step4_rr: 8', 'step5_rr: 8']\n",
      "empirical response rate 0.0553236505032022\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4159.079338458144\n",
      "orr termination 0.04209254484390522 0.08339763341285597 0.04130508856895075\n",
      "remaining size for Round 3: 135841\n",
      "10\n",
      "['step1_rr: 9', 'step2_rr: 9', 'step3_rr: 9', 'step4_rr: 9', 'step5_rr: 9']\n",
      "empirical response rate 0.0536939615736505\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "orr termination 0.05355795553584017 0.07989709465147751 0.026339139115637344\n",
      "remaining size for Round 3: 135950\n",
      "Calculated size for Round 3: 7419.508447839914\n",
      "orr termination 0.020769651951928855 0.08093271058117106 0.060163058629242205\n",
      "remaining size for Round 4: 128531\n",
      "11\n",
      "['step1_rr: 10', 'step2_rr: 10', 'step3_rr: 10', 'step4_rr: 10', 'step5_rr: 10']\n",
      "empirical response rate 0.05460887465690759\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "orr termination 0.0599083621261241 0.08036974757340075 0.020461385447276652\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 8710.76757072587\n",
      "orr termination 0.02662771709322386 0.07884737146677237 0.05221965437354851\n",
      "remaining size for Round 4: 127179\n",
      "12\n",
      "['step1_rr: 11', 'step2_rr: 11', 'step3_rr: 11', 'step4_rr: 11', 'step5_rr: 11']\n",
      "empirical response rate 0.05275045745654163\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 3988.418451118696\n",
      "orr termination 0.058385748256098616 0.07719819510560878 0.018812446849510167\n",
      "remaining size for Round 3: 136012\n",
      "Calculated size for Round 3: 6088.585468763352\n",
      "orr termination 0.040556210977173296 0.07867242775716889 0.03811621677999559\n",
      "remaining size for Round 4: 129924\n",
      "Calculated size for Round 4: 5952.380518829358\n",
      "orr termination 0.027414672933320585 0.08184770513719339 0.0544330322038728\n",
      "remaining size for last Round 5: 123972\n",
      "13\n",
      "['step1_rr: 12', 'step2_rr: 12', 'step3_rr: 12', 'step4_rr: 12', 'step5_rr: 12']\n",
      "empirical response rate 0.05626715462031107\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4221.784173594918\n",
      "orr termination 0.04196456627033828 0.08367335649991957 0.04170879022958129\n",
      "remaining size for Round 3: 135779\n",
      "14\n",
      "['step1_rr: 13', 'step2_rr: 13', 'step3_rr: 13', 'step4_rr: 13', 'step5_rr: 13']\n",
      "empirical response rate 0.05466605672461116\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "orr termination 0.017029938566384732 0.07992551160202775 0.06289557303564303\n",
      "remaining size for Round 3: 135885\n",
      "15\n",
      "['step1_rr: 14', 'step2_rr: 14', 'step3_rr: 14', 'step4_rr: 14', 'step5_rr: 14']\n",
      "empirical response rate 0.05375114364135407\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "orr termination 0.05949887365107111 0.07920248829709327 0.01970361464602216\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 8862.981334632133\n",
      "orr termination 0.02812691793156017 0.0807373490513116 0.05261043111975142\n",
      "remaining size for Round 4: 127084\n",
      "16\n",
      "['step1_rr: 15', 'step2_rr: 15', 'step3_rr: 15', 'step4_rr: 15', 'step5_rr: 15']\n",
      "empirical response rate 0.05466605672461116\n",
      "remaining size for Round 2: 140000\n",
      "17\n",
      "['step1_rr: 16', 'step2_rr: 16', 'step3_rr: 16', 'step4_rr: 16', 'step5_rr: 16']\n",
      "empirical response rate 0.05595265324794144\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "orr termination 0.0453538142166996 0.08071230632782364 0.03535849211112404\n",
      "remaining size for Round 3: 135800\n",
      "Calculated size for Round 3: 6261.636502352751\n",
      "orr termination 0.06200043203508738 0.07685185828848434 0.014851426253396964\n",
      "remaining size for Round 4: 129539\n",
      "Calculated size for Round 4: 6268.357139146181\n",
      "orr termination 0.03827436434004135 0.07743630953971221 0.03916194519967087\n",
      "remaining size for last Round 5: 123271\n",
      "18\n",
      "['step1_rr: 17', 'step2_rr: 17', 'step3_rr: 17', 'step4_rr: 17', 'step5_rr: 17']\n",
      "empirical response rate 0.05480901189387008\n",
      "remaining size for Round 2: 140000\n",
      "19\n",
      "['step1_rr: 18', 'step2_rr: 18', 'step3_rr: 18', 'step4_rr: 18', 'step5_rr: 18']\n",
      "empirical response rate 0.05598124428179323\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "orr termination 0.04022905332991139 0.081092957864714 0.04086390453480261\n",
      "remaining size for Round 3: 135798\n",
      "20\n",
      "['step1_rr: 19', 'step2_rr: 19', 'step3_rr: 19', 'step4_rr: 19', 'step5_rr: 19']\n",
      "empirical response rate 0.05489478499542543\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "orr termination 0.05415648576592917 0.07642976365301488 0.022273277887085705\n",
      "remaining size for Round 3: 135870\n",
      "Calculated size for Round 3: 5825.885488866729\n",
      "orr termination 0.03441816630115204 0.0775998655285822 0.043181699227430155\n",
      "remaining size for Round 4: 130045\n",
      "Calculated size for Round 4: 5738.011579940944\n",
      "orr termination 0.026791799663424355 0.07998502743040782 0.053193227766983465\n",
      "remaining size for last Round 5: 124307\n",
      "21\n",
      "['step1_rr: 20', 'step2_rr: 20', 'step3_rr: 20', 'step4_rr: 20', 'step5_rr: 20']\n",
      "empirical response rate 0.05486619396157365\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4128.701861019453\n",
      "orr termination 0.06530424145100401 0.074448489832519 0.009144248381514994\n",
      "remaining size for Round 3: 135872\n",
      "Calculated size for Round 3: 6310.541921682473\n",
      "orr termination 0.05426430304141583 0.07480101923356704 0.020536716192151208\n",
      "remaining size for Round 4: 129562\n",
      "Calculated size for Round 4: 5525.609803333159\n",
      "orr termination 0.031277145711458836 0.07687879845825171 0.04560165274679288\n",
      "remaining size for last Round 5: 124037\n",
      "22\n",
      "['step1_rr: 21', 'step2_rr: 21', 'step3_rr: 21', 'step4_rr: 21', 'step5_rr: 21']\n",
      "empirical response rate 0.05518069533394328\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "orr termination 0.027487382650316684 0.08203229803639864 0.05454491538608196\n",
      "remaining size for Round 3: 135851\n",
      "23\n",
      "['step1_rr: 22', 'step2_rr: 22', 'step3_rr: 22', 'step4_rr: 22', 'step5_rr: 22']\n",
      "empirical response rate 0.054780420860018296\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "orr termination 0.039347385036818026 0.07855018328700682 0.03920279825018879\n",
      "remaining size for Round 3: 135877\n",
      "24\n",
      "['step1_rr: 23', 'step2_rr: 23', 'step3_rr: 23', 'step4_rr: 23', 'step5_rr: 23']\n",
      "empirical response rate 0.05415141811527905\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "orr termination 0.03255498815897222 0.07984708568790236 0.04729209752893014\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 7863.697547225291\n",
      "orr termination 0.03721041328580743 0.07418796548103516 0.036977552195227734\n",
      "remaining size for Round 4: 128056\n",
      "25\n",
      "['step1_rr: 24', 'step2_rr: 24', 'step3_rr: 24', 'step4_rr: 24', 'step5_rr: 24']\n",
      "empirical response rate 0.05400846294602013\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "orr termination 0.05604297214496611 0.07835042506910461 0.0223074529241385\n",
      "remaining size for Round 3: 135929\n",
      "Calculated size for Round 3: 6656.540759999831\n",
      "orr termination 0.030750179224424537 0.0773137690091037 0.04656358978467916\n",
      "remaining size for Round 4: 129273\n",
      "Calculated size for Round 4: 6057.9209020379685\n",
      "orr termination 0.04148287473519407 0.08288444243632441 0.04140156770113034\n",
      "remaining size for last Round 5: 123216\n",
      "26\n",
      "['step1_rr: 25', 'step2_rr: 25', 'step3_rr: 25', 'step4_rr: 25', 'step5_rr: 25']\n",
      "empirical response rate 0.056038426349496795\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4206.576669795643\n",
      "orr termination 0.04903710748409767 0.07734733072611112 0.028310223242013453\n",
      "remaining size for Round 3: 135794\n",
      "Calculated size for Round 3: 6317.9619188125525\n",
      "orr termination 0.03238308464682647 0.0790984523228082 0.04671536767598173\n",
      "remaining size for Round 4: 129477\n",
      "Calculated size for Round 4: 6081.837240426962\n",
      "orr termination 0.039350163368894325 0.07812979581398721 0.03877963244509289\n",
      "remaining size for last Round 5: 123396\n",
      "27\n",
      "['step1_rr: 26', 'step2_rr: 26', 'step3_rr: 26', 'step4_rr: 26', 'step5_rr: 26']\n",
      "empirical response rate 0.05377973467520585\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "orr termination 0.018401433434070264 0.08537507944963504 0.06697364601556478\n",
      "remaining size for Round 3: 135944\n",
      "28\n",
      "['step1_rr: 27', 'step2_rr: 27', 'step3_rr: 27', 'step4_rr: 27', 'step5_rr: 27']\n",
      "empirical response rate 0.0529791857273559\n",
      "remaining size for Round 2: 140000\n",
      "29\n",
      "['step1_rr: 28', 'step2_rr: 28', 'step3_rr: 28', 'step4_rr: 28', 'step5_rr: 28']\n",
      "empirical response rate 0.05312214089661482\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4013.037453633404\n",
      "orr termination 0.02627578571429175 0.07685485273815035 0.0505790670238586\n",
      "remaining size for Round 3: 135987\n",
      "30\n",
      "['step1_rr: 29', 'step2_rr: 29', 'step3_rr: 29', 'step4_rr: 29', 'step5_rr: 29']\n",
      "empirical response rate 0.054837602927721864\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "orr termination 0.012972876587602192 0.07598070750483352 0.06300783091723132\n",
      "remaining size for Round 3: 135874\n",
      "Calculated size for Round 3: 5578.978519348212\n",
      "orr termination 0.0393893052156517 0.07957745485864916 0.04018814964299746\n",
      "remaining size for Round 4: 130296\n",
      "31\n",
      "['step1_rr: 30', 'step2_rr: 30', 'step3_rr: 30', 'step4_rr: 30', 'step5_rr: 30']\n",
      "empirical response rate 0.05518069533394328\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "orr termination 0.029415451269150544 0.07849887147533213 0.04908342020618159\n",
      "remaining size for Round 3: 135851\n",
      "Calculated size for Round 3: 5863.916193367026\n",
      "orr termination 0.01992254036303856 0.0799741948683167 0.060051654505278135\n",
      "remaining size for Round 4: 129988\n",
      "32\n",
      "['step1_rr: 31', 'step2_rr: 31', 'step3_rr: 31', 'step4_rr: 31', 'step5_rr: 31']\n",
      "empirical response rate 0.05435155535224154\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4094.5466697157462\n",
      "orr termination 0.04069538921570424 0.0818213629345912 0.04112597371888697\n",
      "remaining size for Round 3: 135906\n",
      "33\n",
      "['step1_rr: 32', 'step2_rr: 32', 'step3_rr: 32', 'step4_rr: 32', 'step5_rr: 32']\n",
      "empirical response rate 0.05332227813357731\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4026.2983311032726\n",
      "orr termination 0.037220002675971475 0.0750647343939475 0.03784473171797602\n",
      "remaining size for Round 3: 135974\n",
      "34\n",
      "['step1_rr: 33', 'step2_rr: 33', 'step3_rr: 33', 'step4_rr: 33', 'step5_rr: 33']\n",
      "empirical response rate 0.05375114364135407\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4054.7250678641312\n",
      "orr termination 0.04700114891779822 0.07742836421439064 0.030427215296592425\n",
      "remaining size for Round 3: 135946\n",
      "Calculated size for Round 3: 5862.399837722858\n",
      "orr termination 0.052440018204786845 0.07734954184361781 0.024909523638830963\n",
      "remaining size for Round 4: 130084\n",
      "Calculated size for Round 4: 6199.205125777967\n",
      "orr termination 0.02078039422735569 0.07948364680097966 0.05870325257362397\n",
      "remaining size for last Round 5: 123885\n",
      "35\n",
      "['step1_rr: 34', 'step2_rr: 34', 'step3_rr: 34', 'step4_rr: 34', 'step5_rr: 34']\n",
      "empirical response rate 0.054637465690759376\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4113.519228021547\n",
      "orr termination 0.049596003904562716 0.07359125474269554 0.023995250838132823\n",
      "remaining size for Round 3: 135887\n",
      "Calculated size for Round 3: 8934.00598156634\n",
      "orr termination 0.04208353160558849 0.08228249196474341 0.04019896035915492\n",
      "remaining size for Round 4: 126953\n",
      "36\n",
      "['step1_rr: 35', 'step2_rr: 35', 'step3_rr: 35', 'step4_rr: 35', 'step5_rr: 35']\n",
      "empirical response rate 0.05669602012808783\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4250.309141054068\n",
      "orr termination 0.03047354309133447 0.0755650682837532 0.04509152519241873\n",
      "remaining size for Round 3: 135750\n",
      "Calculated size for Round 3: 7063.914287039291\n",
      "orr termination 0.03901458138098181 0.07662578796590144 0.037611206584919635\n",
      "remaining size for Round 4: 128687\n",
      "37\n",
      "['step1_rr: 36', 'step2_rr: 36', 'step3_rr: 36', 'step4_rr: 36', 'step5_rr: 36']\n",
      "empirical response rate 0.05600983531564501\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4204.676016429063\n",
      "orr termination 0.03900318281055777 0.07734666938149976 0.038343486570941984\n",
      "remaining size for Round 3: 135796\n",
      "Calculated size for Round 3: 6715.329769957385\n",
      "orr termination 0.03805034994970285 0.0773565660744055 0.03930621612470265\n",
      "remaining size for Round 4: 129081\n",
      "Calculated size for Round 4: 6510.842467736615\n",
      "orr termination 0.03721620666948291 0.07493498322708056 0.03771877655759765\n",
      "remaining size for last Round 5: 122571\n",
      "38\n",
      "['step1_rr: 37', 'step2_rr: 37', 'step3_rr: 37', 'step4_rr: 37', 'step5_rr: 37']\n",
      "empirical response rate 0.05458028362305581\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "orr termination 0.02102538929468593 0.0804681899232426 0.05944280062855667\n",
      "remaining size for Round 3: 135891\n",
      "39\n",
      "['step1_rr: 38', 'step2_rr: 38', 'step3_rr: 38', 'step4_rr: 38', 'step5_rr: 38']\n",
      "empirical response rate 0.05535224153705398\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4160.97847079396\n",
      "orr termination 0.04078344513801377 0.08224828857851212 0.04146484344049835\n",
      "remaining size for Round 3: 135840\n",
      "40\n",
      "['step1_rr: 39', 'step2_rr: 39', 'step3_rr: 39', 'step4_rr: 39', 'step5_rr: 39']\n",
      "empirical response rate 0.05489478499542543\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4130.599976544927\n",
      "orr termination 0.040632688169868245 0.07969484749160506 0.03906215932173682\n",
      "remaining size for Round 3: 135870\n",
      "41\n",
      "['step1_rr: 40', 'step2_rr: 40', 'step3_rr: 40', 'step4_rr: 40', 'step5_rr: 40']\n",
      "empirical response rate 0.05529505946935041\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4157.18026960777\n",
      "orr termination 0.019383111767292183 0.07847009284947251 0.05908698108218033\n",
      "remaining size for Round 3: 135843\n",
      "42\n",
      "['step1_rr: 41', 'step2_rr: 41', 'step3_rr: 41', 'step4_rr: 41', 'step5_rr: 41']\n",
      "empirical response rate 0.05363677950594693\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "orr termination 0.044796601188162886 0.08650457368167948 0.04170797249351659\n",
      "remaining size for Round 3: 135953\n",
      "43\n",
      "['step1_rr: 42', 'step2_rr: 42', 'step3_rr: 42', 'step4_rr: 42', 'step5_rr: 42']\n",
      "empirical response rate 0.05377973467520585\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4056.620695646924\n",
      "orr termination 0.04132947920316615 0.08270483596260196 0.04137535675943581\n",
      "remaining size for Round 3: 135944\n",
      "44\n",
      "['step1_rr: 43', 'step2_rr: 43', 'step3_rr: 43', 'step4_rr: 43', 'step5_rr: 43']\n",
      "empirical response rate 0.05583828911253431\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4193.273425323935\n",
      "orr termination 0.015330281046462267 0.07546070847587875 0.06013042742941649\n",
      "remaining size for Round 3: 135807\n",
      "45\n",
      "['step1_rr: 44', 'step2_rr: 44', 'step3_rr: 44', 'step4_rr: 44', 'step5_rr: 44']\n",
      "empirical response rate 0.05555237877401647\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4174.274174005051\n",
      "orr termination 0.041014481462810004 0.08101214736415027 0.03999766590134027\n",
      "remaining size for Round 3: 135826\n",
      "Calculated size for Round 3: 8880.019582934601\n",
      "orr termination 0.04231984741927279 0.08454876668770217 0.04222891926842938\n",
      "remaining size for Round 4: 126946\n",
      "46\n",
      "['step1_rr: 45', 'step2_rr: 45', 'step3_rr: 45', 'step4_rr: 45', 'step5_rr: 45']\n",
      "empirical response rate 0.0536939615736505\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4050.934004187099\n",
      "orr termination 0.05760963083278524 0.07766377746475826 0.020054146631973024\n",
      "remaining size for Round 3: 135950\n",
      "Calculated size for Round 3: 8726.637294679387\n",
      "orr termination 0.05324063183714846 0.0788154399931685 0.02557480815602005\n",
      "remaining size for Round 4: 127224\n",
      "Calculated size for Round 4: 6275.896981730762\n",
      "orr termination 0.03889256063222644 0.07824639127508694 0.0393538306428605\n",
      "remaining size for last Round 5: 120949\n",
      "47\n",
      "['step1_rr: 46', 'step2_rr: 46', 'step3_rr: 46', 'step4_rr: 46', 'step5_rr: 46']\n",
      "empirical response rate 0.05449451052150046\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4104.032152159118\n",
      "orr termination 0.04985182987215729 0.08195605981154215 0.03210422993938486\n",
      "remaining size for Round 3: 135896\n",
      "Calculated size for Round 3: 8225.607815216212\n",
      "orr termination 0.02577258110837221 0.07903606394103936 0.05326348283266715\n",
      "remaining size for Round 4: 127671\n",
      "48\n",
      "['step1_rr: 47', 'step2_rr: 47', 'step3_rr: 47', 'step4_rr: 47', 'step5_rr: 47']\n",
      "empirical response rate 0.055380832570905765\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "orr termination 0.04838056054894191 0.08302359094298924 0.03464303039404733\n",
      "remaining size for Round 3: 135838\n",
      "Calculated size for Round 3: 7337.529357412252\n",
      "orr termination 0.02061527921067477 0.08182575448232868 0.06121047527165391\n",
      "remaining size for Round 4: 128501\n",
      "49\n",
      "['step1_rr: 48', 'step2_rr: 48', 'step3_rr: 48', 'step4_rr: 48', 'step5_rr: 48']\n",
      "empirical response rate 0.0554951967063129\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4170.4750844497285\n",
      "orr termination 0.05199640304628389 0.07701290186737401 0.025016498821090125\n",
      "remaining size for Round 3: 135830\n",
      "Calculated size for Round 3: 9162.179324153083\n",
      "orr termination 0.038646684575875855 0.0766374582223597 0.03799077364648385\n",
      "remaining size for Round 4: 126668\n",
      "50\n",
      "['step1_rr: 49', 'step2_rr: 49', 'step3_rr: 49', 'step4_rr: 49', 'step5_rr: 49']\n",
      "empirical response rate 0.05563815187557182\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4179.973283933777\n",
      "orr termination 0.046553225403252435 0.07778635505639808 0.031233129653145647\n",
      "remaining size for Round 3: 135821\n",
      "Calculated size for Round 3: 7138.89920338488\n",
      "orr termination 0.05219458071983504 0.07822646893059856 0.02603188821076352\n",
      "remaining size for Round 4: 128683\n",
      "Calculated size for Round 4: 6601.224750038162\n",
      "orr termination 0.038082737293099564 0.07584266131001305 0.037759924016913485\n",
      "remaining size for last Round 5: 122082\n",
      "51\n",
      "['step1_rr: 50', 'step2_rr: 50', 'step3_rr: 50', 'step4_rr: 50', 'step5_rr: 50']\n",
      "empirical response rate 0.05586688014638609\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4195.17369890541\n",
      "orr termination 0.0655776023035611 0.07657443389422626 0.010996831590665154\n",
      "remaining size for Round 3: 135805\n",
      "Calculated size for Round 3: 6514.745686540579\n",
      "orr termination 0.06595869449354089 0.07849704279345929 0.0125383482999184\n",
      "remaining size for Round 4: 129291\n",
      "Calculated size for Round 4: 6062.726987083972\n",
      "orr termination 0.06124208683340537 0.0762571738680862 0.015015087034680831\n",
      "remaining size for last Round 5: 123229\n",
      "52\n",
      "['step1_rr: 51', 'step2_rr: 51', 'step3_rr: 51', 'step4_rr: 51', 'step5_rr: 51']\n",
      "empirical response rate 0.055809698078682524\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "orr termination 0.04023087208648568 0.0797420554301699 0.039511183343684225\n",
      "remaining size for Round 3: 135809\n",
      "53\n",
      "['step1_rr: 52', 'step2_rr: 52', 'step3_rr: 52', 'step4_rr: 52', 'step5_rr: 52']\n",
      "empirical response rate 0.05661024702653248\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4244.60301145521\n",
      "orr termination 0.0290038214643201 0.08628428527373445 0.05728046380941436\n",
      "remaining size for Round 3: 135756\n",
      "54\n",
      "['step1_rr: 53', 'step2_rr: 53', 'step3_rr: 53', 'step4_rr: 53', 'step5_rr: 53']\n",
      "empirical response rate 0.054837602927721864\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4126.80380911839\n",
      "orr termination 0.06278233275927705 0.08354303154413882 0.020760698784861767\n",
      "remaining size for Round 3: 135874\n",
      "Calculated size for Round 3: 9464.369345991343\n",
      "orr termination 0.05550807975899788 0.08280274038741947 0.02729466062842159\n",
      "remaining size for Round 4: 126410\n",
      "Calculated size for Round 4: 6245.448190296271\n",
      "orr termination 0.041616895138137586 0.08327183113650703 0.04165493599836945\n",
      "remaining size for last Round 5: 120165\n",
      "55\n",
      "['step1_rr: 54', 'step2_rr: 54', 'step3_rr: 54', 'step4_rr: 54', 'step5_rr: 54']\n",
      "empirical response rate 0.05323650503202196\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4020.614713204558\n",
      "orr termination 0.053399326060773064 0.07965240183465289 0.026253075773879822\n",
      "remaining size for Round 3: 135980\n",
      "Calculated size for Round 3: 10380.253032656941\n",
      "orr termination 0.03766523058176825 0.07585140973623172 0.03818617915446347\n",
      "remaining size for Round 4: 125600\n",
      "56\n",
      "['step1_rr: 55', 'step2_rr: 55', 'step3_rr: 55', 'step4_rr: 55', 'step5_rr: 55']\n",
      "empirical response rate 0.054780420860018296\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4123.007896224133\n",
      "orr termination 0.04684925292995673 0.07001795356903284 0.023168700639076112\n",
      "remaining size for Round 3: 135877\n",
      "Calculated size for Round 3: 7775.144927856973\n",
      "orr termination 0.0392556045491713 0.07438369257111303 0.035128088021941735\n",
      "remaining size for Round 4: 128102\n",
      "57\n",
      "['step1_rr: 56', 'step2_rr: 56', 'step3_rr: 56', 'step4_rr: 56', 'step5_rr: 56']\n",
      "empirical response rate 0.05446591948764867\n",
      "remaining size for Round 2: 140000\n",
      "58\n",
      "['step1_rr: 57', 'step2_rr: 57', 'step3_rr: 57', 'step4_rr: 57', 'step5_rr: 57']\n",
      "empirical response rate 0.053979871912168347\n",
      "remaining size for Round 2: 140000\n",
      "59\n",
      "['step1_rr: 58', 'step2_rr: 58', 'step3_rr: 58', 'step4_rr: 58', 'step5_rr: 58']\n",
      "empirical response rate 0.05546660567246112\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4168.575634817409\n",
      "orr termination 0.041488133589021876 0.08238138434120613 0.04089325075218426\n",
      "remaining size for Round 3: 135832\n",
      "60\n",
      "['step1_rr: 59', 'step2_rr: 59', 'step3_rr: 59', 'step4_rr: 59', 'step5_rr: 59']\n",
      "empirical response rate 0.05498055809698079\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4136.294704781159\n",
      "orr termination 0.01599290167253355 0.07925361205703615 0.06326071038450261\n",
      "remaining size for Round 3: 135864\n",
      "61\n",
      "['step1_rr: 60', 'step2_rr: 60', 'step3_rr: 60', 'step4_rr: 60', 'step5_rr: 60']\n",
      "empirical response rate 0.055895471180237875\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4197.074035806328\n",
      "orr termination 0.05152986383602764 0.07364091711042087 0.02211105327439323\n",
      "remaining size for Round 3: 135803\n",
      "Calculated size for Round 3: 5866.108892684864\n",
      "orr termination 0.05381947549200292 0.07523754051840788 0.021418065026404955\n",
      "remaining size for Round 4: 129937\n",
      "Calculated size for Round 4: 5673.74203849496\n",
      "orr termination 0.03212193737614927 0.07819846646817535 0.046076529092026086\n",
      "remaining size for last Round 5: 124264\n",
      "62\n",
      "['step1_rr: 61', 'step2_rr: 61', 'step3_rr: 61', 'step4_rr: 61', 'step5_rr: 61']\n",
      "empirical response rate 0.05312214089661482\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4013.037453633404\n",
      "orr termination 0.04347987782308113 0.07615637843439767 0.032676500611316536\n",
      "remaining size for Round 3: 135987\n",
      "Calculated size for Round 3: 6419.2636168193285\n",
      "orr termination 0.02054219412513997 0.07912705385537303 0.05858485973023306\n",
      "remaining size for Round 4: 129568\n",
      "63\n",
      "['step1_rr: 62', 'step2_rr: 62', 'step3_rr: 62', 'step4_rr: 62', 'step5_rr: 62']\n",
      "empirical response rate 0.05689615736505032\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4263.625650278873\n",
      "orr termination 0.0317789960252146 0.07947398833659275 0.04769499231137815\n",
      "remaining size for Round 3: 135737\n",
      "Calculated size for Round 3: 7468.918103441395\n",
      "orr termination 0.04074455761441568 0.08215162878760426 0.041407071173188585\n",
      "remaining size for Round 4: 128269\n",
      "64\n",
      "['step1_rr: 63', 'step2_rr: 63', 'step3_rr: 63', 'step4_rr: 63', 'step5_rr: 63']\n",
      "empirical response rate 0.05458028362305581\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4109.724206535297\n",
      "orr termination 0.026185358063994888 0.07854619515925158 0.0523608370952567\n",
      "remaining size for Round 3: 135891\n",
      "65\n",
      "['step1_rr: 64', 'step2_rr: 64', 'step3_rr: 64', 'step4_rr: 64', 'step5_rr: 64']\n",
      "empirical response rate 0.05592406221408966\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "orr termination 0.038449496720063946 0.07742198691693412 0.03897249019687018\n",
      "remaining size for Round 3: 135802\n",
      "66\n",
      "['step1_rr: 65', 'step2_rr: 65', 'step3_rr: 65', 'step4_rr: 65', 'step5_rr: 65']\n",
      "empirical response rate 0.05598124428179323\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4202.775426338063\n",
      "orr termination 0.056664694464503736 0.08412375595249444 0.027459061487990703\n",
      "remaining size for Round 3: 135798\n",
      "Calculated size for Round 3: 11855.950310752247\n",
      "orr termination 0.03971652118038788 0.0801527867781859 0.04043626559779801\n",
      "remaining size for Round 4: 123943\n",
      "67\n",
      "['step1_rr: 66', 'step2_rr: 66', 'step3_rr: 66', 'step4_rr: 66', 'step5_rr: 66']\n",
      "empirical response rate 0.056781793229643183\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4256.015838229115\n",
      "orr termination 0.054358496186508176 0.07596182895975738 0.021603332773249204\n",
      "remaining size for Round 3: 135744\n",
      "Calculated size for Round 3: 6589.382496219206\n",
      "orr termination 0.04798111859863878 0.07786077348270204 0.02987965488406326\n",
      "remaining size for Round 4: 129155\n",
      "Calculated size for Round 4: 6265.717290226316\n",
      "orr termination 0.05296128046740169 0.07957095198312736 0.026609671515725665\n",
      "remaining size for last Round 5: 122890\n",
      "68\n",
      "['step1_rr: 67', 'step2_rr: 67', 'step3_rr: 67', 'step4_rr: 67', 'step5_rr: 67']\n",
      "empirical response rate 0.05609560841720036\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4210.378166320425\n",
      "orr termination 0.01154917404384693 0.07743214671804677 0.06588297267419983\n",
      "remaining size for Round 3: 135790\n",
      "Calculated size for Round 3: 5486.600925040108\n",
      "orr termination 0.039016940868824505 0.07766412802024378 0.03864718715141927\n",
      "remaining size for Round 4: 130304\n",
      "69\n",
      "['step1_rr: 68', 'step2_rr: 68', 'step3_rr: 68', 'step4_rr: 68', 'step5_rr: 68']\n",
      "empirical response rate 0.05486619396157365\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4128.701861019453\n",
      "orr termination 0.033076901746053516 0.07600846624567725 0.04293156449962374\n",
      "remaining size for Round 3: 135872\n",
      "Calculated size for Round 3: 5172.309047543932\n",
      "orr termination 0.039271596124355185 0.07704088578392537 0.03776928965957019\n",
      "remaining size for Round 4: 130700\n",
      "Calculated size for Round 4: 6208.335125385662\n",
      "orr termination 0.0502966115191482 0.07524739719466601 0.02495078567551781\n",
      "remaining size for last Round 5: 124492\n",
      "70\n",
      "['step1_rr: 69', 'step2_rr: 69', 'step3_rr: 69', 'step4_rr: 69', 'step5_rr: 69']\n",
      "empirical response rate 0.05363677950594693\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4047.143196418434\n",
      "orr termination 0.06424242966795599 0.07649996003897624 0.012257530371020259\n",
      "remaining size for Round 3: 135953\n",
      "Calculated size for Round 3: 6880.739626114368\n",
      "orr termination 0.0464918117368307 0.07726404946372287 0.030772237726892165\n",
      "remaining size for Round 4: 129073\n",
      "Calculated size for Round 4: 6026.153086196818\n",
      "orr termination 0.026839524971882026 0.07930968837627227 0.052470163404390244\n",
      "remaining size for last Round 5: 123047\n",
      "71\n",
      "['step1_rr: 70', 'step2_rr: 70', 'step3_rr: 70', 'step4_rr: 70', 'step5_rr: 70']\n",
      "empirical response rate 0.055809698078682524\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4191.373215070667\n",
      "orr termination 0.050216258459317806 0.08203635607812496 0.03182009761880715\n",
      "remaining size for Round 3: 135809\n",
      "Calculated size for Round 3: 8060.170792764634\n",
      "orr termination 0.028891490828351067 0.08367357067967082 0.054782079851319755\n",
      "remaining size for Round 4: 127749\n",
      "72\n",
      "['step1_rr: 71', 'step2_rr: 71', 'step3_rr: 71', 'step4_rr: 71', 'step5_rr: 71']\n",
      "empirical response rate 0.05592406221408966\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4198.974436017923\n",
      "orr termination 0.05298652829079497 0.07928099338325942 0.02629446509246445\n",
      "remaining size for Round 3: 135802\n",
      "Calculated size for Round 3: 9948.311038831904\n",
      "orr termination 0.03973554339696728 0.07889284135285811 0.03915729795589083\n",
      "remaining size for Round 4: 125854\n",
      "73\n",
      "['step1_rr: 72', 'step2_rr: 72', 'step3_rr: 72', 'step4_rr: 72', 'step5_rr: 72']\n",
      "empirical response rate 0.05721065873741994\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4284.557829370903\n",
      "orr termination 0.032779081988691366 0.08036234141821905 0.04758325942952768\n",
      "remaining size for Round 3: 135716\n",
      "Calculated size for Round 3: 8060.2677846711695\n",
      "orr termination 0.041117223333561194 0.08244002686560427 0.041322803532043074\n",
      "remaining size for Round 4: 127656\n",
      "74\n",
      "['step1_rr: 73', 'step2_rr: 73', 'step3_rr: 73', 'step4_rr: 73', 'step5_rr: 73']\n",
      "empirical response rate 0.05572392497712717\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "orr termination 0.051341894260714546 0.07723123228542285 0.025889338024708303\n",
      "remaining size for Round 3: 135815\n",
      "Calculated size for Round 3: 10074.017989287995\n",
      "orr termination 0.03842491060011444 0.07878567560357383 0.04036076500345939\n",
      "remaining size for Round 4: 125741\n",
      "75\n",
      "['step1_rr: 74', 'step2_rr: 74', 'step3_rr: 74', 'step4_rr: 74', 'step5_rr: 74']\n",
      "empirical response rate 0.056724611161939616\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4252.211310393531\n",
      "orr termination 0.04115041530881933 0.082316472631791 0.04116605732297167\n",
      "remaining size for Round 3: 135748\n",
      "76\n",
      "['step1_rr: 75', 'step2_rr: 75', 'step3_rr: 75', 'step4_rr: 75', 'step5_rr: 75']\n",
      "empirical response rate 0.053979871912168347\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4069.8918802880116\n",
      "orr termination 0.041097504844491775 0.0727336717857216 0.031636166941229824\n",
      "remaining size for Round 3: 135931\n",
      "Calculated size for Round 3: 5967.344123374608\n",
      "orr termination 0.06199942744840978 0.07738341590513043 0.015383988456720649\n",
      "remaining size for Round 4: 129964\n",
      "Calculated size for Round 4: 6414.127639058158\n",
      "orr termination 0.05966046251073709 0.07879423571122018 0.019133773200483095\n",
      "remaining size for last Round 5: 123550\n",
      "77\n",
      "['step1_rr: 76', 'step2_rr: 76', 'step3_rr: 76', 'step4_rr: 76', 'step5_rr: 76']\n",
      "empirical response rate 0.05618138151875572\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4216.080885454846\n",
      "orr termination 0.040424820899476306 0.08046247331604228 0.040037652416565976\n",
      "remaining size for Round 3: 135784\n",
      "78\n",
      "['step1_rr: 77', 'step2_rr: 77', 'step3_rr: 77', 'step4_rr: 77', 'step5_rr: 77']\n",
      "empirical response rate 0.05303636779505947\n",
      "remaining size for Round 2: 140000\n",
      "79\n",
      "['step1_rr: 78', 'step2_rr: 78', 'step3_rr: 78', 'step4_rr: 78', 'step5_rr: 78']\n",
      "empirical response rate 0.054923376029277216\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4132.498155686146\n",
      "orr termination 0.03922134943805993 0.07849111789560585 0.03926976845754592\n",
      "remaining size for Round 3: 135868\n",
      "80\n",
      "['step1_rr: 79', 'step2_rr: 79', 'step3_rr: 79', 'step4_rr: 79', 'step5_rr: 79']\n",
      "empirical response rate 0.05415141811527905\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4081.2696732894456\n",
      "orr termination 0.058130413363509596 0.07274991045376997 0.01461949709026037\n",
      "remaining size for Round 3: 135919\n",
      "Calculated size for Round 3: 6970.2747551324055\n",
      "orr termination 0.037137967811386154 0.07276210247338752 0.035624134662001365\n",
      "remaining size for Round 4: 128949\n",
      "Calculated size for Round 4: 5684.543100095475\n",
      "orr termination 0.0375236908786849 0.07525736354852368 0.03773367266983878\n",
      "remaining size for last Round 5: 123265\n",
      "81\n",
      "['step1_rr: 80', 'step2_rr: 80', 'step3_rr: 80', 'step4_rr: 80', 'step5_rr: 80']\n",
      "empirical response rate 0.05518069533394328\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4149.584629234816\n",
      "orr termination 0.05278589795353343 0.077940655678925 0.025154757725391566\n",
      "remaining size for Round 3: 135851\n",
      "Calculated size for Round 3: 10377.67980297701\n",
      "orr termination 0.03946326116626725 0.07907459621571891 0.03961133504945166\n",
      "remaining size for Round 4: 125474\n",
      "82\n",
      "['step1_rr: 81', 'step2_rr: 81', 'step3_rr: 81', 'step4_rr: 81', 'step5_rr: 81']\n",
      "empirical response rate 0.05572392497712717\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4185.672964367693\n",
      "orr termination 0.053403829852834296 0.0798616700422658 0.0264578401894315\n",
      "remaining size for Round 3: 135815\n",
      "Calculated size for Round 3: 9613.44724125604\n",
      "orr termination 0.03986848585960546 0.0778700690563597 0.038001583196754236\n",
      "remaining size for Round 4: 126202\n",
      "83\n",
      "['step1_rr: 82', 'step2_rr: 82', 'step3_rr: 82', 'step4_rr: 82', 'step5_rr: 82']\n",
      "empirical response rate 0.05558096980786825\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4176.173813910594\n",
      "orr termination 0.044918175251398795 0.07689736081086412 0.03197918555946533\n",
      "remaining size for Round 3: 135824\n",
      "Calculated size for Round 3: 6308.9160656529275\n",
      "orr termination 0.0208862348558213 0.07991367021155268 0.059027435355731385\n",
      "remaining size for Round 4: 129516\n",
      "84\n",
      "['step1_rr: 83', 'step2_rr: 83', 'step3_rr: 83', 'step4_rr: 83', 'step5_rr: 83']\n",
      "empirical response rate 0.056038426349496795\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4206.576669795643\n",
      "orr termination 0.013877950258749765 0.07773355379083889 0.06385560353208913\n",
      "remaining size for Round 3: 135794\n",
      "Calculated size for Round 3: 5360.112600958171\n",
      "orr termination 0.040096711690659474 0.07838019421455336 0.03828348252389389\n",
      "remaining size for Round 4: 130434\n",
      "85\n",
      "['step1_rr: 84', 'step2_rr: 84', 'step3_rr: 84', 'step4_rr: 84', 'step5_rr: 84']\n",
      "empirical response rate 0.05466605672461116\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4115.416834309409\n",
      "orr termination 0.016574149555061073 0.07560866629457157 0.05903451673951049\n",
      "remaining size for Round 3: 135885\n",
      "Calculated size for Round 3: 5061.861710212482\n",
      "orr termination 0.027990346756411048 0.08327262138417135 0.05528227462776031\n",
      "remaining size for Round 4: 130824\n",
      "86\n",
      "['step1_rr: 85', 'step2_rr: 85', 'step3_rr: 85', 'step4_rr: 85', 'step5_rr: 85']\n",
      "empirical response rate 0.053579597438243365\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4043.352644626449\n",
      "orr termination 0.0627330756694493 0.0732884950815561 0.010555419412106803\n",
      "remaining size for Round 3: 135957\n",
      "Calculated size for Round 3: 6114.950036433685\n",
      "orr termination 0.06244174504190191 0.07402329633097754 0.011581551289075627\n",
      "remaining size for Round 4: 129843\n",
      "Calculated size for Round 4: 5493.172636348\n",
      "orr termination 0.031233869226211526 0.07680766500506986 0.04557379577885833\n",
      "remaining size for last Round 5: 124350\n",
      "87\n",
      "['step1_rr: 86', 'step2_rr: 86', 'step3_rr: 86', 'step4_rr: 86', 'step5_rr: 86']\n",
      "empirical response rate 0.054180009149130834\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4083.166195613249\n",
      "orr termination 0.05336643184283468 0.07970890542347761 0.026342473580642928\n",
      "remaining size for Round 3: 135917\n",
      "Calculated size for Round 3: 10522.766518241293\n",
      "orr termination 0.038739887871415864 0.07882489568162125 0.04008500781020539\n",
      "remaining size for Round 4: 125395\n",
      "88\n",
      "['step1_rr: 87', 'step2_rr: 87', 'step3_rr: 87', 'step4_rr: 87', 'step5_rr: 87']\n",
      "empirical response rate 0.05400846294602013\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4071.788019442796\n",
      "orr termination 0.04937876699056471 0.07552646353875779 0.02614769654819308\n",
      "remaining size for Round 3: 135929\n",
      "Calculated size for Round 3: 9459.389230019104\n",
      "orr termination 0.044071262352743924 0.08448225924284473 0.04041099689010081\n",
      "remaining size for Round 4: 126470\n",
      "89\n",
      "['step1_rr: 88', 'step2_rr: 88', 'step3_rr: 88', 'step4_rr: 88', 'step5_rr: 88']\n",
      "empirical response rate 0.057467978042086004\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4301.689819632026\n",
      "orr termination 0.0656390788354568 0.07373207709363824 0.008092998258181439\n",
      "remaining size for Round 3: 135699\n",
      "Calculated size for Round 3: 5777.241382332505\n",
      "orr termination 0.010113733359614671 0.07849315472395803 0.06837942136434336\n",
      "remaining size for Round 4: 129922\n",
      "90\n",
      "['step1_rr: 89', 'step2_rr: 89', 'step3_rr: 89', 'step4_rr: 89', 'step5_rr: 89']\n",
      "empirical response rate 0.05595265324794144\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4200.874899531425\n",
      "orr termination 0.05563716817261614 0.07883711513549316 0.02319994696287702\n",
      "remaining size for Round 3: 135800\n",
      "Calculated size for Round 3: 6073.333347597499\n",
      "orr termination 0.03691940113641988 0.0840821898203444 0.047162788683924525\n",
      "remaining size for Round 4: 129727\n",
      "Calculated size for Round 4: 6124.685547271525\n",
      "orr termination 0.05787229947478871 0.08381897162276196 0.02594667214797325\n",
      "remaining size for last Round 5: 123603\n",
      "91\n",
      "['step1_rr: 90', 'step2_rr: 90', 'step3_rr: 90', 'step4_rr: 90', 'step5_rr: 90']\n",
      "empirical response rate 0.056209972552607505\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4217.9819182904175\n",
      "orr termination 0.041366964706094946 0.08287528576867546 0.04150832106258052\n",
      "remaining size for Round 3: 135783\n",
      "92\n",
      "['step1_rr: 91', 'step2_rr: 91', 'step3_rr: 91', 'step4_rr: 91', 'step5_rr: 91']\n",
      "empirical response rate 0.055666742909423604\n",
      "remaining size for Round 2: 140000\n",
      "93\n",
      "['step1_rr: 92', 'step2_rr: 92', 'step3_rr: 92', 'step4_rr: 92', 'step5_rr: 92']\n",
      "empirical response rate 0.05609560841720036\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4210.378166320425\n",
      "orr termination 0.027415936234594363 0.0806480039372711 0.053232067702676744\n",
      "remaining size for Round 3: 135790\n",
      "94\n",
      "['step1_rr: 93', 'step2_rr: 93', 'step3_rr: 93', 'step4_rr: 93', 'step5_rr: 93']\n",
      "empirical response rate 0.05340805123513266\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4031.9825257930215\n",
      "orr termination 0.056731464471395106 0.07513993383897771 0.018408469367582607\n",
      "remaining size for Round 3: 135969\n",
      "Calculated size for Round 3: 6047.152475831199\n",
      "orr termination 0.05288801053444084 0.07655819358420313 0.02367018304976229\n",
      "remaining size for Round 4: 129922\n",
      "Calculated size for Round 4: 6056.86739400797\n",
      "orr termination 0.05811831000917289 0.07664376562555653 0.018525455616383635\n",
      "remaining size for last Round 5: 123866\n",
      "95\n",
      "['step1_rr: 94', 'step2_rr: 94', 'step3_rr: 94', 'step4_rr: 94', 'step5_rr: 94']\n",
      "empirical response rate 0.05349382433668801\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4037.6672970440713\n",
      "orr termination 0.010055184591578748 0.08151232667899405 0.0714571420874153\n",
      "remaining size for Round 3: 135963\n",
      "96\n",
      "['step1_rr: 95', 'step2_rr: 95', 'step3_rr: 95', 'step4_rr: 95', 'step5_rr: 95']\n",
      "empirical response rate 0.05443732845379689\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4100.237767911125\n",
      "orr termination 0.03247532913587142 0.08151874513149716 0.04904341599562574\n",
      "remaining size for Round 3: 135900\n",
      "Calculated size for Round 3: 8091.017548933854\n",
      "orr termination 0.04129383634350643 0.08125134742747911 0.03995751108397268\n",
      "remaining size for Round 4: 127809\n",
      "97\n",
      "['step1_rr: 96', 'step2_rr: 96', 'step3_rr: 96', 'step4_rr: 96', 'step5_rr: 96']\n",
      "empirical response rate 0.05200709057639524\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 3939.2130430862803\n",
      "orr termination 0.05719854176513218 0.0851054764499859 0.027906934684853717\n",
      "remaining size for Round 3: 136061\n",
      "Calculated size for Round 3: 11023.430221535004\n",
      "orr termination 0.03934521449511156 0.07973126716876784 0.04038605267365628\n",
      "remaining size for Round 4: 125038\n",
      "98\n",
      "['step1_rr: 97', 'step2_rr: 97', 'step3_rr: 97', 'step4_rr: 97', 'step5_rr: 97']\n",
      "empirical response rate 0.05652447392497713\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4238.897449671384\n",
      "orr termination 0.04249639699568215 0.0849752495870278 0.04247885259134566\n",
      "remaining size for Round 3: 135762\n",
      "99\n",
      "['step1_rr: 98', 'step2_rr: 98', 'step3_rr: 98', 'step4_rr: 98', 'step5_rr: 98']\n",
      "empirical response rate 0.05460887465690759\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4111.621685427298\n",
      "orr termination 0.048659885113091474 0.07685452128622094 0.02819463617312947\n",
      "remaining size for Round 3: 135889\n",
      "Calculated size for Round 3: 6254.291752131855\n",
      "orr termination 0.032284950745321395 0.08116216000966323 0.04887720926434183\n",
      "remaining size for Round 4: 129635\n",
      "Calculated size for Round 4: 6308.621845279171\n",
      "orr termination 0.0397954885128447 0.0783681161631766 0.0385726276503319\n",
      "remaining size for last Round 5: 123327\n",
      "100\n",
      "['step1_rr: 99', 'step2_rr: 99', 'step3_rr: 99', 'step4_rr: 99', 'step5_rr: 99']\n",
      "empirical response rate 0.055380832570905765\n",
      "remaining size for Round 2: 140000\n",
      "Calculated size for Round 2: 4162.8776666065105\n",
      "orr termination 0.05609999019753911 0.0837675595578677 0.02766756936032859\n",
      "remaining size for Round 3: 135838\n",
      "Calculated size for Round 3: 10900.422085594402\n",
      "orr termination 0.041065034294624984 0.08149003877865532 0.04042500448403034\n",
      "remaining size for Round 4: 124938\n"
     ]
    }
   ],
   "source": [
    "rr_dict = {\"step{}_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "sample_size_dict = {\"step{}_sample_size\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "last_round_sample_size = []\n",
    "random_rr_dict = {\"step{}_random_max_rr\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "random_rr_dict.update({\n",
    "    \"step{}_random_mean_rr\".format(r): [] for r in range(1, n_rounds + 1)\n",
    "})\n",
    "\n",
    "stopping_dict = {\"early_stopping\": [],\n",
    "                 \"early_stopping_plan\":[],\n",
    "                 \"early_stopping_orr\":[],\n",
    "                 \"early_stopping_size\":[]}\n",
    "final_plan_number = []\n",
    "highest_rr_overall = []\n",
    "highest_true_rr = []\n",
    "\n",
    "better_chance = []\n",
    "\n",
    "orr_total = []\n",
    "orr_total_adaptive = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for seed in random_seeds:\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    print([f\"{key}: {len(value)}\" for key, value in rr_dict.items()])\n",
    "\n",
    "\n",
    "\n",
    "    event_list = 0\n",
    "    event_list_adaptive = 0\n",
    "    max_rr = []\n",
    "\n",
    "    # step 1:\n",
    "    ## Generate dataset\n",
    "    dt_design_5 = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed)\n",
    "    highest_true_rr.append(np.max(dt_design_5['plan_response_rate']))\n",
    "    print(\"empirical response rate\", dt_design_5['response'].mean())\n",
    "    ## save for benchmark results\n",
    "    maxidx = np.argmax(dt_design_5['plan_response_rate'])\n",
    "    random_rr_dict['step1_random_max_rr'].append(dt_design_5.iloc[maxidx,6])\n",
    "    random_rr_dict['step1_random_mean_rr'].append(dt_design_5['plan_response_rate'].mean())\n",
    "\n",
    "    ## Ensemble modelling:\n",
    "    y_pred = ensemble_model_fit(data=dt_design_5, data_pred = dt_design_5)\n",
    "\n",
    "    ## select recruitment plan\n",
    "    pred_df = pd.DataFrame(np.hstack((dt_design_5,  y_pred[:, 1].reshape(-1, 1))),\n",
    "                             columns=list(dt_design_5.columns) + ['predicted_response_rate'])\n",
    "    pred_df_rr = pred_df.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "    x = pred_df_rr['predicted_response_rate'].values\n",
    "    if len(x) <= 10:\n",
    "        best_k = 2\n",
    "    else:\n",
    "        best_k = kmeans_fit(data = x)['best_k']\n",
    "    kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "    merged_df = pd.merge(pred_df_rr, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "    cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "    highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "    highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "    highest_cluster['p_vec'] = p_vec_next\n",
    "    highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "    # highest_cluster = pred_df_rr\n",
    "\n",
    "    # highest_cluster = pd.merge(highest_cluster, dt_design_5[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "    # highest_cluster['cluster_number'] = highest_cluster['recruitment_plan']\n",
    "\n",
    "    ## prepare to chance of better performance:\n",
    "    temp = dt_design_5[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "    event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(\"step1\", np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "    # print(temp)\n",
    "    p0 = (temp['plan_response_rate'].mean())\n",
    "\n",
    "    rr_dict[\"step1_rr\"].append(dt_design_5['plan_response_rate'].mean())\n",
    "    sample_size_dict[\"step1_sample_size\"].append(len(dt_design_5))\n",
    "\n",
    "    for round in range(2, n_rounds+1):\n",
    "\n",
    "        rr_dict[\"step\"+str(round)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "        plan_number_dict[\"step\"+str(round)+\"_plan_number\"].append(len(p_vec_next))\n",
    "\n",
    "        ## when it comes to the last round:\n",
    "        if round == n_rounds:\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            if round == 2: # if the last round is round 2\n",
    "                remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "            else:\n",
    "                remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "            print(\"remaining size for last Round \" + str(round) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            ## data generation, combine previous data:\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                          design_number = n_design, n_rounds = n_rounds,\n",
    "                                                          n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(0)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(len(temp), temp['plan_response_rate'].mean())\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        ## If haven't reached the last round:\n",
    "        ## check remaining sample size:\n",
    "        if round == 2:\n",
    "            remaining_size = total_n - len(dt_design_5) # apply to the rest of the patients\n",
    "        else:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "\n",
    "        print(\"remaining size for Round \" + str(round) + \": \" + str(remaining_size))\n",
    "\n",
    "        ## determine whether move on to step 2:\n",
    "        if len(highest_cluster) == 1: # if there is only one plan left\n",
    "\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size) # record the last round sample size\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(1)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        ## sample size determination:\n",
    "        if round == 2:\n",
    "            dt_design_5_step2up_overall = dt_design_5\n",
    "        orr_1 = dt_design_5_step2up_overall['response'].mean() # observed overall response rates for previous rounds\n",
    "        orr_2 = orr_1 + delta\n",
    "        n_1 = len(dt_design_5_step2up_overall)\n",
    "\n",
    "        size_step2up = sample_size_calc(orr_1, n_1, delta=delta, alpha=alpha, power=power) # total size for dataset\n",
    "        if size_step2up > 0 and size_step2up < 1000:\n",
    "            size_step2up = 1000 # if size in [0,1000], then it is 1000 for this round.\n",
    "        elif size_step2up >= 1000:\n",
    "            size_step2up = min(size_step2up, int(total_n/n_rounds)) # dataset size capped by the n_patient_per_plan\n",
    "        else:\n",
    "        # if size_step2up <= 0:\n",
    "            # the process stops at this step\n",
    "            print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up) + 'lt 0, break')\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                      n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "            if round == 2:\n",
    "                supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)] # data from step 1\n",
    "            else:\n",
    "                # step from previous rounds\n",
    "                supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "\n",
    "            dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(0)\n",
    "            stopping_dict['early_stopping_size'].append(1)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_step2up_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+1, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare for chance of better performance:\n",
    "            temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "            break\n",
    "\n",
    "        print('Calculated size for Round ' + str(round) + ': ' + str(size_step2up))\n",
    "\n",
    "        sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(size_step2up)\n",
    "\n",
    "        ## save benchmark results for last round:\n",
    "        dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                            n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "        maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "        random_rr_dict[\"step\"+str(round)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "        ## data generation, combine previous data:\n",
    "        dt_design_5_step2up = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next,round=round,\n",
    "                                                  design_number = n_design, n_rounds = n_rounds,\n",
    "                                                  n_patient_per_plan = n_patient_per_plan, size = int(size_step2up), seed=seed)\n",
    "\n",
    "        plan_list = dt_design_5_step2up['recruitment_plan'].unique()\n",
    "        if round == 2:\n",
    "            supp = dt_design_5[dt_design_5['recruitment_plan'].isin(plan_list)]\n",
    "        else:\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "        dt_design_5_step2up_overall = pd.concat([dt_design_5_step2up, supp.reset_index(drop=True)], axis = 0)\n",
    "        dt_design_5_step2up_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "        ## Ensemble model fitting:\n",
    "        dt_design_5_step2up.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "        y_pred2up = ensemble_model_fit(data = dt_design_5_step2up_overall, data_pred = dt_design_5_step2up)\n",
    "        pred_df_step2up = pd.DataFrame(np.hstack((dt_design_5_step2up,  y_pred2up[:, 1].reshape(-1, 1))),\n",
    "                                    columns=list(dt_design_5_step2up.columns) + ['predicted_response_rate'])\n",
    "        pred_df_rr_step2up = pred_df_step2up.groupby([f'Design_Feature_{i+1}' for i in range(n_design)]+['recruitment_plan'])['predicted_response_rate'].mean().reset_index(name='predicted_response_rate')\n",
    "\n",
    "        ## select recruitment plans:\n",
    "        x = pred_df_rr_step2up['predicted_response_rate'].values\n",
    "\n",
    "        if len(x) <= 10:\n",
    "            best_k = 2\n",
    "        else:\n",
    "            best_k = kmeans_fit(data = x)['best_k']\n",
    "        kmeans_results = kmeans_bhattacharyya(data=x, k=best_k)\n",
    "\n",
    "        ## match the cluster results back to the original data\n",
    "        highest_cluster_previous = highest_cluster # save previous cluster results\n",
    "\n",
    "        merged_df = pd.merge(pred_df_rr_step2up, kmeans_results['clusters'][['predicted_response_rate', 'cluster_number']], on='predicted_response_rate')\n",
    "        cluster_with_highest_rate = kmeans_results['clusters'].groupby('cluster_number')['predicted_response_rate'].mean().idxmax()\n",
    "        highest_cluster = merged_df[merged_df['cluster_number']==cluster_with_highest_rate].reset_index(drop=True)\n",
    "        highest_cluster.sort_values(by='predicted_response_rate', ascending=False, inplace=True)\n",
    "\n",
    "        # p_vec_previous = p_vec_next # save p_vec of previous round\n",
    "        p_vec_next = np.array(highest_cluster['predicted_response_rate']/np.sum(highest_cluster['predicted_response_rate']))\n",
    "\n",
    "        highest_cluster['p_vec'] = p_vec_next\n",
    "\n",
    "        highest_cluster = pd.merge(highest_cluster, dt_design_5_step2up[['recruitment_plan','plan_response_rate']].drop_duplicates(), how='left', on='recruitment_plan')\n",
    "\n",
    "        ## prepare to chance of better performance:\n",
    "        temp = dt_design_5_step2up[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "        event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(\"step\"+str(round), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "        # print(temp)\n",
    "\n",
    "        ## check early stopping predicted ORR:\n",
    "        orr_df = pd.merge(highest_cluster_previous, highest_cluster[['recruitment_plan','predicted_response_rate','p_vec']], on='recruitment_plan', how='left')\n",
    "        orr_df.fillna(0, inplace=True)\n",
    "        p_orr_1 = np.dot(np.array(orr_df['p_vec_x']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        p_orr_2 = np.dot(np.array(orr_df['p_vec_y']), np.array(orr_df['predicted_response_rate_y']))\n",
    "        print(\"orr termination\", p_orr_1, p_orr_2, p_orr_2 - p_orr_1)\n",
    "\n",
    "        if (p_orr_2 - p_orr_1 < epsilon):\n",
    "            # step 3 use the same strategy of step2\n",
    "            print(i, p_orr_1, p_orr_2, \"early stop at Round \" + str(round))\n",
    "            rr_dict[\"step\"+str(round+1)+\"_rr\"].append(np.dot(np.array(highest_cluster['p_vec']), np.array(highest_cluster['plan_response_rate'])))\n",
    "\n",
    "            ## save benchmark results for last round:\n",
    "            dt_benchmark = generate_data_step1(design_number = n_design, n_rounds = n_rounds,\n",
    "                                                n_patient_per_plan = n_patient_per_plan, seed=seed+round)\n",
    "            maxidx = np.argmax(dt_benchmark['plan_response_rate'])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_max_rr'].append(dt_benchmark.iloc[maxidx,6])\n",
    "            random_rr_dict[\"step\"+str(round+1)+'_random_mean_rr'].append(dt_benchmark['plan_response_rate'].mean())\n",
    "\n",
    "            ### update remaining size:\n",
    "            remaining_size -= len(dt_design_5_step2up)\n",
    "            print(\"early stop, remaining size for Round\" + str(round + 1) + \": \" + str(remaining_size))\n",
    "            sample_size_dict[\"step\"+str(round)+\"_sample_size\"].append(remaining_size)\n",
    "            last_round_sample_size.append(remaining_size)\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                sample_size_dict[\"step\"+str(r)+\"_sample_size\"].append(np.nan)\n",
    "\n",
    "            dt_design_5_rest = generate_data_step2up(highest_cluster=highest_cluster, p_vec = p_vec_next, round=round,\n",
    "                                                      design_number = n_design, n_rounds = n_rounds,\n",
    "                                                      n_patient_per_plan = n_patient_per_plan, size = int(remaining_size), seed=seed)\n",
    "            plan_list = dt_design_5_rest['recruitment_plan'].unique()\n",
    "            supp = dt_design_5_step2up_overall[dt_design_5_step2up_overall['recruitment_plan'].isin(plan_list)]\n",
    "            dt_design_5_rest_overall = pd.concat([dt_design_5_rest, supp.reset_index(drop=True)], axis = 0)\n",
    "            dt_design_5_rest_overall.drop(['predicted_response_rate','cluster_number','p_vec'], axis=1, inplace=True)\n",
    "\n",
    "            stopping_dict['early_stopping'].append(1)\n",
    "            stopping_dict['early_stopping_plan'].append(0)\n",
    "            stopping_dict['early_stopping_orr'].append(1)\n",
    "            stopping_dict['early_stopping_size'].append(0)\n",
    "\n",
    "            ## record final plan number\n",
    "            final_plan_number.append(len(p_vec_next))\n",
    "\n",
    "            ## record highest responserate overall\n",
    "            highest_rr_overall.append(np.max(dt_design_5_rest_overall['plan_response_rate']))\n",
    "\n",
    "            for r in range(round+2, n_rounds+1):\n",
    "                rr_dict[\"step\"+str(r)+\"_rr\"].append(np.nan)\n",
    "\n",
    "            ## prepare to chance of better performance:\n",
    "            temp = dt_design_5_rest[['recruitment_plan','plan_response_rate', 'group_size']].drop_duplicates()\n",
    "            event_list += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            event_list_adaptive += (np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(\"step\"+str(round+1), np.dot(temp['plan_response_rate'].values, temp['group_size'].values))\n",
    "            # print(temp)\n",
    "\n",
    "            result = binomtest(int(event_list), n=total_n, p=p0)\n",
    "            # print(int(event_list), total_n, p0)\n",
    "            orr_total.append(event_list)\n",
    "            orr_total_adaptive.append(event_list_adaptive)\n",
    "            better_chance.append(1 if result.pvalue < 0.05 else 0)\n",
    "            # print(result.pvalue)\n",
    "\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nk18kzKRNIH_",
   "metadata": {
    "id": "nk18kzKRNIH_"
   },
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9J1mW4QbNIH_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1707448236231,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "9J1mW4QbNIH_",
    "outputId": "338e681d-1cf5-4fba-cdf9-37d207e4cf10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step1_rr</th>\n",
       "      <th>step2_rr</th>\n",
       "      <th>step3_rr</th>\n",
       "      <th>step4_rr</th>\n",
       "      <th>step5_rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.061816</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.064082</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.065190</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.063879</td>\n",
       "      <td>0.065887</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.065803</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.063531</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    step1_rr  step2_rr  step3_rr  step4_rr  step5_rr\n",
       "0      0.055  0.061816  0.068471  0.068471  0.068471\n",
       "1      0.055  0.064082  0.062143  0.068471       NaN\n",
       "2      0.055  0.065190  0.068471  0.068471  0.068471\n",
       "3      0.055  0.063879  0.065887  0.068471  0.068471\n",
       "4      0.055  0.065803  0.068471  0.068471       NaN\n",
       "..       ...       ...       ...       ...       ...\n",
       "95     0.055  0.068471  0.068471  0.068471       NaN\n",
       "96     0.055  0.068471  0.068471  0.068471       NaN\n",
       "97     0.055  0.068471  0.068471       NaN       NaN\n",
       "98     0.055  0.063531  0.068471  0.068471  0.068471\n",
       "99     0.055  0.068471  0.068471  0.068471       NaN\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_df = pd.DataFrame(rr_dict)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6NYOdlLXNIH_",
   "metadata": {
    "id": "6NYOdlLXNIH_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8 (0.9)\n"
     ]
    }
   ],
   "source": [
    "# Calculate average rounds:\n",
    "row_non_nan_counts = rr_df.count(axis=1)\n",
    "\n",
    "print(f\"{np.mean(row_non_nan_counts):.1f} ({np.std(row_non_nan_counts):.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "iu_OS2wcNIH_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1707448237526,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "iu_OS2wcNIH_",
    "outputId": "27d70514-4ac7-40f9-8373-5ed213bdb833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_rr: 0.055 (0.000)\n",
      "step2_rr: 0.066 (0.002)\n",
      "step3_rr: 0.068 (0.002)\n",
      "step4_rr: 0.068 (0.001)\n",
      "step5_rr: 0.068 (0.000)\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "for key, values in rr_df.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "x86hoXfQNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707448339675,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "x86hoXfQNIIA",
    "outputId": "44c42256-3c95-48ff-b6a1-2d7484750b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.066, StD: 0.001\n"
     ]
    }
   ],
   "source": [
    "result_dict = np.array(orr_total) / total_n\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "NoLQzsrsNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1707448339008,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "NoLQzsrsNIIA",
    "outputId": "3e8dab14-08fa-4902-87dd-f18235e86888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068470526432204\n",
      "1.3877787807814457e-17\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(highest_true_rr))\n",
    "print(np.std(highest_true_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "43XsahNUNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1707447643064,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "43XsahNUNIIA",
    "outputId": "d8e676ad-a73e-4e62-f939-ebf6efadaa9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.068, StD: 0.001\n"
     ]
    }
   ],
   "source": [
    "result_dict = np.array(orr_total_adaptive) / (total_n-34976)\n",
    "mean_result = np.mean(result_dict)\n",
    "std_result = np.std(result_dict)\n",
    "\n",
    "print(f\"Mean: {mean_result:.3f}, StD: {std_result:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "-vHcWwS5NIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1707448246018,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "-vHcWwS5NIIA",
    "outputId": "7e9f5fc0-3a8c-4472-f0c2-bb0392711f79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_plan_number: nan (nan)\n",
      "step2_plan_number: 5.1 (3.4)\n",
      "step3_plan_number: 2.8 (1.9)\n",
      "step4_plan_number: 1.9 (1.3)\n",
      "step5_plan_number: 1.7 (0.8)\n"
     ]
    }
   ],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in plan_number_dict.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    result_dict[key] = f\"{mean_value:.1f} ({std_value:.1f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4ICQ_3-9NIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1707448245147,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "4ICQ_3-9NIIA",
    "outputId": "b4a9a3b4-4878-418d-da2f-545cc90cc55b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': 0.74,\n",
       " 'early_stopping_plan': 0.74,\n",
       " 'early_stopping_orr': 0.0,\n",
       " 'early_stopping_size': 0.0}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = {key: np.mean(values) for key, values in stopping_dict.items()}\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "lpvh9zRkNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1707447645503,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "lpvh9zRkNIIA",
    "outputId": "8d467010-aa11-47ae-85d1-b6e431ff7e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129809.8 5716.781251718488\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(last_round_sample_size), np.std(last_round_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "IT1BZInpNIIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1707447644111,
     "user": {
      "displayName": "Xinying Fang",
      "userId": "08585996645312082255"
     },
     "user_tz": 300
    },
    "id": "IT1BZInpNIIA",
    "outputId": "05483b1d-c213-419c-c926-cb56090014dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1_sample_size: 34976.000 (0.000)\n",
      "step2_sample_size: 13653.204 (34663.534)\n",
      "step3_sample_size: 48926.921 (60003.920)\n",
      "step4_sample_size: 77445.742 (59804.188)\n",
      "step5_sample_size: 123288.077 (968.081)\n"
     ]
    }
   ],
   "source": [
    "# plan_number_dict = {\"step{}_plan_number\".format(r): [] for r in range(1, n_rounds + 1)}\n",
    "result_dict = {}\n",
    "for key, values in sample_size_dict.items():\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_value = np.nanstd(values)\n",
    "    result_dict[key] = f\"{mean_value:.3f} ({std_value:.3f})\"\n",
    "#     result_dict[key + \"_std\"] = std_value\n",
    "for key, value in list(result_dict.items())[:12]:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7zsQ_p2wNIIA",
   "metadata": {
    "id": "7zsQ_p2wNIIA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(better_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599373f-d645-4258-b30c-de954c27a996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5df54c-d2a1-4256-8b01-ea2177d42458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb29da-a1b3-42ce-88cb-6309fcdaf1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b0d4e-c3e3-49f7-a3f6-acea176b346b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
